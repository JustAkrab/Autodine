2024-10-12 03:54:35.955 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 03:54:35.971 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 03:54:35.980 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 03:54:35.980 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 03:54:44.209 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 03:54:44.275 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:54:44.294 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 03:54:44.342 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:54:44.342 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 03:54:44.395 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:54:44.395 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 03:54:44.395 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 03:54:44.933 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 03:54:44.935 - RealTimeSTT: root - WARNING - Audio queue size exceeds latency limit. Current size: 123. Discarding old audio chunks.
2024-10-12 03:54:44.935 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 03:54:44.936 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 03:55:48.634 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 03:55:48.635 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 03:55:48.635 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 03:55:48.636 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 03:55:49.350 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 03:55:54.366 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 03:55:54.366 - RealTimeSTT: root - INFO - recording started
2024-10-12 03:55:54.366 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 03:55:54.367 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 03:55:55.525 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 03:55:55.525 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 03:55:55.526 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 03:55:55.596 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 03:55:55.600 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 03:55:55.621 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 03:55:55.645 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 03:55:58.022 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.42 seconds
2024-10-12 03:55:58.023 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 03:55:58.023 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 03:55:58.024 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 03:56:34.137 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 03:56:34.138 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 03:56:34.147 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 03:56:34.771 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 03:56:34.771 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 03:56:34.844 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 03:56:41.680 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 03:56:41.689 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 03:56:41.697 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 03:56:41.697 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 03:56:41.951 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 03:56:41.959 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:56:41.962 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 03:56:41.965 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:56:41.966 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 03:56:41.969 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:56:41.970 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 03:56:41.970 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 03:56:42.306 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 03:56:42.308 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 03:56:42.308 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 03:56:46.048 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 03:56:46.049 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 03:56:46.049 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 03:56:46.049 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 03:56:46.626 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 03:56:50.567 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 03:56:50.568 - RealTimeSTT: root - INFO - recording started
2024-10-12 03:56:50.568 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 03:56:50.568 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 03:56:51.716 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 03:56:51.716 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 03:56:51.717 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 03:56:51.767 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 03:56:51.770 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 03:56:51.774 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 03:56:51.776 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 03:56:52.472 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-10-12 03:56:52.473 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 03:56:52.473 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 03:56:52.474 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 03:58:20.658 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 03:58:20.658 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 03:58:20.667 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 03:58:21.141 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 03:58:21.242 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 03:58:21.299 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 03:58:26.853 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 03:58:26.860 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 03:58:26.865 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 03:58:26.866 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 03:58:27.075 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 03:58:27.078 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:58:27.080 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 03:58:27.082 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:58:27.083 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 03:58:27.085 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 03:58:27.085 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 03:58:27.085 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 03:58:27.325 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 03:58:27.327 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 03:58:27.327 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 03:58:31.037 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 03:58:31.038 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 03:58:31.038 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 03:58:31.039 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 03:58:31.578 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:00:59.718 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 04:00:59.719 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 04:00:59.724 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 04:01:00.362 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 04:01:00.362 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 04:01:00.424 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 04:01:06.652 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:01:06.662 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:01:06.672 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:01:06.672 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:01:06.953 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:01:06.960 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:01:06.964 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:01:06.968 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:01:06.969 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:01:06.975 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:01:06.976 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:01:06.976 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:01:07.428 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:01:07.431 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:01:07.431 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:01:11.816 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:01:11.817 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:01:11.817 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:01:11.817 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:01:12.792 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:01.599 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:01.599 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:01.599 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:01.600 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:03.779 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:03.779 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:03.781 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:03.844 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:03.852 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:03.873 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:03.898 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:04.876 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.02 seconds
2024-10-12 04:02:04.877 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:04.878 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:04.879 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:16.769 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:16.769 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:16.769 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:16.769 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:17.919 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:17.919 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:17.919 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:17.964 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:17.967 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:17.968 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:17.978 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:18.619 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.65 seconds
2024-10-12 04:02:18.620 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:18.620 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:18.621 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:22.778 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:22.778 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:22.778 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:22.778 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:23.938 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:23.938 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:23.939 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:24.009 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:24.011 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:24.011 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:24.058 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:24.727 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:02:24.728 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:24.728 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:24.729 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:34.179 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:34.179 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:34.179 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:34.179 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:35.838 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:35.838 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:35.839 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:35.906 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:35.908 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:35.925 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:35.968 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:36.545 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:02:36.546 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:36.546 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:36.547 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:42.049 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:42.049 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:42.049 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:42.050 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:43.198 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:43.198 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:43.199 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:43.298 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:43.301 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:43.309 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:43.328 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:43.983 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-10-12 04:02:43.984 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:43.984 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:43.985 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:02:49.148 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:02:49.148 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:02:49.148 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:02:49.149 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:02:50.299 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:02:50.299 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:02:50.300 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:02:50.385 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:02:50.387 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:02:50.398 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:02:50.428 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:02:51.051 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 04:02:51.052 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:02:51.052 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:02:51.053 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:03:05.917 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:05.917 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:05.919 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:03:05.919 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:07.778 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:07.778 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:03:07.779 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:07.866 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:07.869 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:07.882 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:07.897 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:08.028 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:08.028 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:08.028 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:03:08.606 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:03:08.636 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.77 seconds
2024-10-12 04:03:08.637 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:08.637 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:09.758 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:09.759 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:09.759 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:09.761 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:09.762 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:09.765 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:09.765 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:10.661 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.90 seconds
2024-10-12 04:03:10.662 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:10.662 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:10.664 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:03:28.229 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 04:03:28.230 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 04:03:28.240 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 04:03:28.734 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 04:03:38.551 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:03:38.559 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:03:38.565 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:03:38.565 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:03:38.831 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:03:38.835 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:03:38.836 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:03:38.838 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:03:38.838 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:03:38.840 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:03:38.841 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:03:38.841 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:03:39.113 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:03:39.115 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:03:39.116 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:03:42.702 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:03:42.702 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:03:42.703 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:42.703 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:43.234 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:03:44.142 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:44.142 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:44.143 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:03:44.143 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:47.272 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:47.272 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:03:47.273 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:47.288 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:47.292 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:47.301 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:47.343 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:47.592 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:47.592 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:47.592 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:03:48.025 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:03:48.099 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.81 seconds
2024-10-12 04:03:48.100 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:48.100 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:49.903 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:49.903 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:49.904 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:49.906 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:49.907 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:49.908 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:49.909 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:50.626 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:03:50.627 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:50.627 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:50.628 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:03:50.922 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:50.922 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:50.922 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:03:50.923 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:52.392 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:52.392 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:03:52.392 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:52.453 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:52.455 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:52.456 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:52.461 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:52.712 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:52.715 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:52.716 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:03:53.239 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:03:53.325 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.87 seconds
2024-10-12 04:03:53.326 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:53.326 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:03:54.182 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:03:54.182 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:03:54.183 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:03:54.184 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:03:54.187 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:03:54.187 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:03:54.204 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:03:54.952 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:03:54.953 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:03:54.953 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:03:54.979 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:03:55.058 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.87 seconds
2024-10-12 04:03:55.059 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:03:55.059 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:04:06.861 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:04:06.861 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:04:06.863 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:04:06.864 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:04:06.864 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:04:06.865 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:04:06.872 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:04:07.927 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.06 seconds
2024-10-12 04:04:07.929 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:04:07.929 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:04:07.931 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:04:10.122 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:04:10.122 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:04:10.122 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:04:10.122 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:04:17.862 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:04:17.862 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:04:17.863 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:04:17.895 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:04:17.898 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:04:17.899 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:04:17.932 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:04:18.714 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.82 seconds
2024-10-12 04:04:18.715 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:04:18.716 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:04:18.717 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:04:25.932 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:04:25.932 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:04:25.932 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:04:25.933 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:04:27.591 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:04:27.591 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:04:27.591 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:04:27.626 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:04:27.628 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:04:27.638 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:04:27.662 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:04:28.467 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.84 seconds
2024-10-12 04:04:28.468 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:04:28.468 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:04:28.470 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:04:28.551 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:04:28.551 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:04:28.551 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:04:28.552 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:04:33.542 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:04:33.543 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:04:33.543 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:04:33.607 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:04:33.611 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:04:33.613 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:04:33.628 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:04:34.476 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.86 seconds
2024-10-12 04:04:34.477 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:04:34.477 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:04:34.479 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:05:46.762 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:05:46.762 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:05:46.762 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:05:46.762 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:05:47.911 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:05:47.911 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:05:47.912 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:05:48.002 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:05:48.004 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:05:48.004 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:05:48.042 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:05:48.712 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.71 seconds
2024-10-12 04:05:48.713 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:05:48.713 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:05:48.714 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:05:50.731 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:05:50.732 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:05:50.732 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:05:50.732 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:00.202 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:00.202 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:00.203 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:00.237 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:00.240 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:00.241 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:00.262 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:01.101 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:01.102 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:01.102 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:06:01.140 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:06:01.206 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.97 seconds
2024-10-12 04:06:01.207 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:01.207 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:02.442 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:02.442 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:02.443 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:02.445 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:02.446 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:02.448 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:02.463 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:03.141 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:03.141 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:03.141 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:06:03.142 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:06:03.142 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:06:03.143 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:03.143 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:04.302 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:04.302 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:04.302 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:04.303 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:04.305 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:04.307 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:04.313 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:04.872 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:04.873 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:04.873 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:06:05.047 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:06:05.079 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.77 seconds
2024-10-12 04:06:05.080 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:05.080 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:10.072 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:10.072 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:10.073 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:10.075 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:10.077 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:10.078 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:10.079 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:10.512 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:10.512 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:10.512 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:06:10.960 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:06:11.021 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.94 seconds
2024-10-12 04:06:11.022 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:11.022 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:12.053 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:12.053 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:12.054 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:12.056 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:12.058 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:12.058 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:12.058 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:12.691 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:12.691 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:12.692 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:06:12.770 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:06:12.796 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.74 seconds
2024-10-12 04:06:12.797 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:12.797 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:13.841 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:13.841 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:13.841 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:13.843 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:13.844 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:13.846 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:13.846 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:14.508 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 04:06:14.509 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:14.509 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:14.512 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:14.871 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:14.872 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:14.872 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:14.872 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:16.022 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:16.022 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:16.023 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:16.078 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:16.082 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:16.082 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:16.083 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:16.736 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.65 seconds
2024-10-12 04:06:16.737 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:16.737 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:16.738 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:20.632 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:20.632 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:20.632 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:20.633 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:23.062 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:23.062 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:23.062 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:23.130 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:23.132 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:23.133 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:23.193 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:23.928 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.80 seconds
2024-10-12 04:06:23.929 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:23.929 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:23.930 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:25.042 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:25.042 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:25.042 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:25.042 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:29.461 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:29.461 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:29.462 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:29.479 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:29.482 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:29.498 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:29.522 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:30.368 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.89 seconds
2024-10-12 04:06:30.370 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:30.370 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:30.372 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:30.672 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:30.672 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:30.672 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:30.672 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:41.171 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:41.171 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:41.172 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:41.219 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:41.221 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:41.231 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:41.233 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:42.299 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.08 seconds
2024-10-12 04:06:42.299 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:42.300 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:42.301 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:43.991 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:43.991 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:43.991 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:43.992 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:47.892 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:47.892 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:47.893 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:47.915 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:47.917 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:47.917 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:47.951 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:48.906 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.99 seconds
2024-10-12 04:06:48.908 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:48.908 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:48.910 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:06:50.321 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:06:50.321 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:06:50.321 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:06:50.322 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:06:54.482 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:06:54.482 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:06:54.482 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:06:54.563 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:06:54.563 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:06:54.583 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:06:54.612 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:06:55.389 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.83 seconds
2024-10-12 04:06:55.390 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:06:55.390 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:06:55.392 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:07:08.432 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:08.432 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:08.432 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:07:08.433 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:11.512 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:11.512 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:07:11.512 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:11.643 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:11.650 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:11.661 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:11.701 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:12.453 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.80 seconds
2024-10-12 04:07:12.454 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:12.454 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:12.456 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:07:14.451 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:14.451 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:14.451 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:07:14.452 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:22.131 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:22.131 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:07:22.132 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:22.184 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:22.186 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:22.191 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:22.204 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:23.091 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:23.092 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:23.092 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:07:23.252 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:07:23.296 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.11 seconds
2024-10-12 04:07:23.297 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:23.297 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:24.501 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:24.501 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:24.502 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:24.503 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:24.504 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:24.506 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:24.513 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:25.393 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.89 seconds
2024-10-12 04:07:25.395 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:25.396 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:25.398 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:07:25.781 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:25.781 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:25.781 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:07:25.781 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:29.230 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:29.231 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:07:29.231 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:29.275 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:29.277 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:29.291 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:29.302 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:30.066 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.79 seconds
2024-10-12 04:07:30.067 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:30.067 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:30.069 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:07:35.631 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:35.632 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:35.632 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:07:35.632 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:39.351 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:39.351 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:07:39.352 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:39.392 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:39.394 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:39.411 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:39.414 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:40.315 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.92 seconds
2024-10-12 04:07:40.316 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:40.316 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:40.318 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:07:43.762 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:07:43.762 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:07:43.762 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:07:43.762 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:07:45.302 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:07:45.302 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:07:45.303 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:07:45.373 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:07:45.376 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:07:45.380 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:07:45.432 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:07:47.278 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.90 seconds
2024-10-12 04:07:47.279 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:07:47.279 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:07:47.281 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:08:13.331 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:13.331 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:13.331 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:08:13.331 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:14.991 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:14.991 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:08:14.991 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:15.044 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:15.046 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:15.048 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:15.061 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:16.186 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.14 seconds
2024-10-12 04:08:16.188 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:16.188 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:16.190 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:08:31.631 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:31.631 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:31.632 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:08:31.632 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:33.300 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:33.301 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:08:33.301 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:33.354 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:33.355 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:33.361 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:33.369 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:38.741 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:38.741 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:38.742 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:08:40.027 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:08:40.067 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 6.71 seconds
2024-10-12 04:08:40.068 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:40.068 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:43.281 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:43.281 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:43.281 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:43.282 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:43.284 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:43.284 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:43.285 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:44.282 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.00 seconds
2024-10-12 04:08:44.284 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:44.284 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:44.285 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:08:45.011 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:45.012 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:45.012 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:08:45.012 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:47.631 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:47.631 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:08:47.632 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:47.687 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:47.690 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:47.701 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:47.712 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:48.406 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:08:48.407 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:48.408 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:48.409 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:08:48.471 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:48.471 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:48.471 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:08:48.471 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:53.841 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:53.841 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:08:53.841 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:53.929 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:53.931 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:53.932 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:53.971 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:54.231 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:08:54.231 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:08:54.231 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:08:54.866 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:08:54.945 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.01 seconds
2024-10-12 04:08:54.946 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:54.946 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:08:58.391 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:08:58.391 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:58.391 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:08:58.392 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:08:58.393 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:08:58.395 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:08:58.395 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:08:59.174 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.78 seconds
2024-10-12 04:08:59.175 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:08:59.175 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:08:59.177 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:09:03.631 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:03.631 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:03.631 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:09:03.632 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:05.491 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:05.492 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:09:05.492 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:05.570 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:05.572 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:05.579 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:05.621 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:05.871 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:05.871 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:05.871 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:09:06.447 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:09:06.482 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.91 seconds
2024-10-12 04:09:06.485 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:06.485 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:08.691 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:08.691 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:08.691 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:08.691 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:08.692 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:08.693 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:08.704 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:10.742 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:10.742 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:10.742 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:09:11.868 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:09:11.880 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 3.19 seconds
2024-10-12 04:09:11.882 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:11.882 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:13.942 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:13.942 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:13.942 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:13.943 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:13.944 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:13.945 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:13.946 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:14.262 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:14.262 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:14.262 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:09:14.818 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:09:14.892 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.95 seconds
2024-10-12 04:09:14.894 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:14.894 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:16.371 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:16.371 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:16.372 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:16.373 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:16.374 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:16.375 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:16.382 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:16.751 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:16.751 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:16.751 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:09:17.250 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:09:17.261 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.89 seconds
2024-10-12 04:09:17.263 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:17.263 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:25.652 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:25.652 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:25.654 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:25.655 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:25.657 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:25.661 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:25.672 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:26.675 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.01 seconds
2024-10-12 04:09:26.676 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:26.676 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:26.677 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:09:27.121 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:27.121 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:27.121 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:09:27.121 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:28.271 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:28.271 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:09:28.272 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:28.330 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:28.332 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:28.342 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:28.345 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:29.132 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.80 seconds
2024-10-12 04:09:29.133 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:29.134 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:29.136 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:09:50.290 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:09:50.291 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:09:50.291 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:09:50.291 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:09:51.441 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:09:51.441 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:09:51.442 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:09:51.540 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:09:51.543 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:09:51.555 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:09:51.571 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:09:52.263 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:09:52.264 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:09:52.265 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:09:52.267 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:10:06.299 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 04:10:06.299 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 04:10:06.300 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 04:10:06.852 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 04:10:06.879 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 04:10:06.948 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 04:13:10.089 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:13:10.097 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:13:10.103 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:13:10.103 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:13:10.373 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:13:10.376 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:13:10.378 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:13:10.379 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:13:10.380 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:13:10.381 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:13:10.382 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:13:10.382 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:13:10.728 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:13:10.734 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:13:10.734 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:13:17.377 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:13:17.378 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:13:17.378 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:13:17.378 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:13:18.033 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:13:20.469 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:13:20.469 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:13:20.469 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:13:20.470 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:13:21.629 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:13:21.630 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:13:21.630 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:13:21.664 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:13:21.667 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:13:21.668 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:13:21.688 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:13:22.325 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 04:13:22.337 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': None}], 'model': 'gpt-4o'}}
2024-10-12 04:13:22.367 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:13:22.388 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002687FAE9A20>
2024-10-12 04:13:22.389 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002686A778840> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002687FAE99F0>
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:13:22.445 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:13:22.528 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 12 Oct 2024 09:13:23 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'15'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'130'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'8h19m42.989s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_019d0f93348066da6b7565facf420b93'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=M7tWgitD3nRxGtXZM5IonE2keV9KXgup_UoIAOceTYQ-1728724403-1.0.1.1-LT6rKGtlAMmHn6KcssFSYpJox6v6nhDR0TvLnCk2BnJwaLQibfkWjPwgOnLNQ4HW02eK6Pid13EGsUYQPkTHvw; path=/; expires=Sat, 12-Oct-24 09:43:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=NnpQMEP9kHg_f_2P.5mEW37fi6H0noY5zSQ4YmCggMk-1728724403457-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d15f94129bd424a-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:13:22.529 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2024-10-12 04:13:22.529 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:13:22.529 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:13:22.529 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:13:22.529 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:13:22.534 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"
2024-10-12 04:13:22.534 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-10-12 04:13:22.536 - RealTimeSTT: openai._base_client - DEBUG - Not retrying
2024-10-12 04:13:22.536 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-12 04:14:04.670 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:14:04.678 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:14:04.683 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:14:04.683 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:14:04.902 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:14:04.905 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:14:04.906 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:14:04.908 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:14:04.908 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:14:04.910 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:14:04.911 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:14:04.911 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:14:05.203 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:14:05.206 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:14:05.206 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:14:09.977 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:14:09.978 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:14:09.978 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:14:09.978 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:14:10.507 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:14:12.229 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:14:12.229 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:14:12.229 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:14:12.230 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:14:13.380 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:14:13.380 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:14:13.381 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:14:13.386 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:14:13.389 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:14:13.393 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:14:13.448 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:14:14.080 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:14:14.091 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': None}], 'model': 'gpt-4o'}}
2024-10-12 04:14:14.109 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:14:14.159 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E3A4749870>
2024-10-12 04:14:14.159 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E38F43C840> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:14:14.170 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E3A4749840>
2024-10-12 04:14:14.171 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:14:14.171 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:14:14.171 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:14:14.171 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:14:14.171 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:14:14.235 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 12 Oct 2024 09:14:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'14'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'129'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'8h26m3.266s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_ba485b33ab2fa8a5b061e31300094a6f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SrLADBffIS6bH.kZJVK.UTSpaZH95dBRTZg9340WUO0-1728724455-1.0.1.1-N9I3NY9SFqISQTXfDkZD4bqOK.i_WQcpYvWbxXJ9TndO5egPbMUYcieDWoCNpcPS068FrA8W3yW5ThsZ_N7tnA; path=/; expires=Sat, 12-Oct-24 09:44:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kq0dI.EUCSo_QA9wm6XHYPMSOQ3I1831tFdsG5rguL8-1728724455169-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d15fa847f1217b5-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:14:14.235 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2024-10-12 04:14:14.235 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:14:14.236 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:14:14.236 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:14:14.236 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:14:14.241 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"
2024-10-12 04:14:14.241 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-10-12 04:14:14.243 - RealTimeSTT: openai._base_client - DEBUG - Not retrying
2024-10-12 04:14:14.243 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-12 04:14:16.969 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:14:16.969 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:14:16.969 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:17:04.032 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:17:04.041 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:17:04.047 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:17:04.047 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:17:04.277 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:17:04.282 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:17:04.286 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:17:04.290 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:17:04.290 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:17:04.294 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:17:04.294 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:17:04.294 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:17:04.573 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:17:04.575 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:17:04.575 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:17:10.021 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:17:10.022 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:17:10.028 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:17:10.052 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:17:10.100 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6D5008D00>
2024-10-12 04:17:10.100 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F6C07A8840> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:17:10.121 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6D5008CD0>
2024-10-12 04:17:10.121 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:17:10.121 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:17:10.121 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:17:10.122 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:17:10.122 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:17:10.714 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:17:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'533'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'129'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'8h30m19.299s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_d580a81f1ad97104e5475848be6d5f54'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4kJmLzX7Aflodm4WHiTfDz7Hq3JzMgorY._1AIGsPQs-1728724631-1.0.1.1-nlFXqAtgsDlAXrZAoDl7mghJwX_kJXNuOSwUct3BwBg96gnbLGBazpQm7akxUhrliWuTyL1bG_DsgH_eHErVig; path=/; expires=Sat, 12-Oct-24 09:47:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=R3mq0r4OchAWKpjHKIjZ5aNLesc2vrMb3pl6cjh5P84-1728724631653-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d15fed029b942c7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:17:10.715 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:17:10.722 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:17:10.725 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:17:10.725 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:17:10.725 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:17:10.725 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:17:10.741 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:17:10.742 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:17:10.742 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:17:10.743 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:17:10.743 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:17:10.743 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:17:11.093 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:17:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'299'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'128'), (b'x-ratelimit-remaining-tokens', b'7951'), (b'x-ratelimit-reset-requests', b'8h37m30.686s'), (b'x-ratelimit-reset-tokens', b'12.293s'), (b'x-request-id', b'req_bff35792e598abb145aa5de778ff7e93'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d15fed41b6242c7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:17:11.094 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:17:11.094 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:17:11.095 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:17:11.095 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:17:11.095 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:17:11.095 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:18:13.796 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:18:13.804 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:18:13.810 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:18:13.810 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:18:14.067 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:18:14.070 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:18:14.072 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:18:14.074 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:18:14.075 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:18:14.077 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:18:14.077 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:18:14.077 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:18:14.404 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:18:14.406 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:18:14.406 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:18:19.191 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:18:19.192 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:18:19.192 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:18:19.192 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:18:19.842 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:18:21.074 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:18:21.075 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:18:21.075 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:18:21.075 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:18:22.225 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:18:22.225 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:18:22.226 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:18:22.323 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:18:22.331 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:18:22.350 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:18:22.354 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:18:23.034 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-10-12 04:18:23.047 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:18:23.068 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:18:23.101 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5836A99F0>
2024-10-12 04:18:23.101 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E582948840> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:18:23.114 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5836A99C0>
2024-10-12 04:18:23.115 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:18:23.115 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:18:23.115 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:18:23.116 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:18:23.116 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:18:23.687 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:18:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'127'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'8h43m30.305s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_770573774aadd3fbff2406f02e43087f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zMAzupgqcIw87BahryWp4mAqyLOnW1q0Dw7Y9TXCwQ0-1728724704-1.0.1.1-RXtXrn5QfDS4Xdoox9kTHXvwyOfmR21YwbzYHOiQ3uGBG10A4gEDTl2l7snsebv1vpsiUeO1oSa29r.HrYVBew; path=/; expires=Sat, 12-Oct-24 09:48:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=q1wd1icU7A9XXVHuhc5IUh4BZNpkPoQ93.x9QB22I0M-1728724704627-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1600986b2e424d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:18:23.688 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:18:23.688 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:18:23.689 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:18:23.690 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:18:23.690 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:18:23.690 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:18:23.693 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:18:23.693 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:18:23.695 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:18:27.024 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:18:27.024 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:18:27.024 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:18:27.025 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:18:29.073 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:18:29.074 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:18:29.074 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:18:29.150 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:18:29.153 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:18:29.153 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:18:29.204 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:18:31.164 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.01 seconds
2024-10-12 04:18:31.177 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:18:31.178 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:18:31.179 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:18:31.179 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:18:31.191 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5836331F0>
2024-10-12 04:18:31.191 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E582948840> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:18:31.204 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5836AB6A0>
2024-10-12 04:18:31.204 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:18:31.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:18:31.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:18:31.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:18:31.206 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:18:31.764 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:18:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'487'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'126'), (b'x-ratelimit-remaining-tokens', b'8877'), (b'x-ratelimit-reset-requests', b'8h50m34.215s'), (b'x-ratelimit-reset-tokens', b'6.738s'), (b'x-request-id', b'req_452d6ce8dfd74634d26d96afd16791d5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1600cafca8437a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:18:31.765 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:18:31.765 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:18:31.766 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:18:31.767 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:18:31.767 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:18:31.767 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:18:35.404 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:18:35.404 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:18:35.405 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:19:26.128 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:19:26.135 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:19:26.141 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:19:26.142 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:19:26.359 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:19:26.362 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:19:26.364 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:19:26.365 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:19:26.366 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:19:26.367 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:19:26.368 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:19:26.369 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:19:26.620 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:19:26.622 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:19:26.622 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:19:31.854 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:19:31.855 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:19:31.855 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:19:31.855 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:19:32.379 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:19:33.437 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:19:33.437 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:19:33.437 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:19:33.438 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:19:34.586 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:19:34.586 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:19:34.588 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:19:34.654 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:19:34.657 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:19:34.668 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:19:34.715 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:19:35.495 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.84 seconds
2024-10-12 04:19:35.502 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:19:35.523 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:19:35.556 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000279A6E39BD0>
2024-10-12 04:19:35.557 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027990B988C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:19:35.569 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000279A6E39BA0>
2024-10-12 04:19:35.569 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:19:35.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:19:35.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:19:35.570 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:19:35.570 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:19:36.043 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:19:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'125'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'8h56m41.858s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_54ac3cf815966cc49843103666f4c763'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ARX4yaUrKYCJnd.58n5.Hi3m7M8kFf_ors.JJC6U2_w-1728724776-1.0.1.1-fNuffdupOastoxm6wtkUh4wU7ImC8uu0nJhyvXZYtURbRI600wbltWpxch.QSxW69XWDYFvMSWRFM6x5Ohh54w; path=/; expires=Sat, 12-Oct-24 09:49:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cNOwuJnzuMnk2JrG0Nj1ydN2bG7KWZrOtU4kV793Pt8-1728724776983-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16025d4fb003d5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:19:36.045 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:19:36.045 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:19:36.046 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:19:36.046 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:19:36.046 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:19:36.046 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:19:36.051 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:19:36.051 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:19:36.052 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:19:37.656 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:19:37.656 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:19:37.656 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:19:37.657 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:19:40.156 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:19:40.157 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:19:40.158 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:19:40.244 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:19:40.246 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:19:40.247 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:19:40.275 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:19:40.932 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:19:40.942 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:19:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:19:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:19:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:19:40.945 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:19:40.945 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:19:41.302 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:19:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'304'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'124'), (b'x-ratelimit-remaining-tokens', b'8744'), (b'x-ratelimit-reset-requests', b'9h3m48.479s'), (b'x-ratelimit-reset-tokens', b'7.533s'), (b'x-request-id', b'req_15a190362a455e363f937a20acbe7fca'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16027edc6403d5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:19:41.302 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:19:41.303 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:19:41.303 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:19:41.304 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:19:41.304 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:19:41.304 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:19:49.306 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:19:49.307 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:19:49.307 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:20:27.808 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:20:27.815 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:20:27.821 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:20:27.821 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:20:28.069 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:20:28.072 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:20:28.074 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:20:28.076 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:20:28.076 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:20:28.079 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:20:28.079 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:20:28.080 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:20:28.338 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:20:28.341 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:20:28.341 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:20:33.196 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:20:33.197 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:20:33.197 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:20:33.197 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:20:33.715 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:20:35.068 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:20:35.068 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:20:35.068 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:20:35.069 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:20:36.227 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:20:36.228 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:20:36.229 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:20:36.241 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:20:36.243 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:20:36.244 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:20:36.287 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:20:36.868 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 04:20:36.876 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:20:36.892 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:20:36.926 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D0C2999AE0>
2024-10-12 04:20:36.926 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0AD6688C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:20:36.938 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D0C28D0940>
2024-10-12 04:20:36.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:20:36.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:20:36.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:20:36.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:20:36.939 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:20:37.357 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:20:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'123'), (b'x-ratelimit-remaining-tokens', b'8888'), (b'x-ratelimit-reset-requests', b'9h10m4.475s'), (b'x-ratelimit-reset-tokens', b'6.672s'), (b'x-request-id', b'req_febe2834cfa3161f092a7a848ab4dfee'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qNmL4T8AQg5BaEiGmqazcHfijLz7._nMEippe8li3r0-1728724838-1.0.1.1-XQmLxrH0cS4rcmop6mOAoGFIo_e_097I_cy5pzpL.CSsdAV9cs_pTLN5paP3w_2uD0Uamn2SPt8RAPGzqRuS1A; path=/; expires=Sat, 12-Oct-24 09:50:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=0Nd0uv1Mbw5ioX7FLrQrTZU.5rfqltNdQzsvhcyAfTg-1728724838301-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1603dcdd738ca5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:20:37.358 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:20:37.358 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:20:37.358 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:20:37.358 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:20:37.358 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:20:37.359 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:20:37.361 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:20:37.361 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:20:37.363 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:20:39.037 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:20:39.037 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:20:39.038 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:20:39.038 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:20:40.317 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:20:40.317 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:20:40.318 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:20:40.344 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:20:40.346 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:20:40.346 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:20:40.386 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:20:40.948 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-10-12 04:20:40.959 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! Would you like to get some food?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-4o'}}
2024-10-12 04:20:40.960 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:20:40.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:20:40.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:20:40.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:20:40.961 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:20:41.348 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:20:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'296'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'122'), (b'x-ratelimit-remaining-tokens', b'8525'), (b'x-ratelimit-reset-requests', b'9h17m12.43s'), (b'x-ratelimit-reset-tokens', b'8.849s'), (b'x-request-id', b'req_4d9ca6451bed1a8a4ab617b29a4a870a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1603f5ff598ca5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:20:41.348 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:20:41.349 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:20:41.349 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:20:41.349 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:20:41.349 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:20:41.349 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:20:45.567 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:20:45.567 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:20:45.567 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:21:56.318 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:21:56.326 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:21:56.331 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:21:56.332 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:21:56.595 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:21:56.598 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:21:56.599 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:21:56.601 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:21:56.601 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:21:56.603 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:21:56.604 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:21:56.604 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:21:56.871 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:21:56.873 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:21:56.874 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:22:01.551 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:22:01.552 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:22:01.552 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:22:01.553 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:22:02.083 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:22:03.429 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:22:03.430 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:22:03.430 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:22:03.430 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:22:04.589 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:22:04.589 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:22:04.590 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:22:04.608 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:22:04.610 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:22:04.618 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:22:04.648 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:22:05.252 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:22:05.253 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:22:05.253 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:22:05.255 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:22:19.370 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:22:19.370 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:22:19.370 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:22:19.370 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:22:20.519 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:22:20.519 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:22:20.520 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:22:20.608 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:22:20.611 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:22:20.612 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:22:20.648 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:22:21.167 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.56 seconds
2024-10-12 04:22:21.168 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:22:21.168 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:22:21.169 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:22:23.079 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:22:23.079 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:22:23.079 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:22:23.079 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:22:24.229 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:22:24.229 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:22:24.229 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:22:24.297 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:22:24.298 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:22:24.300 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:22:24.313 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:22:24.953 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.65 seconds
2024-10-12 04:22:24.954 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:22:24.954 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:22:24.955 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:22:28.139 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:22:28.139 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:22:28.139 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:22:28.139 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:22:30.438 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:22:30.438 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:22:30.439 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:22:30.458 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:22:30.460 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:22:30.460 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:22:30.508 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:22:31.161 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-10-12 04:22:31.162 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:22:31.163 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:22:31.163 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:23:20.313 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:23:20.323 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:23:20.329 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:23:20.329 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:23:20.618 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:23:20.621 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:20.623 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:23:20.625 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:20.626 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:23:20.628 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:20.629 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:23:20.629 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:23:20.909 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:23:20.911 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:23:20.911 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:23:54.815 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:23:54.827 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:23:54.836 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:23:54.837 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:23:55.094 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:23:55.097 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:55.098 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:23:55.100 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:55.101 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:23:55.102 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:23:55.103 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:23:55.103 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:23:55.380 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:23:55.382 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:23:55.382 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:24:00.342 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:24:00.343 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:24:00.343 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:24:00.343 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:24:00.859 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:24:02.419 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:24:02.419 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:24:02.419 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:24:02.420 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:24:03.568 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:24:03.569 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:24:03.570 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:24:03.635 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:24:03.639 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:24:03.659 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:24:03.698 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:24:04.993 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.35 seconds
2024-10-12 04:24:05.006 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 04:24:05.022 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:24:05.062 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B656B09AB0>
2024-10-12 04:24:05.062 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B641758940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:24:05.075 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B656ACB130>
2024-10-12 04:24:05.075 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:24:05.075 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:24:05.075 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:24:05.076 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:24:05.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:24:05.714 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:24:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'575'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'122'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'9h21m0.338s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_2ce394c7893f922bfb906e6404e8f791'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Nl7lSofDe_nXnNmT.IVDqjYq_F77N7IDbRN.mW7LAe4-1728725046-1.0.1.1-9RB43EBvVicmJP3e9HMak3r_XaxtmNAAAcX_NyXAGIkT2bRJvbSMAAabnwKYUmknBZ2Siobxk4M9N7iyDIv8aA; path=/; expires=Sat, 12-Oct-24 09:54:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VyPZN_3lc4uz_kjafs4jqmjClpMX3.cKIE93OUsDCo0-1728725046664-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1608f1b876176c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:24:05.715 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:24:05.716 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:24:05.720 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:24:05.720 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:24:05.720 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:24:05.720 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:24:05.723 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:24:05.724 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:24:05.725 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:24:07.409 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:24:07.409 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:24:07.409 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:24:07.409 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:24:09.459 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:24:09.459 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:24:09.460 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:24:09.514 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:24:09.517 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:24:09.518 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:24:09.518 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:24:10.176 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 04:24:10.187 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n    Now here are the conversations between a user and the assistant so far. Continue being the assistant\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Ja, und like to get some food.'}], 'model': 'gpt-4o'}}
2024-10-12 04:24:10.188 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:24:10.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:24:10.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:24:10.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:24:10.189 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:24:10.536 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:24:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'300'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'121'), (b'x-ratelimit-remaining-tokens', b'8689'), (b'x-ratelimit-reset-requests', b'9h28m7.23s'), (b'x-ratelimit-reset-tokens', b'7.863s'), (b'x-request-id', b'req_ce20bd6158909316310acd8e1a0695b5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160911adc4176c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:24:10.537 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:24:10.537 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:24:10.537 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:24:10.538 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:24:10.538 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:24:10.538 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:25:39.397 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:25:39.405 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:25:39.412 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:25:39.412 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:25:39.566 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:25:39.569 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:25:39.570 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:25:39.572 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:25:39.573 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:25:39.575 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:25:39.575 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:25:39.575 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:25:39.849 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:25:39.851 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:25:39.851 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:25:44.644 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:25:44.645 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:25:44.645 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:25:44.645 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:25:45.135 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:25:46.076 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:25:46.077 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:25:46.077 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:25:46.077 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:25:47.227 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:25:47.227 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:25:47.228 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:25:47.258 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:25:47.260 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:25:47.267 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:25:47.286 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:25:47.871 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 04:25:47.879 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for your responses\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 04:25:47.894 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:25:47.928 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101E49C30>
2024-10-12 04:25:47.928 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000191010E8940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:25:47.940 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101E49C00>
2024-10-12 04:25:47.941 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:25:47.941 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:25:47.941 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:25:47.941 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:25:47.941 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:25:48.408 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:25:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'120'), (b'x-ratelimit-remaining-tokens', b'8851'), (b'x-ratelimit-reset-requests', b'9h33m41.464s'), (b'x-ratelimit-reset-tokens', b'6.894s'), (b'x-request-id', b'req_9e2a0f3706687807892e60bc4a0619e9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7UT6BVPjh091QioNK4_QhKscyhhaFySpHRv6g8Ki.Hg-1728725149-1.0.1.1-vc5LE6wMDnzfsKmpjbdWFrPcS47K4Fs5SZGXv2pUcmX4HUDtYM4bdEkE4Mt_YbDSKEdbfJR7qEKUTrq3AAa7Yg; path=/; expires=Sat, 12-Oct-24 09:55:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TuaCEvC2nu5D3OFfGKVU4H5AIck4N_sASQ.0mNT5OH8-1728725149360-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160b74abb64231-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:25:48.410 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:25:48.410 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:25:48.411 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:25:48.411 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:25:48.411 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:25:48.411 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:25:48.416 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:25:48.416 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:25:48.419 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:25:49.716 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:25:49.716 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:25:49.716 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:25:49.716 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:25:51.837 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:25:51.837 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:25:51.838 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:25:51.858 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:25:51.862 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:25:51.866 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:25:51.896 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:25:52.565 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-10-12 04:25:52.576 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}], 'model': 'gpt-4o'}}
2024-10-12 04:25:52.578 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:25:52.579 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:25:52.579 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:25:52.579 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:25:52.579 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:25:52.977 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:25:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'119'), (b'x-ratelimit-remaining-tokens', b'8546'), (b'x-ratelimit-reset-requests', b'9h40m48.838s'), (b'x-ratelimit-reset-tokens', b'8.723s'), (b'x-request-id', b'req_d2f35fd66c32d88d4d800bfd3768d820'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160b91ac634231-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:25:52.978 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:25:52.978 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:25:52.979 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:25:52.979 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:25:52.979 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:25:52.979 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:25:52.980 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:25:52.980 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:25:52.981 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:25:55.736 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:25:55.736 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:25:55.737 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:25:55.737 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:25:58.676 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:25:58.677 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:25:58.677 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:25:58.693 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:25:58.695 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:25:58.717 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:25:58.746 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:25:59.407 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.71 seconds
2024-10-12 04:25:59.429 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'Um, what do you guys have in the menu?'}], 'model': 'gpt-4o'}}
2024-10-12 04:25:59.431 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:25:59.431 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:25:59.432 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:25:59.467 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101EA6FE0>
2024-10-12 04:25:59.467 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000191010E8940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:25:59.481 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101EA6F20>
2024-10-12 04:25:59.481 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:25:59.482 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:25:59.482 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:25:59.482 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:25:59.482 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:26:00.501 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:26:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'880'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'118'), (b'x-ratelimit-remaining-tokens', b'8592'), (b'x-ratelimit-reset-requests', b'9h47m53.932s'), (b'x-ratelimit-reset-tokens', b'8.442s'), (b'x-request-id', b'req_0adacc5ac49f72c02b3ae10abedc4508'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160bbccf98432e-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:26:00.502 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:26:00.502 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:26:00.503 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:26:00.503 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:26:00.503 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:26:00.503 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:26:00.504 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:26:00.504 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:26:00.507 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:26:03.736 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:26:03.736 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:26:03.736 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:26:03.736 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:26:06.426 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:26:06.426 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:26:06.426 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:26:06.519 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:26:06.522 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:26:06.532 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:26:06.557 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:26:07.166 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:26:07.187 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'Um, what do you guys have in the menu?'}, {'role': 'assistant', 'content': 'We have a variety of meals including Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog. What would you like to have?'}, {'role': 'user', 'content': 'Can I get it big and cheeseburger?'}], 'model': 'gpt-4o'}}
2024-10-12 04:26:07.189 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:26:07.190 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:26:07.190 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:26:07.198 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101EAE6E0>
2024-10-12 04:26:07.199 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000191010E8940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:26:07.211 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019101EAE290>
2024-10-12 04:26:07.211 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:26:07.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:26:07.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:26:07.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:26:07.212 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:26:07.253 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:26:08 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'117'), (b'x-ratelimit-remaining-tokens', b'8654'), (b'x-ratelimit-reset-requests', b'9h54m58.204s'), (b'x-ratelimit-reset-tokens', b'8.075s'), (b'x-request-id', b'req_b0a1fb1c3aecb533f23b9aa6fefabe60'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160bed19b9c434-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:26:07.253 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:26:07.253 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:26:07.253 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:26:07.253 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:26:07.254 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:26:07.254 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:26:07.254 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:26:07.262 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:26:07.262 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:26:07.262 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:26:27.262 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'Um, what do you guys have in the menu?'}, {'role': 'assistant', 'content': 'We have a variety of meals including Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog. What would you like to have?'}, {'role': 'user', 'content': 'Can I get it big and cheeseburger?'}], 'model': 'gpt-4o'}}
2024-10-12 04:26:27.264 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:26:27.265 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:26:27.265 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:26:27.285 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019102EF4160>
2024-10-12 04:26:27.285 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000191010E8940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019102EF4130>
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:26:27.311 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:26:28.542 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:26:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1176'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'116'), (b'x-ratelimit-remaining-tokens', b'8740'), (b'x-ratelimit-reset-requests', b'10h1m50.101s'), (b'x-ratelimit-reset-tokens', b'7.56s'), (b'x-request-id', b'req_cf8d44da3bd8358d43e711bbf2368fbb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160c6abcb47ca8-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:26:28.543 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:26:28.543 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:26:28.544 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:26:28.544 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:26:28.544 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:26:28.544 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:27:19.426 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:27:19.434 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:27:19.439 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:27:19.439 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:27:19.573 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:27:19.576 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:27:19.577 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:27:19.579 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:27:19.580 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:27:19.582 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:27:19.582 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:27:19.582 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:27:19.854 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:27:19.857 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:27:19.857 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:27:24.917 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:27:24.918 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:27:24.918 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:27:24.918 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:27:25.430 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:27:28.683 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:27:28.683 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:27:28.683 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:27:28.684 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:27:32.073 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:27:32.073 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:27:32.074 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:27:32.151 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:27:32.153 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:27:32.155 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:27:32.202 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:27:32.882 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.73 seconds
2024-10-12 04:27:32.890 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}], 'model': 'gpt-4o'}}
2024-10-12 04:27:32.904 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:27:32.925 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B2593CB2E0>
2024-10-12 04:27:32.925 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24410C940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:27:32.939 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B2594099F0>
2024-10-12 04:27:32.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:27:32.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:27:32.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:27:32.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:27:32.940 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:27:33.570 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:27:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'115'), (b'x-ratelimit-remaining-tokens', b'8843'), (b'x-ratelimit-reset-requests', b'10h7m56.471s'), (b'x-ratelimit-reset-tokens', b'6.942s'), (b'x-request-id', b'req_70addd69c10e537347fe01bab8012e01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=d508b_aX_3it5d_SJy0niEz_rHjc7VuIQWEnrD57w20-1728725254-1.0.1.1-Up92z2xXZUfWNLrTGUzGQVOrbVPRi5GKdEAs73QBsBYTl03ZFc9rF.Qd3v9oDOzviRGm_dHXJpTt2b0gj4ENzA; path=/; expires=Sat, 12-Oct-24 09:57:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=LXDz_rs3QM3VyyBtO8FYZkPRr6D3U4RgX9D21iEeYEo-1728725254525-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160e04ebfa7ce4-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:27:33.572 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:27:33.573 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:27:33.574 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:27:33.574 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:27:33.574 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:27:33.574 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:27:33.578 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:27:33.578 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:27:33.580 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:27:36.873 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:27:36.873 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:27:36.873 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:27:36.873 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:27:38.663 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:27:38.663 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:27:38.664 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:27:38.727 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:27:38.730 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:27:38.733 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:27:38.737 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:27:39.407 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-10-12 04:27:39.417 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}], 'model': 'gpt-4o'}}
2024-10-12 04:27:39.424 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:27:39.424 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:27:39.425 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:27:39.437 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B259465C60>
2024-10-12 04:27:39.437 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24410C940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:27:39.449 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B259465C30>
2024-10-12 04:27:39.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:27:39.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:27:39.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:27:39.450 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:27:39.450 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:27:40.001 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:27:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'494'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'114'), (b'x-ratelimit-remaining-tokens', b'8804'), (b'x-ratelimit-reset-requests', b'10h15m1.962s'), (b'x-ratelimit-reset-tokens', b'7.176s'), (b'x-request-id', b'req_74d0b12cd24e6f5d365ec1ec1b3922b5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160e2d98254362-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:27:40.002 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:27:40.002 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:27:40.003 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:27:40.003 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:27:40.003 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:27:40.003 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:27:40.005 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:27:40.005 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:27:40.008 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:27:42.313 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:27:42.313 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:27:42.313 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:27:42.314 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:27:44.103 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:27:44.103 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:27:44.104 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:27:44.152 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:27:44.155 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:27:44.155 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:27:44.172 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:27:44.493 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:27:44.493 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:27:44.493 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:27:44.806 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:27:44.898 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.74 seconds
2024-10-12 04:27:44.910 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}], 'model': 'gpt-4o'}}
2024-10-12 04:27:44.912 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:27:44.913 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:27:44.913 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:27:44.913 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:27:44.913 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:27:45.453 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'113'), (b'x-ratelimit-remaining-tokens', b'8561'), (b'x-ratelimit-reset-requests', b'10h22m8.502s'), (b'x-ratelimit-reset-tokens', b'8.633s'), (b'x-request-id', b'req_4bc6114b6bbb7eb17923fdb1f7c0ff6e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160e4fbb2a4362-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:27:45.454 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:27:45.454 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:27:45.455 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:27:45.455 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:27:45.455 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:27:45.455 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:27:45.456 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:27:45.457 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:27:46.214 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:27:46.214 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:27:46.215 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:27:46.216 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:27:46.218 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:27:46.219 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:27:46.223 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:27:46.914 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.70 seconds
2024-10-12 04:27:46.936 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}], 'model': 'gpt-4o'}}
2024-10-12 04:27:46.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:27:46.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:27:46.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:27:46.939 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:27:46.939 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:27:46.980 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:27:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'112'), (b'x-ratelimit-remaining-tokens', b'7731'), (b'x-ratelimit-reset-requests', b'10h29m18.471s'), (b'x-ratelimit-reset-tokens', b'13.611s'), (b'x-request-id', b'req_26b13b9ef00902ff5eed20d684e60970'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160e5c6b824362-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:27:46.981 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:27:46.981 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:27:46.981 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:27:46.981 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:27:46.981 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:27:46.982 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:27:46.982 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:27:46.983 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:27:46.983 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:27:46.983 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:27:50.762 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:27:50.762 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:27:50.763 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:28:06.983 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}], 'model': 'gpt-4o'}}
2024-10-12 04:28:06.985 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:28:06.985 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:28:06.985 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:28:07.009 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25A494700>
2024-10-12 04:28:07.009 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24410C940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:28:07.024 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25A4946D0>
2024-10-12 04:28:07.025 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:28:07.025 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:28:07.025 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:28:07.025 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:28:07.025 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:28:07.692 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'613'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'111'), (b'x-ratelimit-remaining-tokens', b'8760'), (b'x-ratelimit-reset-requests', b'10h36m10.384s'), (b'x-ratelimit-reset-tokens', b'7.44s'), (b'x-request-id', b'req_a574d73ec8ec3100d32d98dc2de93c1a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160ed9fe2e1988-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:28:07.692 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:28:07.693 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:28:07.693 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:28:07.693 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:28:07.693 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:28:07.693 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:28:07.694 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:28:07.694 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:28:08.422 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:28:08.423 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:28:08.425 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:28:08.498 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:28:08.498 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:28:08.506 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:28:08.553 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:28:11.113 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:28:11.113 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:28:11.113 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:28:12.614 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:28:12.632 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 4.13 seconds
2024-10-12 04:28:12.658 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}, {'role': 'assistant', 'content': 'All set! Would you like to order anything else?'}, {'role': 'user', 'content': "No. No. No. I don't want anything else."}], 'model': 'gpt-4o'}}
2024-10-12 04:28:12.659 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:28:12.660 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:28:12.660 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:28:12.660 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:28:12.660 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:28:12.712 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:28:13 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'110'), (b'x-ratelimit-remaining-tokens', b'8494'), (b'x-ratelimit-reset-requests', b'10h43m16.744s'), (b'x-ratelimit-reset-tokens', b'9.035s'), (b'x-request-id', b'req_f871f44af111b76382b42cfa553ae8e1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160efd2f3b1988-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:28:12.712 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:28:12.712 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:28:12.712 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:28:12.712 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:28:12.712 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:28:12.712 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:28:12.713 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:28:12.713 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:28:12.713 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:28:12.713 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:28:32.713 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}, {'role': 'assistant', 'content': 'All set! Would you like to order anything else?'}, {'role': 'user', 'content': "No. No. No. I don't want anything else."}], 'model': 'gpt-4o'}}
2024-10-12 04:28:32.715 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:28:32.716 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:28:32.716 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:28:32.753 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25A4A2770>
2024-10-12 04:28:32.753 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24410C940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:28:32.765 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25946EBF0>
2024-10-12 04:28:32.766 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:28:32.766 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:28:32.766 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:28:32.766 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:28:32.766 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:28:33.453 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:28:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'636'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'109'), (b'x-ratelimit-remaining-tokens', b'8736'), (b'x-ratelimit-reset-requests', b'10h50m8.645s'), (b'x-ratelimit-reset-tokens', b'7.584s'), (b'x-request-id', b'req_a69054e857f4663b1d23b64091f86dbd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160f7addab8cca-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:28:33.453 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:28:33.454 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:28:33.455 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:28:33.455 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:28:33.455 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:28:33.455 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:28:33.456 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:28:33.456 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:28:34.213 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:28:34.213 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:28:34.215 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:28:34.217 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:28:34.220 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:28:34.229 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:28:34.283 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:28:35.209 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.99 seconds
2024-10-12 04:28:35.248 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}, {'role': 'assistant', 'content': 'All set! Would you like to order anything else?'}, {'role': 'user', 'content': "No. No. No. I don't want anything else."}, {'role': 'assistant', 'content': 'All right! Is that all?'}, {'role': 'user', 'content': 'No, I would not like to order anything else. Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 04:28:35.250 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:28:35.251 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:28:35.251 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:28:35.251 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:28:35.251 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:28:35.921 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'622'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'108'), (b'x-ratelimit-remaining-tokens', b'7920'), (b'x-ratelimit-reset-requests', b'10h57m18.16s'), (b'x-ratelimit-reset-tokens', b'12.479s'), (b'x-request-id', b'req_2c3f451b5bc532a49eb0f2258d7e29b1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d160f8a5dc18cca-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:28:35.922 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:28:35.922 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:28:35.923 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:28:35.923 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:28:35.923 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:28:35.923 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:28:35.924 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:28:35.924 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:28:35.927 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:28:48.043 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:28:48.043 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:28:48.043 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:28:48.044 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:28:49.773 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:28:49.773 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:28:49.774 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:28:49.814 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:28:49.816 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:28:49.817 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:28:49.834 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:28:50.534 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:28:50.534 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:28:50.535 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:28:50.536 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:28:54.313 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:28:54.313 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:28:54.313 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:28:54.313 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:28:58.153 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:28:58.153 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:28:58.154 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:28:58.208 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:28:58.210 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:28:58.211 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:28:58.212 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:28:58.793 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:28:58.793 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:28:58.793 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:28:58.934 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:28:58.996 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.79 seconds
2024-10-12 04:28:59.028 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'I would like to order cheeseburger.'}, {'role': 'assistant', 'content': 'We have a Bacon Cheeseburger which comes with beef patty, bacon, cheese, and lettuce. Would you like to order that?'}, {'role': 'user', 'content': 'Yes, I would like to order that.'}, {'role': 'assistant', 'content': 'Would you like any customizations or anything else with your Bacon Cheeseburger?'}, {'role': 'user', 'content': 'Yes, and extra cheese and.'}, {'role': 'assistant', 'content': 'Got it. Would you like anything else?'}, {'role': 'user', 'content': 'And onions as well.'}, {'role': 'assistant', 'content': 'All set! Would you like to order anything else?'}, {'role': 'user', 'content': "No. No. No. I don't want anything else."}, {'role': 'assistant', 'content': 'All right! Is that all?'}, {'role': 'user', 'content': 'No, I would not like to order anything else. Hello.'}, {'role': 'assistant', 'content': 'All right!'}, {'role': 'user', 'content': 'Thank you so much for watching!'}], 'model': 'gpt-4o'}}
2024-10-12 04:28:59.030 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:28:59.030 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:28:59.031 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:28:59.043 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25A4B14E0>
2024-10-12 04:28:59.043 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24410C940> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:28:59.054 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B25A4AF7C0>
2024-10-12 04:28:59.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:28:59.055 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:28:59.055 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:28:59.055 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:28:59.055 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:28:59.728 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:29:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'614'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'107'), (b'x-ratelimit-remaining-tokens', b'8704'), (b'x-ratelimit-reset-requests', b'11h4m6.345s'), (b'x-ratelimit-reset-tokens', b'7.776s'), (b'x-request-id', b'req_6151ef7964663c921296efee233f10eb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16101f2b6641ef-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:28:59.728 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:28:59.728 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:28:59.729 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:28:59.729 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:28:59.729 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:28:59.729 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:29:41.396 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:29:41.403 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:29:41.408 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:29:41.409 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:29:41.656 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:29:41.658 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:29:41.660 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:29:41.662 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:29:41.662 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:29:41.664 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:29:41.665 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:29:41.665 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:29:41.919 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:29:41.921 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:29:41.922 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:29:46.813 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:29:46.814 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:29:46.815 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:29:46.815 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:29:47.343 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:29:50.758 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:29:50.759 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:29:50.759 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:29:50.759 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:29:51.909 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:29:51.909 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:29:51.910 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:29:51.982 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:29:51.984 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:29:51.985 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:29:52.038 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:29:53.326 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.34 seconds
2024-10-12 04:29:53.336 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 04:29:53.349 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:29:53.362 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A8747B310>
2024-10-12 04:29:53.362 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020A867388C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:29:53.373 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A874B9A80>
2024-10-12 04:29:53.373 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:29:53.374 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:29:53.374 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:29:53.374 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:29:53.374 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:29:53.984 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:29:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'106'), (b'x-ratelimit-remaining-tokens', b'8850'), (b'x-ratelimit-reset-requests', b'11h10m24.034s'), (b'x-ratelimit-reset-tokens', b'6.9s'), (b'x-request-id', b'req_41325a8e1967c68954ae44fdd68e2482'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4U1Its2C.QrFEj9.wZtUqq7Xdj3O9iI2Le7RkrRF_aU-1728725394-1.0.1.1-8wi0Nnz3B26zcq0UvIFSk3yvIA4vbXIG.9fsRzPBhnIssSM3AXxAsPzESiDNRsyToMW12zprie3ekYc0p54z4w; path=/; expires=Sat, 12-Oct-24 09:59:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ptySm5fMY6YXIfMqAQLiSm9uZRGPISiUcn0pBjx9i3M-1728725394943-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161172aacc0fa9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:29:53.985 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:29:53.985 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:29:53.986 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:29:53.986 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:29:53.986 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:29:53.986 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:29:53.989 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:29:53.990 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:29:53.992 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:29:55.749 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:29:55.750 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:29:55.750 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:29:55.750 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:29:58.058 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:29:58.059 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:29:58.060 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:29:58.089 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:29:58.092 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:29:58.114 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:29:58.118 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:29:58.731 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:29:58.742 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would you like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like a.'}], 'model': 'gpt-4o'}}
2024-10-12 04:29:58.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:29:58.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:29:58.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:29:58.745 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:29:58.745 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:29:59.267 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:30:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'105'), (b'x-ratelimit-remaining-tokens', b'8670'), (b'x-ratelimit-reset-requests', b'11h17m30.664s'), (b'x-ratelimit-reset-tokens', b'7.974s'), (b'x-request-id', b'req_a733614a0c8978824cf0f0fee94c34a4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1611943ab90fa9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:29:59.268 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:29:59.268 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:29:59.269 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:29:59.269 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:29:59.269 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:29:59.269 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:29:59.271 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:29:59.271 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:29:59.274 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:30:02.788 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:30:02.788 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:30:02.789 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:30:02.789 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:30:03.949 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:30:03.949 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:30:03.950 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:30:04.011 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:30:04.013 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:30:04.035 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:30:04.068 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:30:05.462 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.45 seconds
2024-10-12 04:30:05.479 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:\n    {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {},  # No modifications\n        ...\n    }\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: \n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"Gotcha. Would like anything else?"\n        }\n\n        User Input: "No that\'s it."\n        Assistant Reply:\n        {"ORDER":\n        {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output":"DONE"\n        }\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:\n        {"ORDER":\n        {\n        },\n        "output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"\n        }\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:\n        {"ORDER":\n            {},\n         "output":"Yes we do! Do you just want a regular burger then?"\n        }\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n          "output":"Do you just want 1 piece of extra cheese or more?"\n        }\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 1},\n            },\n            "output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"\n        }\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right! Is that all?"\n        }\n\n        User Input:"Yes bitch"\n        Assistant Reply:\n        {"ORDER":\n            {"Burger":{"Cheese": 2},\n            },\n            "output":"All right!"\n        }\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"Hello! Would like to get some food?"\n        }      \n\n        User Input: "Hell no!"\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"\n        }      \n\n        User Input: ""\n        Assistant Reply:\n        {"ORDER":\n            {\n            },\n            "output":"DONE"\n        }      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format \n        {"ORDER":\n            {...\n            },\n            "output":...\n        }  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would you like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like a.'}, {'role': 'assistant', 'content': "Sure! Could you please specify what you'd like to order?"}, {'role': 'user', 'content': 'I burger.'}], 'model': 'gpt-4o'}}
2024-10-12 04:30:05.481 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:30:05.482 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:30:05.482 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:30:05.509 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A87516440>
2024-10-12 04:30:05.509 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020A867388C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:30:05.520 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A87516410>
2024-10-12 04:30:05.520 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:30:05.520 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:30:05.521 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:30:05.521 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:30:05.521 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:30:06.014 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:30:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'104'), (b'x-ratelimit-remaining-tokens', b'8698'), (b'x-ratelimit-reset-requests', b'11h24m35.874s'), (b'x-ratelimit-reset-tokens', b'7.808s'), (b'x-request-id', b'req_7d4c5a123a0a82ad186c2a025c5b840b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1611be89550cb1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:30:06.015 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:30:06.015 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:30:06.015 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:30:06.015 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:30:06.015 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:30:06.016 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:31:35.978 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:31:35.978 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:31:35.978 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:35:59.296 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:35:59.305 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:35:59.313 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:35:59.313 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:35:59.565 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:35:59.570 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:35:59.574 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:35:59.578 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:35:59.579 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:35:59.582 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:35:59.583 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:35:59.583 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:35:59.964 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:35:59.967 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:35:59.967 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:36:24.595 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:36:24.603 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:36:24.608 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:36:24.608 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:36:24.857 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:36:24.861 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:36:24.863 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:36:24.864 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:36:24.865 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:36:24.867 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:36:24.867 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:36:24.867 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:36:25.122 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:36:25.124 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:36:25.124 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:36:30.002 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:36:30.003 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:36:30.004 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:36:30.004 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:36:30.662 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:36:31.807 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:36:31.807 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:36:31.807 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:36:31.808 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:36:32.956 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:36:32.956 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:36:32.957 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:36:33.037 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:36:33.040 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:36:33.045 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:36:33.086 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:36:34.366 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.33 seconds
2024-10-12 04:36:34.378 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 04:36:34.396 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:36:34.431 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD679CF0>
2024-10-12 04:36:34.431 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C8973647C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:36:34.444 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD679CC0>
2024-10-12 04:36:34.444 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:36:34.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:36:34.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:36:34.445 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:36:34.445 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:36:34.965 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:36:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'458'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'104'), (b'x-ratelimit-remaining-tokens', b'9036'), (b'x-ratelimit-reset-requests', b'11h25m18.952s'), (b'x-ratelimit-reset-tokens', b'5.784s'), (b'x-request-id', b'req_a8517520cf00acbd552558a0dd7cb284'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XI4S5v.B767.QKq60Z.GnXmNEBEL7k6jbctmxEgSvpc-1728725795-1.0.1.1-sULpx5DBcRCEfv6UbgJWA12zsQKOtP02Geu9B3BFXVMxgIZlNJCMty9beED39niPkA_9kGuVX9A5r1aeXyoseQ; path=/; expires=Sat, 12-Oct-24 10:06:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=0R9Zakx6LINRflxFLRIoQ_v_gM7AI0Ca616mKSKqElg-1728725795935-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161b3d6a180cba-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:36:34.966 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:36:34.966 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:36:34.967 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:36:34.967 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:36:34.967 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:36:34.967 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:36:34.977 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}], 'model': 'gpt-4o'}}
2024-10-12 04:36:34.978 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:36:34.978 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:36:34.978 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:36:34.978 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:36:34.978 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:36:35.342 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:36:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'314'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'103'), (b'x-ratelimit-remaining-tokens', b'8149'), (b'x-ratelimit-reset-requests', b'11h32m30.418s'), (b'x-ratelimit-reset-tokens', b'11.105s'), (b'x-request-id', b'req_ecc4bdb6bf1c93c213d04e60a0b8cb27'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161b40bb6e0cba-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:36:35.343 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:36:35.343 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:36:35.344 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:36:35.344 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:36:35.344 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:36:35.344 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:36:35.346 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:36:35.346 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:36:35.349 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:36:37.436 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:36:37.436 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:36:37.436 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:36:37.437 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:36:39.996 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:36:39.996 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:36:39.997 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:36:40.052 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:36:40.056 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:36:40.057 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:36:40.066 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:36:40.743 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:36:40.755 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}], 'model': 'gpt-4o'}}
2024-10-12 04:36:40.756 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:36:40.757 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:36:40.757 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:36:40.765 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD67A1A0>
2024-10-12 04:36:40.766 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C8973647C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:36:40.795 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD6D62F0>
2024-10-12 04:36:40.796 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:36:40.796 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:36:40.797 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:36:40.797 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:36:40.797 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:36:41.266 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:36:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'414'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'102'), (b'x-ratelimit-remaining-tokens', b'8120'), (b'x-ratelimit-reset-requests', b'11h39m36.593s'), (b'x-ratelimit-reset-tokens', b'11.274s'), (b'x-request-id', b'req_f83bd67d5a3054c260f7c9ccb37f5036'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161b651de88c0f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:36:41.267 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:36:41.267 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:36:41.268 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:36:41.268 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:36:41.268 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:36:41.268 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:36:41.281 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}], 'model': 'gpt-4o'}}
2024-10-12 04:36:41.282 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:36:41.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:36:41.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:36:41.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:36:41.283 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:36:41.320 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:36:42 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'101'), (b'x-ratelimit-remaining-tokens', b'7175'), (b'x-ratelimit-reset-requests', b'11h46m48.119s'), (b'x-ratelimit-reset-tokens', b'16.944s'), (b'x-request-id', b'req_0f0e209ad4b090a55e479dd0848068d9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161b682f548c0f-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:36:41.321 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:36:41.321 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:36:41.321 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:36:41.321 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:36:41.321 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:36:41.321 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:36:41.321 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:36:41.329 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:36:41.329 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:36:41.329 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:37:01.330 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}], 'model': 'gpt-4o'}}
2024-10-12 04:37:01.332 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:37:01.333 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:37:01.333 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:37:01.347 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD6E2620>
2024-10-12 04:37:01.347 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C8973647C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD6E25F0>
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:37:01.360 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:37:01.798 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:37:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'100'), (b'x-ratelimit-remaining-tokens', b'8983'), (b'x-ratelimit-reset-requests', b'11h53m40.033s'), (b'x-ratelimit-reset-tokens', b'6.102s'), (b'x-request-id', b'req_035079699a74a2bdffef44e69acaca87'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161be5ad878c18-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:37:01.799 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:37:01.799 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:37:01.800 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:37:01.800 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:37:01.800 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:37:01.800 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:37:01.802 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:37:01.802 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:37:01.804 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:37:06.046 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:37:06.046 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:37:06.046 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:37:06.047 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:37:08.416 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:37:08.417 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:37:08.418 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:37:08.670 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:37:08.672 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:37:08.673 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:37:08.735 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:37:09.348 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 04:37:09.368 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': "I'm gonna have a burger."}], 'model': 'gpt-4o'}}
2024-10-12 04:37:09.370 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:37:09.371 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:37:09.371 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:37:09.391 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD6E39D0>
2024-10-12 04:37:09.391 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C8973647C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:37:09.402 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD7325F0>
2024-10-12 04:37:09.402 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:37:09.403 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:37:09.403 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:37:09.403 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:37:09.403 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:37:09.448 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:37:10 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'99'), (b'x-ratelimit-remaining-tokens', b'8966'), (b'x-ratelimit-reset-requests', b'12h0m43.988s'), (b'x-ratelimit-reset-tokens', b'6.204s'), (b'x-request-id', b'req_e37548c7bc7f631be39ba500cc31b716'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161c17ea5f431c-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:37:09.449 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:37:09.449 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:37:09.449 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:37:09.449 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:37:09.449 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:37:09.449 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:37:09.449 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:37:09.450 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:37:09.450 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:37:09.450 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:37:29.450 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': "I'm gonna have a burger."}], 'model': 'gpt-4o'}}
2024-10-12 04:37:29.452 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:37:29.453 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:37:29.453 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:37:29.497 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD733910>
2024-10-12 04:37:29.497 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C8973647C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C8AD6E3C40>
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:37:29.512 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:37:29.974 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:37:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'404'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'98'), (b'x-ratelimit-remaining-tokens', b'8966'), (b'x-ratelimit-reset-requests', b'12h7m35.877s'), (b'x-ratelimit-reset-tokens', b'6.204s'), (b'x-request-id', b'req_b6ee8ba586bb4bc92215dc022fb81180'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161c9599c04234-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:37:29.975 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:37:29.976 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:37:29.976 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:37:29.976 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:37:29.976 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:37:29.977 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:37:29.995 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Hello! Would like to get some food?'}, {'role': 'user', 'content': 'Yes, I would like to get some food.'}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': "I'm gonna have a burger."}, {'role': 'user', 'content': 'respond only with the syntax: {{"ORDER":{{...}},"output":...}}'}], 'model': 'gpt-4o'}}
2024-10-12 04:37:29.996 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:37:29.996 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:37:29.997 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:37:29.997 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:37:29.997 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:37:30.034 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:37:31 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'97'), (b'x-ratelimit-remaining-tokens', b'7972'), (b'x-ratelimit-reset-requests', b'12h14m47.401s'), (b'x-ratelimit-reset-tokens', b'12.165s'), (b'x-request-id', b'req_f18dcf58c740dd8f4f8627ee2dd92107'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d161c989b5d4234-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:37:30.034 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:37:30.035 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:37:30.035 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:37:30.035 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:37:30.035 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:37:30.036 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:37:30.036 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:37:30.036 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:37:30.036 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:37:30.036 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:39:58.080 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:39:58.088 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:39:58.093 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:39:58.093 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:39:58.230 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:39:58.235 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:39:58.237 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:39:58.240 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:39:58.241 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:39:58.244 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:39:58.244 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:39:58.245 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:39:58.594 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:39:58.596 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:39:58.596 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:40:03.705 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:40:03.706 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:40:03.706 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:40:03.706 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:40:04.350 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:40:05.451 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:40:05.451 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:40:05.451 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:40:05.451 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:40:06.600 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:40:06.601 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:40:06.601 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:40:06.622 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:40:06.624 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:40:06.644 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:40:06.670 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:40:08.081 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.46 seconds
2024-10-12 04:40:08.091 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4-0314'}}
2024-10-12 04:40:08.124 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:40:08.133 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000238E03E9C30>
2024-10-12 04:40:08.134 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000238CB0687C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:40:08.145 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000238E03E9C00>
2024-10-12 04:40:08.145 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:40:08.145 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:40:08.145 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:40:08.146 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:40:08.146 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:40:08.191 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Date', b'Sat, 12 Oct 2024 09:40:09 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_b420ae895aa72b735585078ea52880fe'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lZrwRWT6xPWmvwpJ2HC54D_52i2s5Z.iaqnhsr6_BhA-1728726009-1.0.1.1-JSljbGHCqyFCTtabZqklV2EwX3OgE9aeiuVSGCqouXlghTlbnUz3LrWY.FI2jsREV_yOwsIml5qQ0EzadCqkKQ; path=/; expires=Sat, 12-Oct-24 10:10:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5grXYYlhz4w5MCIV1dPXFfPG5pr5yOaXXhTQNMXLVqU-1728726009168-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1620751a6441af-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:40:08.192 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 404 Not Found"
2024-10-12 04:40:08.192 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:40:08.193 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:40:08.193 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:40:08.193 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:40:08.193 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "404 Not Found"
2024-10-12 04:40:08.193 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
2024-10-12 04:40:08.199 - RealTimeSTT: openai._base_client - DEBUG - Not retrying
2024-10-12 04:40:08.199 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-12 04:40:55.411 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:40:55.418 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:40:55.424 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:40:55.424 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:40:55.708 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:40:55.711 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:40:55.713 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:40:55.715 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:40:55.715 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:40:55.717 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:40:55.717 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:40:55.718 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:40:55.986 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:40:55.988 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:40:55.988 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:41:00.733 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:41:00.733 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:41:00.734 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:41:00.734 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:41:01.262 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:41:02.423 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:41:02.423 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:41:02.423 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:41:02.424 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:41:04.023 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:41:04.023 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:41:04.024 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:41:04.046 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:41:04.049 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:41:04.055 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:41:04.092 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:41:04.647 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.59 seconds
2024-10-12 04:41:04.655 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:41:04.670 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:41:04.682 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AFCA1F9BA0>
2024-10-12 04:41:04.682 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AFB4E087C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:41:04.694 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AFCA1F9B70>
2024-10-12 04:41:04.694 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:41:04.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:41:04.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:41:04.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:41:04.695 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:41:05.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:41:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'597'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'59036'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'964ms'), (b'x-request-id', b'req_379c0f1278268cafb73466828faca761'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CYqrCHRnrqMZQVX5CWDPWPgYp31eTm8YLqvlmEHfbCk-1728726066-1.0.1.1-oomtzFDa6ZnYQHpt1kX30QgFmjKo52FMMuEwAyzZx3Stzr5KLJHRIjv7D2x_ChH6K7_8iB6e2l5HqGdb9EVJYA; path=/; expires=Sat, 12-Oct-24 10:11:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VT.y6GVr9fIXdZzcifVOXZDuRAxcBQCigFtLCFTexYA-1728726066335-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1621d689324362-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:41:05.363 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:41:05.363 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:41:05.363 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:41:05.363 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:41:05.364 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:41:05.364 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:41:05.366 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:41:05.366 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:41:05.368 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:41:06.973 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:41:06.973 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:41:06.973 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:41:06.974 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:41:08.122 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:41:08.122 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:41:08.123 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:41:08.148 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:41:08.151 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:41:08.152 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:41:08.182 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:41:08.745 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.59 seconds
2024-10-12 04:41:08.757 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would you like to order some food?'}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:41:08.758 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:41:08.758 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:41:08.758 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:41:08.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:41:08.759 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:41:09.548 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:41:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'698'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'198'), (b'x-ratelimit-remaining-tokens', b'59022'), (b'x-ratelimit-reset-requests', b'14m19.948s'), (b'x-ratelimit-reset-tokens', b'978ms'), (b'x-request-id', b'req_2ecef0684e11519513369f9c481e0ee7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1621efeb084362-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:41:09.549 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:41:09.549 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:41:09.550 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:41:09.550 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:41:09.550 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:41:09.550 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:41:09.552 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:41:09.553 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:41:09.555 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:41:11.513 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:41:11.513 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:41:11.513 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:41:11.514 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:41:13.242 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:41:13.243 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:41:13.243 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:41:13.296 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:41:13.300 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:41:13.302 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:41:13.306 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:41:13.978 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-10-12 04:41:13.993 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\n    You are a food order assistant. The user will give an order in natural language, and your task is to extract the food items and their customizations, if any, in a structured JSON format.\n\n    Here is the menu so you know what kind of meals the user can get:\n\n    Menu Item: Burger, Description: Delicious beef burger\n    Menu Item: Fries, Description: Crispy golden fries\n    Menu Item: Chicken Sandwich, Description: Grilled chicken sandwich with mayo and lettuce\n    Menu Item: Bacon Cheeseburger, Description: Beef patty with bacon, cheese, and lettuce\n    Menu Item: Avocado Toast, Description: Fresh avocado spread on toasted bread\n    Menu Item: BLT Sandwich, Description: Bacon, lettuce, and tomato sandwich\n    Menu Item: Caesar Salad, Description: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    Menu Item: Egg Salad Sandwich, Description: Egg salad sandwich with mayo on toasted bread\n    Menu Item: Veggie Burger, Description: A healthy veggie patty burger with lettuce, tomato, and onion\n    Menu Item: Spinach & Egg Wrap, Description: Healthy spinach and egg wrap\n    Menu Item: Coffee, Description: Freshly brewed coffee\n    Menu Item: Classic Hot Dog, Description: Hot dog with ketchup and mustard\n\n    Here is the format you should use for your extracted order:{"food_item_1": {"modification_1": value, "modification_2": value, ...},"food_item_2": {},  # No modifications...}\n\n    1) Always use the  {"ORDER":..., "output":...} format for your response.\n    2) The value of "output" should be "DONE" when the conversation is over.\n    3) "ORDER" should be empty if the user hasn\'t ordered anything yet\n\n    Example 1:\n        User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n        Assistant Reply: {"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"Gotcha. Would like anything else?"}\n\n        User Input: "No that\'s it."\n        Assistant Reply:{"ORDER":{"Burger": {"Cheese": 2},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 2}},"output":"DONE"}\n\n        \n    Example 2:\n        User Input: "Hello bitch."\n        Assistant Reply:{"ORDER":{},"output":"Hello. Sorry if I put you in a bad mood. Would like you to get some food?"}\n\n        User Input: "Uhmm fuck. Do you guys have burgers?"\n        Assistant Reply:{"ORDER":{},"output":"Yes we do! Do you just want a regular burger then?"}\n\n        User Input: "All right then. I want a burger but with extra cheese."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 1}, },"output":"Do you just want 1 piece of extra cheese or more?"}\n\n        User Input:"Omg, don\'t be annoying!!"\n        Assistant Reply: {"ORDER": {"Burger":{"Cheese": 1},},"output":"Oh, I am so sorry! I am sincerely sorry. So is one burger with an extra piece of cheese enough?"}\n\n        User Input: "No. I want two extra pieces."\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},},"output":"All right! Is that all?"}\n\n        User Input:"Yes bitch"\n        Assistant Reply:{"ORDER":{"Burger":{"Cheese": 2},}, "output":"All right!"}\n    \n    Example 3:\n        User Input: "Hello"\n        Assistant Reply:{"ORDER":{},"output":"Hello! Would like to get some food?"}      \n\n        User Input: "Hell no!"\n        Assistant Reply:{"ORDER":{},"output":"We have some really good meals like the Classic Hot Dog and Avocado Toast. Are you sure you do not want anything?"}      \n\n        User Input: ""\n        Assistant Reply:{"ORDER":{},"output":"DONE"}      \n\n    Now here are the conversations between a user and the assistant so far. Continue being the assistant always following the format {"ORDER":{...},"output":...}  \n    for all your responses\n    '}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Would you like to order some food?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': "I'm gonna have a burger."}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:41:13.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:41:13.995 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:41:13.995 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:41:13.995 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:41:13.995 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:41:14.808 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:41:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'748'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'197'), (b'x-ratelimit-remaining-tokens', b'59005'), (b'x-ratelimit-reset-requests', b'21m26.676s'), (b'x-ratelimit-reset-tokens', b'995ms'), (b'x-request-id', b'req_ea7a49ba763bf814d74e8c41c57ecd88'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162210a8a74362-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:41:14.808 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:41:14.809 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:41:14.809 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:41:14.809 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:41:14.809 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:41:14.809 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:41:20.922 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:41:20.922 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:41:20.923 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:45:27.115 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:45:27.123 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:45:27.130 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:45:27.130 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:45:27.358 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:45:27.363 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:45:27.366 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:45:27.370 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:45:27.370 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:45:27.374 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:45:27.375 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:45:27.375 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:45:27.693 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:45:27.695 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:45:27.695 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:45:32.412 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:45:32.413 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:45:32.413 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:45:32.413 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:45:32.949 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:45:39.320 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:45:39.320 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:45:39.320 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:45:39.321 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:45:40.470 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:45:40.471 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:45:40.472 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:45:40.506 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:45:40.508 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:45:40.527 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:45:40.540 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:45:42.006 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.50 seconds
2024-10-12 04:45:42.015 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': "C'est l'eau."}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:45:42.049 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:45:42.085 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027053959A80>
2024-10-12 04:45:42.086 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002703E640740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:45:42.096 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027053959A50>
2024-10-12 04:45:42.096 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:45:42.097 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:45:42.097 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:45:42.097 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:45:42.097 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:45:42.989 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:45:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'802'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'196'), (b'x-ratelimit-remaining-tokens', b'59113'), (b'x-ratelimit-reset-requests', b'24m10.576s'), (b'x-ratelimit-reset-tokens', b'887ms'), (b'x-request-id', b'req_7af3a193e63606cf77773fd510407551'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jWFv9Kc8TEATkEEV9FSe4zRdDuITPiTAB_QlH9u6QR0-1728726343-1.0.1.1-IFe4hGfOFQqbtNXVSGc_DnVwNrQUZpQn3Q.sLywThnzmyC6Z_uNf1QXxmZv1Zht8Hyd1oE7SSFDjdQo1EJ8LYQ; path=/; expires=Sat, 12-Oct-24 10:15:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9L6jXYgsx4yZtQVXBBv4teQsuxo.J40WOX_ncWAEjnI-1728726343973-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16289c5f2c4396-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:45:42.990 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:45:42.990 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:45:42.991 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:45:42.991 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:45:42.991 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:45:42.992 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:45:42.995 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:45:42.995 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:45:42.998 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:45:45.270 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:45:45.270 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:45:45.270 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:45:45.271 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:45:48.089 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:45:48.089 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:45:48.090 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:45:48.148 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:45:48.150 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:45:48.151 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:45:48.154 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:45:48.864 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.71 seconds
2024-10-12 04:45:48.877 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': "C'est l'eau."}, {'role': 'assistant', 'content': "It looks like you're not ordering food. Would you like to check our menu or place an order?"}, {'role': 'user', 'content': 'Yes, I would like to order some food.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:45:48.878 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:45:48.878 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:45:48.878 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:45:48.886 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002705395B9A0>
2024-10-12 04:45:48.886 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002703E640740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:45:48.901 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027053913130>
2024-10-12 04:45:48.901 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:45:48.902 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:45:48.902 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:45:48.902 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:45:48.902 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:45:49.466 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:45:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'505'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'195'), (b'x-ratelimit-remaining-tokens', b'59079'), (b'x-ratelimit-reset-requests', b'31m15.774s'), (b'x-ratelimit-reset-tokens', b'921ms'), (b'x-request-id', b'req_836ce6cecca15721a2174e7967bae80f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1628c6dac180d6-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:45:49.467 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:45:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:45:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:45:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:45:49.468 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:45:49.468 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:47:15.293 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:47:15.300 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:47:15.306 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:47:15.306 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:47:15.554 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:47:15.559 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:47:15.561 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:47:15.562 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:47:15.563 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:47:15.564 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:47:15.565 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:47:15.565 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:47:15.889 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:47:15.892 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:47:15.892 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:47:21.125 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:47:21.125 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:47:21.126 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:47:21.126 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:47:21.797 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:47:28.446 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:47:28.447 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:47:28.447 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:47:28.448 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:47:29.607 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:47:29.608 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:47:29.609 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:47:29.699 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:47:29.702 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:47:29.703 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:47:29.727 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:47:31.204 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.50 seconds
2024-10-12 04:47:31.216 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:47:31.237 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:47:31.285 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD3539C00>
2024-10-12 04:47:31.286 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:47:31.300 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD3539BD0>
2024-10-12 04:47:31.300 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:47:31.301 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:47:31.301 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:47:31.301 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:47:31.301 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:47:32.274 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:47:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'918'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'194'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'36m45.373s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_28aa11ea27b47d0b1ce4833916f49c33'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5MDFBWDro6N1zGg7bGlx_AyGrUzWRegkvwtVssnMcgo-1728726453-1.0.1.1-zZUur3Em2SuvE8cAPkz861VG0YF7sabsWVBgOi_8nsv3Flwrgl4W4Ycko94fSE3.WpOfTLMJk8bTRlpVrAdgDg; path=/; expires=Sat, 12-Oct-24 10:17:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DGxrTnCLap.1ZQBoJMPNZY0XEilHDR9QSxDtrZ3c6_Y-1728726453261-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162b46db987d16-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:47:32.276 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:47:32.276 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:47:32.277 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:47:32.277 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:47:32.277 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:47:32.278 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:47:32.284 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:47:32.284 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:47:32.286 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:47:34.147 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:47:34.147 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:47:34.147 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:47:34.148 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:47:35.367 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:47:35.367 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:47:35.368 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:47:35.416 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:47:35.419 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:47:35.427 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:47:35.441 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:47:36.041 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.62 seconds
2024-10-12 04:47:36.052 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:47:36.053 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:47:36.053 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:47:36.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:47:36.054 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:47:36.054 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:47:36.840 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:47:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'728'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'193'), (b'x-ratelimit-remaining-tokens', b'59101'), (b'x-ratelimit-reset-requests', b'43m52.615s'), (b'x-ratelimit-reset-tokens', b'899ms'), (b'x-request-id', b'req_843548b87888cb5f6fbe5d7d3918bbd9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162b649d177d16-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:47:36.841 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:47:36.841 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:47:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:47:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:47:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:47:36.842 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:47:36.843 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:47:36.843 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:47:36.845 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:47:39.587 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:47:39.587 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:47:39.587 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:47:39.588 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:47:40.737 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:47:40.738 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:47:40.739 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:47:40.831 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:47:40.834 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:47:40.852 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:47:40.867 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:47:41.431 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-10-12 04:47:41.446 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:47:41.448 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:47:41.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:47:41.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:47:41.449 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:47:41.449 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:47:42.330 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:47:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'800'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'192'), (b'x-ratelimit-remaining-tokens', b'59079'), (b'x-ratelimit-reset-requests', b'50m59.226s'), (b'x-ratelimit-reset-tokens', b'921ms'), (b'x-request-id', b'req_2e74a12d6930a807cf16de2e6cc9e51c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162b8649997d16-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:47:42.335 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:47:42.335 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:47:42.336 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:47:42.336 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:47:42.336 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:47:42.337 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:47:42.339 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:47:42.339 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:47:42.341 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:47:45.216 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:47:45.217 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:47:45.217 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:47:45.217 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:47:48.167 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:47:48.167 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:47:48.168 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:47:48.207 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:47:48.210 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:47:48.214 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:47:48.225 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:47:48.853 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:47:48.882 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Id love to help you with your order! Could you please tell me what food items you would like to order?'}, {'role': 'user', 'content': 'What items are available on your menu?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:47:48.885 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:47:48.885 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:47:48.886 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:47:48.897 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD35A8130>
2024-10-12 04:47:48.898 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:47:48.909 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD35A7C70>
2024-10-12 04:47:48.909 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:47:48.910 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:47:48.910 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:47:48.910 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:47:48.910 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:47:48.952 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:47:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'191'), (b'x-ratelimit-remaining-tokens', b'59041'), (b'x-ratelimit-reset-requests', b'58m3.762s'), (b'x-ratelimit-reset-tokens', b'959ms'), (b'x-request-id', b'req_b2c541a72326db5cfcc7882e5942f30e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162bb4ef756a5c-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:47:48.953 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:47:48.953 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:47:48.953 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:47:48.953 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:47:48.954 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:47:48.954 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:47:48.954 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:47:48.957 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:47:48.957 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:47:48.957 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:48:08.958 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Id love to help you with your order! Could you please tell me what food items you would like to order?'}, {'role': 'user', 'content': 'What items are available on your menu?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:48:08.960 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:48:08.960 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:48:08.960 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:48:08.983 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD359D090>
2024-10-12 04:48:08.983 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:48:09.014 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD3595B70>
2024-10-12 04:48:09.014 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:48:09.015 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:48:09.015 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:48:09.015 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:48:09.016 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:48:12.380 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:48:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'3304'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'190'), (b'x-ratelimit-remaining-tokens', b'59041'), (b'x-ratelimit-reset-requests', b'1h4m55.659s'), (b'x-ratelimit-reset-tokens', b'959ms'), (b'x-request-id', b'req_a662414f0eb57f715defa89cb675d539'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162c329fc38c87-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:48:12.381 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:48:12.381 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:48:12.382 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:48:12.382 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:48:12.382 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:48:12.382 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:48:12.386 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:48:12.386 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:48:12.389 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:48:15.557 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:48:15.557 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:48:15.557 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:48:15.558 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:48:18.816 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:48:18.817 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:48:18.817 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:48:18.907 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:48:18.910 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:48:18.914 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:48:18.947 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:48:19.630 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 04:48:19.654 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Id love to help you with your order! Could you please tell me what food items you would like to order?'}, {'role': 'user', 'content': 'What items are available on your menu?'}, {'role': 'assistant', 'content': "Heres what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nLet me know what you'd like to order!"}, {'role': 'user', 'content': 'I would like to get your burger.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:48:19.656 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:48:19.656 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:48:19.656 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:48:19.664 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD359CEE0>
2024-10-12 04:48:19.665 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD35A79D0>
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:48:19.695 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:48:20.406 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:48:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'658'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'190'), (b'x-ratelimit-remaining-tokens', b'58848'), (b'x-ratelimit-reset-requests', b'1h11m56.987s'), (b'x-ratelimit-reset-tokens', b'1.152s'), (b'x-request-id', b'req_ffe4ff6dbb343b0940a15972a60075ef'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162c755e3c8c59-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:48:20.407 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:48:20.408 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:48:20.408 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:48:20.408 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:48:20.408 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:48:20.408 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:48:20.410 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:48:20.410 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:48:20.412 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:48:23.807 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:48:23.807 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:48:23.807 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:48:23.808 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:48:26.886 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:48:26.886 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:48:26.888 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:48:26.981 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:48:26.984 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:48:26.996 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:48:27.006 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:48:27.647 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 04:48:27.688 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Id love to help you with your order! Could you please tell me what food items you would like to order?'}, {'role': 'user', 'content': 'What items are available on your menu?'}, {'role': 'assistant', 'content': "Heres what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nLet me know what you'd like to order!"}, {'role': 'user', 'content': 'I would like to get your burger.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to customize your burger in any way, such as adding cheese or any other toppings?'}, {'role': 'user', 'content': 'Yes, I would like extra cheese.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:48:27.689 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:48:27.690 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:48:27.690 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:48:27.729 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45BB5B0>
2024-10-12 04:48:27.730 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:48:27.743 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD359E5C0>
2024-10-12 04:48:27.743 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:48:27.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:48:27.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:48:27.744 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:48:27.745 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:48:27.792 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:48:28 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'189'), (b'x-ratelimit-remaining-tokens', b'58810'), (b'x-ratelimit-reset-requests', b'1h19m0.928s'), (b'x-ratelimit-reset-tokens', b'1.19s'), (b'x-request-id', b'req_b2148033ac0bdd3a3a1b18d8b96520f5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162ca7ab6d4299-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:48:27.792 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:48:27.793 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:48:27.793 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:48:27.793 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:48:27.793 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:48:27.793 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:48:27.793 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:48:27.794 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:48:27.794 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:48:27.794 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:48:47.795 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "It seems like you haven't placed an order yet. What would you like to have?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Id love to help you with your order! Could you please tell me what food items you would like to order?'}, {'role': 'user', 'content': 'What items are available on your menu?'}, {'role': 'assistant', 'content': "Heres what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nLet me know what you'd like to order!"}, {'role': 'user', 'content': 'I would like to get your burger.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to customize your burger in any way, such as adding cheese or any other toppings?'}, {'role': 'user', 'content': 'Yes, I would like extra cheese.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:48:47.797 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:48:47.798 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:48:47.798 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:48:47.839 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C48E0>
2024-10-12 04:48:47.840 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:48:47.868 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45BAC50>
2024-10-12 04:48:47.868 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:48:47.869 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:48:47.869 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:48:47.869 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:48:47.869 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:48:49.719 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:48:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1793'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'188'), (b'x-ratelimit-remaining-tokens', b'58810'), (b'x-ratelimit-reset-requests', b'1h25m52.802s'), (b'x-ratelimit-reset-tokens', b'1.19s'), (b'x-request-id', b'req_75f5f99f45560fea7e089fa0a74cce99'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162d256e0d7271-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:48:49.720 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:48:49.720 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:48:49.721 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:48:49.721 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:48:49.721 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:48:49.721 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:48:49.724 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:48:49.724 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:48:49.726 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:48:55.297 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:48:55.297 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:48:55.297 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:48:55.298 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:48:56.447 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:48:56.447 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:48:56.448 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:48:56.531 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:48:56.533 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:48:56.534 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:48:56.576 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:48:57.740 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.21 seconds
2024-10-12 04:48:57.848 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:48:57.849 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:48:57.849 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:48:57.867 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C64D0>
2024-10-12 04:48:57.867 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:48:57.880 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C64A0>
2024-10-12 04:48:57.881 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:48:57.881 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:48:57.881 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:48:57.881 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:48:57.881 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:48:59.537 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:49:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1606'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'187'), (b'x-ratelimit-remaining-tokens', b'58766'), (b'x-ratelimit-reset-requests', b'1h32m54.798s'), (b'x-ratelimit-reset-tokens', b'1.234s'), (b'x-request-id', b'req_e4b24134258ba5982783708dcf354f1f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162d640d58de97-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:48:59.538 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:48:59.538 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:48:59.539 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:48:59.539 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:48:59.539 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:48:59.539 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:48:59.541 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:48:59.541 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:48:59.543 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:49:16.736 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:49:16.736 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:49:16.737 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:49:16.737 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:49:19.556 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:49:19.556 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:49:19.557 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:49:19.632 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:49:19.634 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:49:19.649 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:49:19.686 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:49:20.400 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.77 seconds
2024-10-12 04:49:20.454 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:49:20.454 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:49:20.454 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:49:20.470 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C2230>
2024-10-12 04:49:20.470 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:49:20.481 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45BAA40>
2024-10-12 04:49:20.482 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:49:20.483 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:49:20.483 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:49:20.483 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:49:20.483 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:49:21.718 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:49:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1183'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'186'), (b'x-ratelimit-remaining-tokens', b'58709'), (b'x-ratelimit-reset-requests', b'1h39m44.192s'), (b'x-ratelimit-reset-tokens', b'1.291s'), (b'x-request-id', b'req_d5123f1a52ec605218e80b321e5aa441'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162df14ebd42a7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:49:21.719 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:49:21.719 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:49:21.720 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:49:21.720 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:49:21.720 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:49:21.721 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:49:21.725 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:49:21.725 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:49:21.728 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:49:26.337 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:49:26.337 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:49:26.337 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:49:26.338 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:49:27.487 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:49:27.487 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:49:27.488 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:49:27.521 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:49:27.523 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:49:27.540 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:49:27.556 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:49:28.147 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.62 seconds
2024-10-12 04:49:28.195 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:49:28.196 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:49:28.196 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:49:28.204 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C4BB0>
2024-10-12 04:49:28.204 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:49:28.216 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45C4B50>
2024-10-12 04:49:28.216 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:49:28.217 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:49:28.217 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:49:28.219 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:49:28.219 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:49:28.257 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:49:29 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'185'), (b'x-ratelimit-remaining-tokens', b'58677'), (b'x-ratelimit-reset-requests', b'1h46m48.455s'), (b'x-ratelimit-reset-tokens', b'1.323s'), (b'x-request-id', b'req_918fe6e63ac785595bb1800d671003df'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162e219c687cfa-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:49:28.258 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:49:28.258 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:49:28.258 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:49:28.258 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:49:28.258 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:49:28.258 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:49:28.258 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:49:28.259 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:49:28.259 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:49:28.259 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:49:48.274 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:49:48.275 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:49:48.275 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:49:48.308 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45BB640>
2024-10-12 04:49:48.308 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DFBE2407C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:49:48.339 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DFD45BB670>
2024-10-12 04:49:48.339 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:49:48.340 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:49:48.340 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:49:48.340 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:49:48.340 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:49:49.751 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:49:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1358'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'184'), (b'x-ratelimit-remaining-tokens', b'58677'), (b'x-ratelimit-reset-requests', b'1h53m40.338s'), (b'x-ratelimit-reset-tokens', b'1.323s'), (b'x-request-id', b'req_92f3a1a7891d0ea64013bbde7424479e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162e9f6863436a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:49:49.753 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:49:49.753 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:49:49.754 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:49:49.754 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:49:49.754 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:49:49.754 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:49:49.755 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:49:49.755 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:49:49.759 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:50:21.350 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:50:21.357 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:50:21.363 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:50:21.363 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:50:21.622 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:50:21.626 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:50:21.628 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:50:21.631 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:50:21.631 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:50:21.634 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:50:21.635 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:50:21.635 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:50:22.095 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:50:22.097 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:50:22.097 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:50:27.313 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:50:27.313 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:50:27.314 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:50:27.314 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:50:27.833 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:50:28.987 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:50:28.987 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:50:28.987 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:50:28.988 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:50:30.138 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:50:30.138 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:50:30.139 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:50:30.208 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:50:30.211 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:50:30.212 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:50:30.267 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:50:31.625 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.41 seconds
2024-10-12 04:50:31.634 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:50:31.669 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:50:31.703 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD82B9B10>
2024-10-12 04:50:31.703 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:50:31.714 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD82B9AE0>
2024-10-12 04:50:31.715 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:50:31.715 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:50:31.715 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:50:31.715 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:50:31.715 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:50:32.414 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:50:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'630'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'183'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'2h0m8.957s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_db1c807acecbdc1e62049a122e49867c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pIG3jY5p1cFeZNyKqLI0Q9U1VfwL581r9ssh0JGBIY4-1728726633-1.0.1.1-EowcmgD4AriSSpnfUv8m_9lLcapFIYPRi8rEbbDFkmt9kKyWMlHOv861sDQuPmss4bl7ONR84GpLCGtOwIa6rg; path=/; expires=Sat, 12-Oct-24 10:20:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=gfWi8pDl6ONiA3zO8FifxU4Ue6Y4BB.ri8wAD5IDtEg-1728726633405-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162fae7c2ac34a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:50:32.415 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:50:32.416 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:50:32.417 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:50:32.417 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:50:32.417 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:50:32.417 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:50:32.421 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:50:32.421 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:50:32.424 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:50:34.237 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:50:34.237 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:50:34.237 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:50:34.237 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:50:37.177 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:50:37.177 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:50:37.177 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:50:37.182 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:50:37.183 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:50:37.205 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:50:37.247 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:50:37.878 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:50:37.890 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Um, I would like to get.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:50:37.891 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:50:37.892 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:50:37.892 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:50:37.905 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD8315C90>
2024-10-12 04:50:37.905 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:50:37.917 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD8315C60>
2024-10-12 04:50:37.918 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:50:37.918 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:50:37.918 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:50:37.918 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:50:37.919 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:50:38.207 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:50:38.207 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:50:38.207 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:50:39.217 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:50:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1243'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'182'), (b'x-ratelimit-remaining-tokens', b'59096'), (b'x-ratelimit-reset-requests', b'2h7m14.751s'), (b'x-ratelimit-reset-tokens', b'904ms'), (b'x-request-id', b'req_4c467a40da440dbc42808ea207e8fd97'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162fd54aa84376-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:50:39.218 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:50:39.218 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:50:39.219 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:50:39.219 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:50:39.219 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:50:39.219 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:50:39.221 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:50:39.221 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:50:39.938 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:50:39.938 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:50:39.939 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:50:40.191 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:50:40.193 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:50:40.209 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:50:40.257 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:50:40.811 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.62 seconds
2024-10-12 04:50:40.825 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'Um, I would like to get.'}, {'role': 'assistant', 'content': "It seems like you're still thinking. Take your time and let me know what you'd like to order!"}, {'role': 'user', 'content': 'Bitte!'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:50:40.826 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:50:40.827 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:50:40.827 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:50:40.828 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:50:40.828 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:50:41.579 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'696'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'181'), (b'x-ratelimit-remaining-tokens', b'59069'), (b'x-ratelimit-reset-requests', b'2h14m23.845s'), (b'x-ratelimit-reset-tokens', b'931ms'), (b'x-request-id', b'req_d939438bd4c52f6290143749ce56cb7e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d162fe769994376-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:50:41.579 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:50:41.580 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:50:41.580 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:50:41.580 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:50:41.580 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:50:41.580 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:50:41.582 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:50:41.582 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:50:41.583 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:50:43.387 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:50:43.387 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:50:43.387 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:50:43.388 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:50:45.057 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:50:45.057 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:50:45.057 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:50:45.119 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:50:45.121 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:50:45.131 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:50:45.177 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:50:45.827 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.71 seconds
2024-10-12 04:50:45.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:50:45.863 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:50:45.864 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:50:45.865 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:50:45.865 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:50:45.902 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:50:46 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'180'), (b'x-ratelimit-remaining-tokens', b'59031'), (b'x-ratelimit-reset-requests', b'2h21m30.811s'), (b'x-ratelimit-reset-tokens', b'969ms'), (b'x-request-id', b'req_3e3a38973fad167fe79923aaf4b2a4fb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163006eca14376-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:50:45.903 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:50:45.904 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:50:45.905 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:50:45.905 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:50:45.905 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:50:45.905 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:50:45.906 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:50:45.907 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:50:45.907 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:50:45.907 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:51:05.918 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:51:05.919 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:51:05.919 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:51:05.927 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD9394130>
2024-10-12 04:51:05.927 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:51:05.940 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD9394100>
2024-10-12 04:51:05.940 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:51:05.940 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:51:05.940 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:51:05.940 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:51:05.941 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:51:06.968 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:51:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'978'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'179'), (b'x-ratelimit-remaining-tokens', b'59031'), (b'x-ratelimit-reset-requests', b'2h28m22.735s'), (b'x-ratelimit-reset-tokens', b'969ms'), (b'x-request-id', b'req_3fff1b3024a6a08842a81b3d69d22678'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1630846f124204-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:51:06.969 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:51:06.969 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:51:06.969 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:51:06.969 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:51:06.969 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:51:06.969 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:51:06.971 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:51:06.971 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:51:06.973 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:51:32.857 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:51:32.858 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:51:32.858 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:51:32.858 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:51:34.527 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:51:34.527 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:51:34.527 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:51:34.601 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:51:34.604 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:51:34.605 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:51:34.657 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:51:36.510 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.91 seconds
2024-10-12 04:51:36.547 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:51:36.547 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:51:36.547 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:51:36.584 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939D300>
2024-10-12 04:51:36.584 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:51:36.595 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD8316FB0>
2024-10-12 04:51:36.595 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:51:36.596 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:51:36.596 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:51:36.596 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:51:36.596 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:51:37.866 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:51:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1217'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'178'), (b'x-ratelimit-remaining-tokens', b'58964'), (b'x-ratelimit-reset-requests', b'2h35m4.073s'), (b'x-ratelimit-reset-tokens', b'1.036s'), (b'x-request-id', b'req_74bdc71449f740a15fa8dc6a86503ceb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1631440ff942f7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:51:37.867 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:51:37.867 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:51:37.867 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:51:37.868 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:51:37.868 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:51:37.868 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:51:37.870 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:51:37.870 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:51:37.872 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:51:43.867 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:51:43.867 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:51:43.868 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:51:43.868 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:51:46.177 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:51:46.177 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:51:46.177 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:51:46.244 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:51:46.247 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:51:46.248 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:51:46.297 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:51:46.940 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:51:46.981 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:51:46.981 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:51:46.981 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:51:46.990 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD82BB8B0>
2024-10-12 04:51:46.990 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:51:47.003 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939B4C0>
2024-10-12 04:51:47.004 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:51:47.004 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:51:47.004 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:51:47.004 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:51:47.004 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:51:47.705 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:51:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'636'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'177'), (b'x-ratelimit-remaining-tokens', b'58852'), (b'x-ratelimit-reset-requests', b'2h42m5.666s'), (b'x-ratelimit-reset-tokens', b'1.148s'), (b'x-request-id', b'req_061d3e1f8988722a2890d77abade5bdd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1631850af95e5f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:51:47.706 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:51:47.706 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:51:47.706 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:51:47.706 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:51:47.706 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:51:47.706 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:51:47.708 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:51:47.708 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:51:47.711 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:51:55.257 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:51:55.257 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:51:55.258 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:51:55.258 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:51:56.927 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:51:56.928 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:51:56.928 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:51:56.931 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:51:56.934 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:51:56.935 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:51:56.987 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:51:57.576 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:51:57.617 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:51:57.617 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:51:57.617 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:51:57.631 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD93A4E50>
2024-10-12 04:51:57.631 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD93A4E20>
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:51:57.643 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:51:58.605 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:51:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'903'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'176'), (b'x-ratelimit-remaining-tokens', b'58804'), (b'x-ratelimit-reset-requests', b'2h49m7.024s'), (b'x-ratelimit-reset-tokens', b'1.196s'), (b'x-request-id', b'req_3efdad5b85c074914ca38d4b80ecea11'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1631c78a663320-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:51:58.608 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:51:58.608 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:51:58.609 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:51:58.609 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:51:58.609 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:51:58.609 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:51:58.612 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:51:58.613 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:51:58.615 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:52:01.407 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:52:01.407 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:52:01.407 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:52:01.408 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:52:03.517 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:52:03.518 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:52:03.518 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:52:03.566 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:52:03.570 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:52:03.570 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:52:03.577 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:52:05.263 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.69 seconds
2024-10-12 04:52:05.329 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:52:05.330 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:52:05.330 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:52:05.339 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939B670>
2024-10-12 04:52:05.340 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:52:05.352 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD82BB610>
2024-10-12 04:52:05.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:52:05.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:52:05.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:52:05.354 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:52:05.354 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:52:05.398 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:52:06 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'175'), (b'x-ratelimit-remaining-tokens', b'58762'), (b'x-ratelimit-reset-requests', b'2h56m11.316s'), (b'x-ratelimit-reset-tokens', b'1.238s'), (b'x-request-id', b'req_e4fc87aa230c7130126d10ee8529ffe5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1631f7bae74315-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:52:05.398 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:52:05.399 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:52:05.399 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:52:05.399 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:52:05.399 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:52:05.399 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:52:05.399 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:52:05.399 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:52:05.400 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:52:05.400 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:52:25.429 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:52:25.430 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:52:25.430 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:52:25.462 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD93A6AA0>
2024-10-12 04:52:25.462 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:52:25.475 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939E260>
2024-10-12 04:52:25.475 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:52:25.476 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:52:25.476 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:52:25.476 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:52:25.476 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:52:26.375 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:52:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'844'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'174'), (b'x-ratelimit-remaining-tokens', b'58762'), (b'x-ratelimit-reset-requests', b'3h3m3.191s'), (b'x-ratelimit-reset-tokens', b'1.238s'), (b'x-request-id', b'req_9947848423d568354615fa51b5bc80ed'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16327589667c9f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:52:26.376 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:52:26.377 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:52:26.377 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:52:26.377 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:52:26.378 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:52:26.378 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:52:26.382 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:52:26.382 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:52:26.384 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:52:37.887 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:52:37.887 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:52:37.887 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:52:37.888 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:52:39.037 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:52:39.038 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:52:39.038 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:52:39.060 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:52:39.062 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:52:39.064 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:52:39.097 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:52:39.800 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.74 seconds
2024-10-12 04:52:39.868 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:52:39.868 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:52:39.868 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:52:39.901 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939B790>
2024-10-12 04:52:39.901 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002ACC2ECC7C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:52:39.913 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACD939B7C0>
2024-10-12 04:52:39.914 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:52:39.914 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:52:39.914 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:52:39.914 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:52:39.915 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:52:40.450 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:52:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'173'), (b'x-ratelimit-remaining-tokens', b'58718'), (b'x-ratelimit-reset-requests', b'3h10m0.868s'), (b'x-ratelimit-reset-tokens', b'1.282s'), (b'x-request-id', b'req_56c552c53092de2df7bf788b27197460'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1632cfb91780cd-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:52:40.451 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:52:40.451 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:52:40.452 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:52:40.452 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:52:40.452 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:52:40.452 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:52:40.459 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:52:40.459 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:52:40.462 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:53:43.885 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:53:43.895 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:53:43.901 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:53:43.901 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:53:44.152 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:53:44.157 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:53:44.161 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:53:44.165 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:53:44.166 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:53:44.170 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:53:44.171 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:53:44.172 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:53:44.558 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:53:44.561 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:53:44.561 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:53:49.386 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:53:49.386 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:53:49.387 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:53:49.387 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:53:49.936 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:53:51.150 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:53:51.150 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:53:51.150 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:53:51.151 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:53:52.309 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:53:52.309 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:53:52.310 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:53:52.312 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:53:52.315 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:53:52.334 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:53:52.368 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:53:53.008 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 04:53:53.017 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:53:53.047 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:53:53.110 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F580734F0>
2024-10-12 04:53:53.110 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F42CE07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:53:53.121 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F580B9C30>
2024-10-12 04:53:53.122 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:53:53.122 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:53:53.122 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:53:53.122 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:53:53.122 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:53:54.005 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:53:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'824'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'172'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'3h15m59.542s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_bd3b64bb856289cce4bcafd88f10c4a9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=N4FxzrtMI00F57cT2S0qJmQuTBcuxNzZFprdB9PJtK4-1728726835-1.0.1.1-vrVcZqvCaoJw2NF3XmoMEYZGCwPtAMbRsymcnSxJiBB8GSwX_F0rRFY7rIzprJQrFBWofYfpu.w2osMUlOXJhg; path=/; expires=Sat, 12-Oct-24 10:23:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=jUoUhiEb9v3NVCSdAO5Ob9QBYGXHfbyqiubRnPzZsR0-1728726835002-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16349948f6439d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:53:54.007 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:53:54.007 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:53:54.008 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:53:54.008 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:53:54.008 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:53:54.008 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:53:54.012 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:53:54.012 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:53:54.014 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:53:56.589 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:53:56.589 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:53:56.590 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:53:56.590 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:53:57.750 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:53:57.750 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:53:57.751 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:53:57.795 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:53:57.799 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:53:57.800 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:53:57.809 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:53:58.411 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 04:53:58.426 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Are you ready to place an order from our menu?'}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:53:58.428 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:53:58.428 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:53:58.429 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:53:58.429 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:53:58.429 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:53:58.959 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:53:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'171'), (b'x-ratelimit-remaining-tokens', b'59098'), (b'x-ratelimit-reset-requests', b'3h23m6.244s'), (b'x-ratelimit-reset-tokens', b'902ms'), (b'x-request-id', b'req_8b25aa11ed56192148e189528c018cd0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1634ba7d87439d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:53:58.960 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:53:58.961 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:53:58.962 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:53:58.962 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:53:58.962 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:53:58.962 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:53:58.964 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:53:58.964 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:53:58.966 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:54:00.558 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:54:00.558 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:54:00.558 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:54:00.558 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:54:02.929 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:54:02.929 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:54:02.930 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:54:02.962 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:54:02.965 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:54:02.966 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:54:02.988 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:54:03.633 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 04:54:03.647 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Are you ready to place an order from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'I would like to order a burger.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:54:03.648 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:54:03.649 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:54:03.649 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:54:03.649 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:54:03.649 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:54:04.434 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:54:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'737'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'170'), (b'x-ratelimit-remaining-tokens', b'59079'), (b'x-ratelimit-reset-requests', b'3h30m13.02s'), (b'x-ratelimit-reset-tokens', b'921ms'), (b'x-request-id', b'req_90253ab89c3521fa346171cef6b348a1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1634db1c48439d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:54:04.435 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:54:04.436 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:54:04.436 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:54:04.436 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:54:04.437 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:54:04.437 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:54:04.438 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:54:04.438 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:54:04.441 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:54:07.789 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:54:07.789 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:54:07.789 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:54:07.789 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:54:10.158 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:54:10.159 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:54:10.159 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:54:10.198 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:54:10.201 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:54:10.202 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:54:10.229 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:54:10.881 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-10-12 04:54:10.901 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Are you ready to place an order from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'I would like to order a burger.'}, {'role': 'assistant', 'content': 'Would you like to customize your burger or order anything else?'}, {'role': 'user', 'content': 'I would like some extra cheese, please.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:54:10.903 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:54:10.904 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:54:10.904 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:54:10.917 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F5811E6E0>
2024-10-12 04:54:10.917 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F42CE07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:54:10.929 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F580BB7C0>
2024-10-12 04:54:10.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:54:10.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:54:10.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:54:10.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:54:10.930 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:54:10.972 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:54:11 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'169'), (b'x-ratelimit-remaining-tokens', b'59052'), (b'x-ratelimit-reset-requests', b'3h37m17.831s'), (b'x-ratelimit-reset-tokens', b'948ms'), (b'x-request-id', b'req_fa79c9a5010ba6849d3eb982f666fda3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163508995f41b2-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:54:10.973 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:54:10.973 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:54:10.973 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:54:10.973 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:54:10.973 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:54:10.973 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:54:10.973 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:54:10.981 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:54:10.981 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:54:10.981 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:54:30.981 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Are you ready to place an order from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'I would like to order a burger.'}, {'role': 'assistant', 'content': 'Would you like to customize your burger or order anything else?'}, {'role': 'user', 'content': 'I would like some extra cheese, please.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:54:30.983 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:54:30.983 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:54:30.983 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:54:31.018 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F58128190>
2024-10-12 04:54:31.018 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F42CE07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:54:31.029 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F58127DF0>
2024-10-12 04:54:31.029 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:54:31.029 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:54:31.030 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:54:31.030 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:54:31.030 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:54:32.090 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:54:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1000'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'168'), (b'x-ratelimit-remaining-tokens', b'59052'), (b'x-ratelimit-reset-requests', b'3h44m9.635s'), (b'x-ratelimit-reset-tokens', b'948ms'), (b'x-request-id', b'req_331c13d5c2f8de74a18d7aa1bce42687'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1635863c79c34e-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:54:32.091 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:54:32.092 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:54:32.092 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:54:32.092 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:54:32.092 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:54:32.093 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:54:32.094 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:54:32.094 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:54:32.097 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:54:35.888 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:54:35.888 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:54:35.888 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:54:35.889 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:54:37.039 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:54:37.040 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:54:37.041 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:54:37.293 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:54:37.294 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:54:37.299 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:54:37.300 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:54:37.931 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 04:54:37.954 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! Are you ready to place an order from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': 'Great! What would you like to order?'}, {'role': 'user', 'content': 'I would like to order a burger.'}, {'role': 'assistant', 'content': 'Would you like to customize your burger or order anything else?'}, {'role': 'user', 'content': 'I would like some extra cheese, please.'}, {'role': 'assistant', 'content': 'Would you like to add anything else to your order?'}, {'role': 'user', 'content': 'No.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:54:37.956 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:54:37.957 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:54:37.958 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:54:37.985 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F59140B20>
2024-10-12 04:54:37.985 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F42CE07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:54:38.019 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F59140E50>
2024-10-12 04:54:38.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:54:38.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:54:38.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:54:38.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:54:38.020 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:54:38.946 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:54:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'861'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'167'), (b'x-ratelimit-remaining-tokens', b'59037'), (b'x-ratelimit-reset-requests', b'3h51m14.639s'), (b'x-ratelimit-reset-tokens', b'963ms'), (b'x-request-id', b'req_4fb23aec8920b5a849aee9f5e95b8c1f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1635b1ed02438a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:54:38.947 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:54:38.947 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:54:38.948 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:54:38.948 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:54:38.948 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:54:38.948 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:55:05.718 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:55:05.725 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:55:05.730 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:55:05.730 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:55:05.955 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:55:05.958 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:05.960 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:55:05.961 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:05.962 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:55:05.964 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:05.964 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:55:05.964 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:55:06.210 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:55:06.212 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:55:06.213 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:55:11.074 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:55:11.075 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:55:11.075 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:11.075 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:11.578 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:55:12.899 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:12.899 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:12.899 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:55:12.900 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:14.049 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:14.049 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:55:14.050 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:14.106 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:14.109 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:14.115 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:14.118 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:15.449 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.34 seconds
2024-10-12 04:55:15.493 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:55:15.524 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204859C9E70>
2024-10-12 04:55:15.524 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020484C707C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:55:15.538 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204859C9E40>
2024-10-12 04:55:15.539 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:55:15.540 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:55:15.540 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:55:15.540 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:55:15.540 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:55:16.264 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:55:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'673'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'166'), (b'x-ratelimit-remaining-tokens', b'59115'), (b'x-ratelimit-reset-requests', b'3h57m49.127s'), (b'x-ratelimit-reset-tokens', b'885ms'), (b'x-request-id', b'req_59348255f1d5471193d5343032063e9c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qRwsvu8LwuDLAnW2H0H4nNWpHgDEcXOPR020ZH7VSBk-1728726917-1.0.1.1-RxnFi01VRm_CQIpZMd9K5t2qSDSkFd4NkOOC..AobOK8ax0xXmnxDMff82zp1IlSHsxuQ94B3Pa9qa3AELGBNg; path=/; expires=Sat, 12-Oct-24 10:25:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=YdRIVdqSyoyBo8BHYwarJm5Y.NOU1rBRSPsxppIhgdM-1728726917264-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16369c6fe11815-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:55:16.265 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:55:16.265 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:55:16.266 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:55:16.266 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:55:16.266 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:55:16.266 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:55:16.269 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:16.269 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:16.272 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:55:19.999 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:19.999 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:19.999 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:55:20.000 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:21.279 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:21.280 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:55:21.281 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:21.367 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:21.370 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:21.376 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:21.409 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:32.271 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:55:32.279 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:55:32.285 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:55:32.285 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:55:32.409 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:55:32.412 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:32.414 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:55:32.415 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:32.416 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:55:32.417 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:55:32.418 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:55:32.418 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:55:32.712 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:55:32.714 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:55:32.715 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:55:37.534 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:55:37.535 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:55:37.535 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:37.535 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:38.090 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:55:39.421 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:39.421 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:39.422 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:55:39.422 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:40.581 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:40.582 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:55:40.582 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:40.616 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:40.619 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:40.626 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:40.641 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:41.227 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 04:55:41.237 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:55:41.254 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:55:41.273 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBD3031C0>
2024-10-12 04:55:41.273 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CEA7F507C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:55:41.286 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBD349C00>
2024-10-12 04:55:41.286 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:55:41.286 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:55:41.286 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:55:41.287 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:55:41.287 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:55:42.257 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:55:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'917'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'166'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'4h4m35.38s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_eeb8aa4f042b4b5d4f127cba8eb5175d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G6zJJ39QtMYIb4I0n2.80YUfgUhQDSLFzbGpjoEHXrY-1728726943-1.0.1.1-NZMfLtXIkJ726UrSdZJJKq.cYIIg5j4Suut9CzRDYe_JC83zAj3_kbj8sTj6MqufgX1su1d8f7TztOAu5ByUQg; path=/; expires=Sat, 12-Oct-24 10:25:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G5ZizpdDiRicp2g9czN7eyqlKpNLnV519lT3WABxSwg-1728726943257-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16373d588342b5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:55:42.258 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:55:42.258 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:55:42.259 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:55:42.259 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:55:42.259 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:55:42.259 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:55:42.262 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:42.262 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:42.264 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:55:44.221 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:44.221 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:44.221 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:55:44.221 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:47.171 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:47.171 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:55:47.172 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:47.223 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:47.226 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:47.227 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:47.230 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:49.222 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.00 seconds
2024-10-12 04:55:49.234 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'Ich mchte auch noch ein bisschen erinnern.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:55:49.235 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:55:49.236 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:55:49.236 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:55:49.247 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBD3A5DB0>
2024-10-12 04:55:49.248 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CEA7F507C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:55:49.259 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBD3A5D80>
2024-10-12 04:55:49.260 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:55:49.260 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:55:49.260 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:55:49.260 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:55:49.260 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:55:51.436 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:55:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'2128'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'165'), (b'x-ratelimit-remaining-tokens', b'59088'), (b'x-ratelimit-reset-requests', b'4h11m39.403s'), (b'x-ratelimit-reset-tokens', b'912ms'), (b'x-request-id', b'req_9d6d8fb351bea52331346ab25f663d30'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16376f395a4301-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:55:51.437 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:55:51.437 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:55:51.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:55:51.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:55:51.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:55:51.438 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:55:51.448 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:51.448 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:51.451 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:55:54.021 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:54.021 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:54.021 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:55:54.021 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:55.170 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:55.170 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:55:55.171 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:55.233 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:55.236 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:55.236 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:55.301 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:55.681 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:55:55.681 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:55:55.681 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:55:55.865 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 04:55:55.885 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.65 seconds
2024-10-12 04:55:55.902 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'Ich mchte auch noch ein bisschen erinnern.'}, {'role': 'assistant', 'content': 'Es klingt so, als ob Sie an etwas erinnert werden mchten. Mchten Sie etwas auf der Speisekarte bestellen? Hier sind die verfgbaren Optionen: \n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nLassen Sie mich wissen, was Sie bestellen mchten!'}, {'role': 'user', 'content': 'What?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:55:55.903 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:55:55.904 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:55:55.904 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:55:55.905 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:55:55.905 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:55:57.402 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:55:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1440'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'164'), (b'x-ratelimit-remaining-tokens', b'58987'), (b'x-ratelimit-reset-requests', b'4h18m44.754s'), (b'x-ratelimit-reset-tokens', b'1.012s'), (b'x-request-id', b'req_f80d4d7ebef86c991fb894279cfaa4cd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163798bea14301-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:55:57.403 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:55:57.403 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:55:57.404 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:55:57.404 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:55:57.404 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:55:57.405 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:55:57.409 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:55:57.409 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:55:58.111 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:55:58.111 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:55:58.112 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:55:58.114 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:55:58.116 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:55:58.117 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:55:58.119 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:55:58.843 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.73 seconds
2024-10-12 04:55:58.865 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'Ich mchte auch noch ein bisschen erinnern.'}, {'role': 'assistant', 'content': 'Es klingt so, als ob Sie an etwas erinnert werden mchten. Mchten Sie etwas auf der Speisekarte bestellen? Hier sind die verfgbaren Optionen: \n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nLassen Sie mich wissen, was Sie bestellen mchten!'}, {'role': 'user', 'content': 'What?'}, {'role': 'assistant', 'content': "I apologize for the confusion! It seems there was a misunderstanding. Would you like to place a food order? Here are the menu items you can choose from:\n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nPlease let me know what you'd like to order!"}, {'role': 'user', 'content': 'Yeah, I see this other.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:55:58.867 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:55:58.867 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:55:58.867 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:55:58.868 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:55:58.868 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:55:58.909 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:55:59 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'163'), (b'x-ratelimit-remaining-tokens', b'58883'), (b'x-ratelimit-reset-requests', b'4h25m53.796s'), (b'x-ratelimit-reset-tokens', b'1.117s'), (b'x-request-id', b'req_f4b7ee9f89813f681523d8a1430dace5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1637ab38d64301-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:55:58.909 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:55:58.909 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:55:58.909 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:55:58.909 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:55:58.909 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:55:58.909 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:55:58.909 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:55:58.911 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:55:58.911 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:55:58.911 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:56:02.461 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:56:02.461 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:56:02.461 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 04:56:18.912 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'Ich mchte auch noch ein bisschen erinnern.'}, {'role': 'assistant', 'content': 'Es klingt so, als ob Sie an etwas erinnert werden mchten. Mchten Sie etwas auf der Speisekarte bestellen? Hier sind die verfgbaren Optionen: \n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nLassen Sie mich wissen, was Sie bestellen mchten!'}, {'role': 'user', 'content': 'What?'}, {'role': 'assistant', 'content': "I apologize for the confusion! It seems there was a misunderstanding. Would you like to place a food order? Here are the menu items you can choose from:\n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nPlease let me know what you'd like to order!"}, {'role': 'user', 'content': 'Yeah, I see this other.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:56:18.913 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:56:18.913 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:56:18.913 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:56:18.927 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBE3C8850>
2024-10-12 04:56:18.927 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CEA7F507C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CEBE3C8820>
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:56:18.938 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:56:19.821 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:56:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'803'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'162'), (b'x-ratelimit-remaining-tokens', b'58883'), (b'x-ratelimit-reset-requests', b'4h32m45.7s'), (b'x-ratelimit-reset-tokens', b'1.117s'), (b'x-request-id', b'req_f54e4ad9fbd114f33742f82043efd08b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163828abb472a5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:56:19.822 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:56:19.822 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:56:19.823 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:56:19.823 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:56:19.823 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:56:19.823 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:56:19.824 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:56:19.824 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:56:21.980 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:56:21.980 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:56:21.982 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:56:22.072 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:56:22.075 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:56:22.088 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:56:22.109 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:56:22.954 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.88 seconds
2024-10-12 04:56:22.992 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'Ich mchte auch noch ein bisschen erinnern.'}, {'role': 'assistant', 'content': 'Es klingt so, als ob Sie an etwas erinnert werden mchten. Mchten Sie etwas auf der Speisekarte bestellen? Hier sind die verfgbaren Optionen: \n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nLassen Sie mich wissen, was Sie bestellen mchten!'}, {'role': 'user', 'content': 'What?'}, {'role': 'assistant', 'content': "I apologize for the confusion! It seems there was a misunderstanding. Would you like to place a food order? Here are the menu items you can choose from:\n\n- Burger\n- Fries\n- Chicken Sandwich\n- Bacon Cheeseburger\n- Avocado Toast\n- BLT Sandwich\n- Caesar Salad\n- Egg Salad Sandwich\n- Veggie Burger\n- Spinach & Egg Wrap\n- Coffee\n- Classic Hot Dog\n\nPlease let me know what you'd like to order!"}, {'role': 'user', 'content': 'Yeah, I see this other.'}, {'role': 'assistant', 'content': "It sounds like you might want to place an order. Please let me know what you'd like to order from the menu, and I'll help you with that!"}, {'role': 'user', 'content': "I'll see you, Salad. I didn't, he was working."}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:56:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:56:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:56:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:56:22.995 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:56:22.995 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:56:23.034 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 09:56:24 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'161'), (b'x-ratelimit-remaining-tokens', b'58835'), (b'x-ratelimit-reset-requests', b'4h39m53.76s'), (b'x-ratelimit-reset-tokens', b'1.165s'), (b'x-request-id', b'req_69f1a63be554b48e4302acfea26fce97'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1638420cde72a5-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:56:23.035 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 04:56:23.035 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:56:23.035 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:56:23.035 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:56:23.036 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:56:23.036 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 04:56:23.036 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 04:56:23.036 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 04:56:23.036 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 04:56:23.036 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 04:56:41.497 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 04:56:41.508 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 04:56:41.514 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 04:56:41.514 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 04:56:41.714 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 04:56:41.716 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:56:41.718 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 04:56:41.720 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:56:41.720 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 04:56:41.722 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 04:56:41.723 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 04:56:41.723 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 04:56:41.964 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 04:56:41.966 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 04:56:41.967 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 04:56:46.808 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 04:56:46.809 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 04:56:46.809 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:56:46.809 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:56:47.338 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:56:48.228 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:56:48.228 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:56:48.228 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:56:48.229 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:56:49.378 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:56:49.378 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:56:49.379 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:56:49.463 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:56:49.466 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:56:49.467 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:56:49.508 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:56:50.781 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.32 seconds
2024-10-12 04:56:50.790 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 04:56:50.802 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:56:50.810 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025A74109AE0>
2024-10-12 04:56:50.810 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025A5EDF07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:56:50.861 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025A74109AB0>
2024-10-12 04:56:50.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:56:50.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:56:50.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:56:50.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:56:50.862 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:56:51.467 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:56:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'545'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'160'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'4h46m37.791s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_ed0273f9d945a23fc3f2b15ae6d7c7b4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bW14zPVji3vq6K9nZHvfyPLczvhmbG20O4sP8WOakgw-1728727012-1.0.1.1-.19J4Ciuu9m.0ac392Jr_ObultC3IBGqQbSFrEitD73jsfyU1DeM0nPyqhId88dYmH1ncjWZ3ndtlRuRUwpYng; path=/; expires=Sat, 12-Oct-24 10:26:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xVkIHuT8IuD.h_KqPMFEZkZ0qhXNc3zCDCDS3c60mTc-1728727012470-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1638f039e5427f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:56:51.469 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:56:51.469 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:56:51.470 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:56:51.470 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:56:51.470 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:56:51.471 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:56:51.475 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:56:51.475 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:56:51.477 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 04:56:53.147 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 04:56:53.148 - RealTimeSTT: root - INFO - recording started
2024-10-12 04:56:53.148 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 04:56:53.149 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 04:56:56.098 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 04:56:56.098 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 04:56:56.099 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 04:56:56.185 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 04:56:56.188 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 04:56:56.208 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 04:56:56.228 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 04:56:58.253 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.07 seconds
2024-10-12 04:56:58.277 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 04:56:58.277 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 04:56:58.277 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 04:56:58.313 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025A74165C90>
2024-10-12 04:56:58.313 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025A5EDF07C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 04:56:58.325 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025A74165C60>
2024-10-12 04:56:58.326 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 04:56:58.326 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 04:56:58.326 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 04:56:58.326 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 04:56:58.326 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 04:56:59.003 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 09:57:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'624'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'159'), (b'x-ratelimit-remaining-tokens', b'59091'), (b'x-ratelimit-reset-requests', b'4h53m42.339s'), (b'x-ratelimit-reset-tokens', b'909ms'), (b'x-request-id', b'req_8b10cd6d4f3a7361d5a7f66d252615a8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16391ed8ba5e61-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 04:56:59.004 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 04:56:59.004 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 04:56:59.005 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 04:56:59.005 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 04:56:59.005 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 04:56:59.005 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 04:56:59.007 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 04:56:59.007 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 04:56:59.009 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:02.040 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 05:00:02.041 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 05:00:02.049 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 05:00:02.102 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2024-10-12 05:00:02.729 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 05:00:17.313 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:00:17.320 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:00:17.325 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:00:17.325 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:00:17.480 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:00:17.485 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:17.488 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:00:17.492 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:17.493 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:00:17.496 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:17.497 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:00:17.497 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:00:17.778 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:00:17.780 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:00:17.781 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:00:22.969 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:00:22.970 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:00:22.970 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:00:22.970 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:00:23.642 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:29.201 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:00:29.215 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:00:29.222 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:00:29.222 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:00:29.445 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:00:29.450 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:29.452 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:00:29.454 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:29.455 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:00:29.457 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:00:29.457 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:00:29.458 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:00:29.788 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:00:29.790 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:00:29.791 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:00:35.300 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:00:35.302 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:00:35.302 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:00:35.302 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:00:36.031 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:36.800 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:00:36.800 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:00:36.801 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:00:37.951 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:00:37.951 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:00:37.951 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:00:37.951 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:00:37.952 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:00:37.952 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:00:37.966 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:00:37.974 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:00:37.975 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:00:38.010 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:00:38.052 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:00:38.055 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:00:38.056 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:00:38.080 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:00:40.498 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.44 seconds
2024-10-12 05:00:40.518 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:00:40.547 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:00:40.578 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.60 seconds
2024-10-12 05:00:40.580 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC58E9D50>
2024-10-12 05:00:40.580 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027AAF62C740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:00:40.592 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:00:40.593 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC58E9D20>
2024-10-12 05:00:40.593 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:00:40.594 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:00:40.594 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:00:40.595 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:00:40.595 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:00:40.608 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:00:40.625 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A6A9F30>
2024-10-12 05:00:40.625 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022319950740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:00:40.639 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A6A9F00>
2024-10-12 05:00:40.640 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:00:40.640 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:00:40.641 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:00:40.641 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:00:40.641 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:00:41.162 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:00:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'514'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'158'), (b'x-ratelimit-remaining-tokens', b'59114'), (b'x-ratelimit-reset-requests', b'4h57m12.059s'), (b'x-ratelimit-reset-tokens', b'886ms'), (b'x-request-id', b'req_3b752e1502223b1fb585fe936535f806'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aFmzMVpuFBV.hGzW60RzlsjJ2MfD2BNHC0IR1AMMsnM-1728727242-1.0.1.1-HnxgqiOHQPWrpJjdSVQxnH.Is.96FEBDu4nviz9MvYOytLX9JlHrfrCvmhxyo56v5zAtUs.tUYNFyDFXY_kKVw; path=/; expires=Sat, 12-Oct-24 10:30:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=YzsQOVCX4p_a0rY86vmeRLEq3.kV8CRbxPB71yUpvJY-1728727242171-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163e8c1f42c347-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:00:41.164 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:00:41.169 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:00:41.171 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:00:41.172 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:00:41.172 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:00:41.172 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:00:41.178 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:00:41.178 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:00:41.181 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:41.246 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:00:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'550'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'157'), (b'x-ratelimit-remaining-tokens', b'58265'), (b'x-ratelimit-reset-requests', b'5h4m24.022s'), (b'x-ratelimit-reset-tokens', b'1.734s'), (b'x-request-id', b'req_2b66576b58106d7d77f61aeb3317d7b1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qwMrHpUKL4VpiyD_3Qxj4_fm5HXF_Db_rXPJBiHyJWc-1728727242-1.0.1.1-uUQoGPc9XXyQRYgtohKZIEbBa_1O76hrO5sPpU6iEdS_lbaawB.fxyMO6nI66GlUojOM_QVTb9IlC4HCw6BEmQ; path=/; expires=Sat, 12-Oct-24 10:30:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=l4yu6xKhS7vK.mkzpVMcVui2CNBWxgoxd1SuQ61k5v4-1728727242255-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163e8c58b1426d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:00:41.247 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:00:41.247 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:00:41.247 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:00:41.247 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:00:41.247 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:00:41.247 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:00:41.251 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:00:41.251 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:00:41.254 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:42.940 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:42.940 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:42.940 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:00:42.941 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:00:43.260 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:43.260 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:43.260 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:00:43.260 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:00:45.370 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:00:45.370 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:00:45.370 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:00:45.370 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:00:45.371 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:00:45.371 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:00:45.373 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:00:45.374 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:00:45.377 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:00:45.440 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:00:45.451 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:00:45.453 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:00:45.453 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:00:45.500 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:00:46.268 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.89 seconds
2024-10-12 05:00:46.293 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'I would like to order food.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:00:46.296 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:00:46.297 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:00:46.297 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:00:46.306 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC5945F60>
2024-10-12 05:00:46.306 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027AAF62C740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:00:46.320 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC5945F30>
2024-10-12 05:00:46.320 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:00:46.321 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:00:46.321 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:00:46.322 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:00:46.322 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:00:46.390 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.94 seconds
2024-10-12 05:00:46.405 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'I would like to order food.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:00:46.412 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:00:46.412 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:00:46.412 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:00:46.425 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A706020>
2024-10-12 05:00:46.425 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022319950740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:00:46.451 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A705FF0>
2024-10-12 05:00:46.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:00:46.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:00:46.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:00:46.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:00:46.452 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:00:46.503 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:00:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'155'), (b'x-ratelimit-remaining-tokens', b'58291'), (b'x-ratelimit-reset-requests', b'5h18m42.229s'), (b'x-ratelimit-reset-tokens', b'1.708s'), (b'x-request-id', b'req_9f29364befe81b23a339880c5905af3e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163eb0bbda5e6b-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:00:46.504 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:00:46.504 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:00:46.504 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:00:46.504 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:00:46.504 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:00:46.504 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:00:46.505 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:00:46.512 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:00:46.512 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:00:46.512 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:00:46.920 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:00:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'156'), (b'x-ratelimit-remaining-tokens', b'59095'), (b'x-ratelimit-reset-requests', b'5h11m30.334s'), (b'x-ratelimit-reset-tokens', b'905ms'), (b'x-request-id', b'req_ef0adeb00e561e559725665297ae8ed5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163eafdb1442c4-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:00:46.921 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:00:46.921 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:00:46.922 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:00:46.922 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:00:46.922 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:00:46.922 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:00:46.923 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:00:46.923 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:00:46.927 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:00:50.170 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:50.171 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:50.171 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 05:00:50.239 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:00:50.240 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:00:50.240 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:00:50.240 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:00:52.990 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:00:52.990 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:00:52.991 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:00:53.089 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:00:53.092 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:00:53.107 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:00:53.120 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:00:53.733 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 05:00:53.751 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'I would like to order food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order? Please let me know the items and any customizations you have in mind.'}, {'role': 'user', 'content': 'Please can I have this sandwich?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:00:53.754 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:00:53.755 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:00:53.755 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:00:53.806 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC594E080>
2024-10-12 05:00:53.806 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027AAF62C740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:00:53.819 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC594E050>
2024-10-12 05:00:53.820 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:00:53.820 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:00:53.820 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:00:53.821 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:00:53.821 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:00:53.865 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:00:54 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'154'), (b'x-ratelimit-remaining-tokens', b'59059'), (b'x-ratelimit-reset-requests', b'5h25m46.829s'), (b'x-ratelimit-reset-tokens', b'941ms'), (b'x-request-id', b'req_e2e5b03b244949c6c7f24c0404d2d6e8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163edebc2b4229-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:00:53.866 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:00:53.866 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:00:53.866 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:00:53.866 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:00:53.866 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:00:53.867 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:00:53.867 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:00:53.868 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:00:53.869 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:00:53.869 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:01:06.513 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'I would like to order food.'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:01:06.515 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:01:06.516 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:01:06.516 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:01:06.541 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A707A00>
2024-10-12 05:01:06.541 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022319950740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:01:06.575 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A7079D0>
2024-10-12 05:01:06.575 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:01:06.575 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:01:06.575 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:01:06.576 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:01:06.576 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:01:07.093 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:01:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'153'), (b'x-ratelimit-remaining-tokens', b'59092'), (b'x-ratelimit-reset-requests', b'5h32m46.075s'), (b'x-ratelimit-reset-tokens', b'908ms'), (b'x-request-id', b'req_6252402fae20f0c50f0004385e2a1a68'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163f2e7d774204-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:01:07.094 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:01:07.095 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:01:07.095 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:01:07.095 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:01:07.095 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:01:07.096 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:01:07.097 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:01:07.097 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:01:07.841 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:01:07.841 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:01:07.843 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:01:07.899 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:01:07.900 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:01:07.903 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:01:07.918 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:01:08.627 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.72 seconds
2024-10-12 05:01:08.641 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'I would like to order food.'}, {'role': 'assistant', 'content': "Great! What would you like to order? Please let me know the items and any modifications or customizations you'd like."}, {'role': 'user', 'content': 'Please, can I have a listen to it?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:01:08.642 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:01:08.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:01:08.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:01:08.643 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:01:08.643 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:01:08.688 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:01:09 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'152'), (b'x-ratelimit-remaining-tokens', b'59052'), (b'x-ratelimit-reset-requests', b'5h39m56.011s'), (b'x-ratelimit-reset-tokens', b'948ms'), (b'x-request-id', b'req_a888260a306f4472fe3e1a5e444932d1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163f3b6e844204-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:01:08.689 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:01:08.689 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:01:08.689 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:01:08.689 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:01:08.689 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:01:08.689 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:01:08.690 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:01:08.690 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:01:08.690 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:01:08.690 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:01:13.869 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'I would like to order food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order? Please let me know the items and any customizations you have in mind.'}, {'role': 'user', 'content': 'Please can I have this sandwich?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:01:13.872 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:01:13.872 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:01:13.872 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:01:13.892 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC594F430>
2024-10-12 05:01:13.892 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027AAF62C740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:01:13.906 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC594F400>
2024-10-12 05:01:13.906 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:01:13.907 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:01:13.907 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:01:13.907 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:01:13.907 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:01:13.953 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:01:14 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'151'), (b'x-ratelimit-remaining-tokens', b'59059'), (b'x-ratelimit-reset-requests', b'5h47m2.742s'), (b'x-ratelimit-reset-tokens', b'941ms'), (b'x-request-id', b'req_05fa825bcc689b78f0a6084888576c83'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163f5c4d2241f8-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:01:13.953 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:01:13.954 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:01:13.954 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:01:13.954 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:01:13.954 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:01:13.954 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:01:13.954 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:01:13.955 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:01:13.955 - RealTimeSTT: openai._base_client - DEBUG - 0 retries left
2024-10-12 05:01:13.955 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:01:28.691 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your food order today?'}, {'role': 'user', 'content': 'I would like to order food.'}, {'role': 'assistant', 'content': "Great! What would you like to order? Please let me know the items and any modifications or customizations you'd like."}, {'role': 'user', 'content': 'Please, can I have a listen to it?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:01:28.693 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:01:28.694 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:01:28.694 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:01:28.706 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231B7275B0>
2024-10-12 05:01:28.706 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022319950740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:01:28.738 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002231A706290>
2024-10-12 05:01:28.738 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:01:28.739 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:01:28.739 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:01:28.739 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:01:28.739 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:01:31.166 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:01:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'2369'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'150'), (b'x-ratelimit-remaining-tokens', b'59052'), (b'x-ratelimit-reset-requests', b'5h53m59.91s'), (b'x-ratelimit-reset-tokens', b'948ms'), (b'x-request-id', b'req_fc6628470b092599a35e040a9b3cb662'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163fb9099c43f3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:01:31.167 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:01:31.167 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:01:31.167 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:01:31.167 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:01:31.168 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:01:31.168 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:01:31.176 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:01:31.176 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:01:31.179 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:01:33.956 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today?'}, {'role': 'user', 'content': 'I would like to order food.'}, {'role': 'assistant', 'content': 'Great! What would you like to order? Please let me know the items and any customizations you have in mind.'}, {'role': 'user', 'content': 'Please can I have this sandwich?'}], 'model': 'gpt-4o-mini'}}
2024-10-12 05:01:33.958 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:01:33.959 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:01:33.959 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:01:33.981 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC5990AC0>
2024-10-12 05:01:33.981 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027AAF62C740> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:01:33.993 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027AC5990A90>
2024-10-12 05:01:33.993 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:01:33.993 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:01:33.993 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:01:33.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:01:33.994 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:01:34.032 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:01:35 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'491'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'59059'), (b'x-ratelimit-reset-requests', b'6h1m6.66s'), (b'x-ratelimit-reset-tokens', b'941ms'), (b'x-request-id', b'req_d0f49d3e95e2ff6f4137e3f0111302ca'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d163fd9dc1d4414-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:01:34.033 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:01:34.033 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:01:34.034 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:01:34.034 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:01:34.034 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:01:34.034 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:01:34.034 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:01:34.035 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-12 05:02:29.392 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:02:29.402 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:02:29.407 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:02:29.408 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:02:29.644 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:02:29.649 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:02:29.652 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:02:29.656 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:02:29.657 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:02:29.661 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:02:29.662 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:02:29.662 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:02:29.974 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:02:29.976 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:02:29.976 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:02:34.706 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:02:34.707 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:02:34.707 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:02:34.707 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:02:35.316 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:02:36.262 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:02:36.262 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:02:36.262 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:02:36.262 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:02:37.542 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:02:37.542 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:02:37.543 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:02:37.795 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:02:37.798 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:02:37.804 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:02:37.861 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:02:38.390 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.59 seconds
2024-10-12 05:02:38.400 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 05:02:38.416 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:02:38.460 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C6355D2530>
2024-10-12 05:02:38.461 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6202EC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:02:38.471 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C635619BA0>
2024-10-12 05:02:38.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:02:38.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:02:38.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:02:38.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:02:38.472 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:02:39.207 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:02:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'662'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'100'), (b'x-ratelimit-remaining-tokens', b'9114'), (b'x-ratelimit-reset-requests', b'11h56m50.865s'), (b'x-ratelimit-reset-tokens', b'5.316s'), (b'x-request-id', b'req_265fee39f0d687a92586aa36f095b230'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NeVZbVGL1mkpWUdqI5kPWzKZ64lU2Qce104HbuSZcGQ-1728727360-1.0.1.1-2gNOkxUmRJ8DVrX7JuXs3PfAoT99Jpl5S2ZJkBvGrYyO6JHfGY21ewxjKTfLlKNWs.yE5fYeHLv8gpHH2H6bnQ; path=/; expires=Sat, 12-Oct-24 10:32:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kcETxZKRUeHI.dlS4YPcRP.uwUbyP5UmEnzMjRYK9rk-1728727360219-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16416cdac20f39-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:02:39.208 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:02:39.209 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:02:39.209 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:02:39.210 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:02:39.210 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:02:39.210 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:02:39.213 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:02:39.214 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:02:39.215 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:02:41.441 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:02:41.441 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:02:41.441 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:02:41.442 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:02:43.752 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:02:43.753 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:02:43.753 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:02:43.814 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:02:43.816 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:02:43.817 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:02:43.871 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:02:44.460 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 05:02:44.474 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes, what is on your menu?'}], 'model': 'gpt-4o'}}
2024-10-12 05:02:44.475 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:02:44.475 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:02:44.476 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:02:44.508 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C635675CC0>
2024-10-12 05:02:44.508 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6202EC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:02:44.525 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C635675C90>
2024-10-12 05:02:44.526 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:02:44.526 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:02:44.527 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:02:44.527 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:02:44.527 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:02:46.225 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:02:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1649'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'99'), (b'x-ratelimit-remaining-tokens', b'9092'), (b'x-ratelimit-reset-requests', b'12h3m56.827s'), (b'x-ratelimit-reset-tokens', b'5.448s'), (b'x-request-id', b'req_878951b5db5fa03b9e5bc140e4587833'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164192afbb5e7e-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:02:46.226 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:02:46.226 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:02:46.226 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:02:46.227 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:02:46.227 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:02:46.227 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:02:46.231 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:02:46.231 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:02:46.233 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:02:48.872 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:02:48.872 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:02:48.872 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:02:48.873 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:02:52.261 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:02:52.262 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:02:52.263 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:02:52.351 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:02:52.354 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:02:52.362 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:02:52.391 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:02:52.969 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 05:02:52.983 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes, what is on your menu?'}, {'role': 'assistant', 'content': "Here's what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nWhat would you like to order?"}, {'role': 'user', 'content': 'Um, can I get Ebola?'}], 'model': 'gpt-4o'}}
2024-10-12 05:02:52.985 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:02:52.986 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:02:52.986 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:02:52.995 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C6356770D0>
2024-10-12 05:02:52.996 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6202EC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:02:53.019 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C635677280>
2024-10-12 05:02:53.019 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:02:53.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:02:53.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:02:53.020 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:02:53.020 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:02:53.785 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:02:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'703'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'98'), (b'x-ratelimit-remaining-tokens', b'8904'), (b'x-ratelimit-reset-requests', b'12h11m0.323s'), (b'x-ratelimit-reset-tokens', b'6.576s'), (b'x-request-id', b'req_b3174fb663038b32de4c8230e98d57df'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1641c7c827423d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:02:53.786 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:02:53.786 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:02:53.787 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:02:53.787 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:02:53.787 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:02:53.787 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:02:53.789 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:02:53.789 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:02:53.791 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:02:56.232 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:02:56.232 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:02:56.232 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:02:56.233 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:02:57.762 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:02:57.762 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:02:57.763 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:02:57.831 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:02:57.832 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:02:57.835 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:02:57.842 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:02:58.440 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-10-12 05:02:58.466 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes, what is on your menu?'}, {'role': 'assistant', 'content': "Here's what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nWhat would you like to order?"}, {'role': 'user', 'content': 'Um, can I get Ebola?'}, {'role': 'assistant', 'content': "I'm here to help with any questions about our menu or to take your order. Would you like to try something from our menu today?"}, {'role': 'user', 'content': 'Can I get it burger?'}], 'model': 'gpt-4o'}}
2024-10-12 05:02:58.468 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:02:58.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:02:58.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:02:58.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:02:58.469 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:02:58.506 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:02:59 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'97'), (b'x-ratelimit-remaining-tokens', b'8730'), (b'x-ratelimit-reset-requests', b'12h18m6.887s'), (b'x-ratelimit-reset-tokens', b'7.614s'), (b'x-request-id', b'req_40d0bfc066fe7011b5d0bbe71d032e88'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1641e9de65423d-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:02:58.506 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:02:58.507 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:02:58.507 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:02:58.507 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:02:58.507 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:02:58.507 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:02:58.507 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:02:58.510 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:02:58.510 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:02:58.510 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:03:18.510 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes, what is on your menu?'}, {'role': 'assistant', 'content': "Here's what we have on our menu:\n\n- Burger: Delicious beef burger\n- Fries: Crispy golden fries\n- Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n- Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n- Avocado Toast: Fresh avocado spread on toasted bread\n- BLT Sandwich: Bacon, lettuce, and tomato sandwich\n- Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n- Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n- Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n- Spinach & Egg Wrap: Healthy spinach and egg wrap\n- Coffee: Freshly brewed coffee\n- Classic Hot Dog: Hot dog with ketchup and mustard\n\nWhat would you like to order?"}, {'role': 'user', 'content': 'Um, can I get Ebola?'}, {'role': 'assistant', 'content': "I'm here to help with any questions about our menu or to take your order. Would you like to try something from our menu today?"}, {'role': 'user', 'content': 'Can I get it burger?'}], 'model': 'gpt-4o'}}
2024-10-12 05:03:18.511 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:03:18.512 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:03:18.512 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:03:18.533 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C63567F340>
2024-10-12 05:03:18.533 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6202EC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:03:18.547 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C6367641F0>
2024-10-12 05:03:18.547 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:03:18.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:03:18.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:03:18.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:03:18.548 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:03:19.369 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:03:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'762'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'96'), (b'x-ratelimit-remaining-tokens', b'8865'), (b'x-ratelimit-reset-requests', b'12h24m58.809s'), (b'x-ratelimit-reset-tokens', b'6.81s'), (b'x-request-id', b'req_9d055f754c8da99f09f2ed5a9ef68e4f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1642675c42186d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:03:19.370 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:03:19.370 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:03:19.371 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:03:19.371 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:03:19.371 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:03:19.371 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:03:19.373 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:03:19.373 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:03:19.376 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:04:56.257 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 05:04:56.257 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 05:04:56.262 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 05:04:57.008 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 05:04:57.008 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 05:04:57.086 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 05:05:14.708 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:05:14.715 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:05:14.720 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:05:14.720 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:05:14.980 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:05:14.983 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:05:14.985 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:05:14.986 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:05:14.987 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:05:14.989 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:05:14.989 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:05:14.989 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:05:15.238 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:05:15.240 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:05:15.240 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:05:19.960 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:05:19.961 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:05:19.961 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:05:19.961 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:05:20.469 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:05:25.780 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:05:25.780 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:05:25.780 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:05:25.781 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:05:26.930 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:05:26.930 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:05:26.931 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:05:27.013 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:05:27.017 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:05:27.028 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:05:27.059 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:05:27.618 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-10-12 05:05:27.627 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 05:05:27.639 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:05:27.676 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B429C00>
2024-10-12 05:05:27.676 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:05:27.688 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B429BD0>
2024-10-12 05:05:27.688 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:05:27.688 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:05:27.688 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:05:27.688 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:05:27.689 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:05:28.376 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:05:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'642'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'95'), (b'x-ratelimit-remaining-tokens', b'9114'), (b'x-ratelimit-reset-requests', b'12h30m1.665s'), (b'x-ratelimit-reset-tokens', b'5.316s'), (b'x-request-id', b'req_65ac43ca40e326aea29c4fd130e9fe57'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AU3kHg_.7lQM5vLpv02KV3_WlId1ulmwmVEdq5wtOqQ-1728727529-1.0.1.1-GXhW1hHlehsYL8G9TNE_Iezflnyha1rFnpUalze0TbY81AiRR2nT5Cvmk4M0iwkXDKnvsJfcZOPyiiCTmeoEUA; path=/; expires=Sat, 12-Oct-24 10:35:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=XG3WRUizjUvovzCa05vCQJV4.t3N377cml6J5RM1Hrg-1728727529393-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16458e79c06a55-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:05:28.378 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:05:28.378 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:05:28.379 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:05:28.379 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:05:28.379 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:05:28.379 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:05:28.382 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:05:28.383 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:05:28.384 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:05:31.669 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:05:31.669 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:05:31.670 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:05:31.670 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:05:33.210 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:05:33.210 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:05:33.211 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:05:33.227 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:05:33.230 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:05:33.231 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:05:33.269 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:05:33.774 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.54 seconds
2024-10-12 05:05:33.787 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o'}}
2024-10-12 05:05:33.789 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:05:33.790 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:05:33.790 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:05:33.816 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B485E40>
2024-10-12 05:05:33.816 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:05:33.827 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B485E10>
2024-10-12 05:05:33.827 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:05:33.828 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:05:33.828 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:05:33.828 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:05:33.828 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:05:34.587 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:05:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'704'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'94'), (b'x-ratelimit-remaining-tokens', b'9097'), (b'x-ratelimit-reset-requests', b'12h37m7.526s'), (b'x-ratelimit-reset-tokens', b'5.418s'), (b'x-request-id', b'req_4e2480974cfed8c46ac256abb08565df'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1645b4d86a42c9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:05:34.588 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:05:34.588 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:05:34.589 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:05:34.589 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:05:34.589 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:05:34.589 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:05:34.591 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:05:34.591 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:05:34.593 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:05:39.289 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:05:39.289 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:05:39.289 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:05:39.289 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:05:41.329 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:05:41.329 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:05:41.330 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:05:41.401 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:05:41.402 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:05:41.419 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:05:41.459 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:05:42.026 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.62 seconds
2024-10-12 05:05:42.041 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}], 'model': 'gpt-4o'}}
2024-10-12 05:05:42.043 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:05:42.043 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:05:42.043 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:05:42.052 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B48E050>
2024-10-12 05:05:42.053 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:05:42.066 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B48DFC0>
2024-10-12 05:05:42.066 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:05:42.067 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:05:42.067 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:05:42.067 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:05:42.067 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:05:42.982 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:05:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'806'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'93'), (b'x-ratelimit-remaining-tokens', b'9064'), (b'x-ratelimit-reset-requests', b'12h44m11.326s'), (b'x-ratelimit-reset-tokens', b'5.616s'), (b'x-request-id', b'req_7ecdc62ad524690a504ed7a3962e988d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1645e859ae7cee-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:05:42.982 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:05:42.983 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:05:42.983 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:05:42.983 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:05:42.983 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:05:42.984 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:05:42.985 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:05:42.985 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:05:42.989 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:05:46.839 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:05:46.839 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:05:46.839 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:05:46.839 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:05:47.989 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:05:47.989 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:05:47.990 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:05:48.032 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:05:48.034 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:05:48.049 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:05:48.054 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:05:48.587 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.55 seconds
2024-10-12 05:05:48.604 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}, {'role': 'assistant', 'content': 'Sure! Would you like to add any customizations to your burger?'}, {'role': 'user', 'content': 'No.'}], 'model': 'gpt-4o'}}
2024-10-12 05:05:48.605 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:05:48.605 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:05:48.605 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:05:48.617 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B48ED10>
2024-10-12 05:05:48.617 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:05:48.629 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B48ECE0>
2024-10-12 05:05:48.629 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:05:48.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:05:48.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:05:48.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:05:48.630 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:05:49.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:05:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'671'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'92'), (b'x-ratelimit-remaining-tokens', b'9045'), (b'x-ratelimit-reset-requests', b'12h51m16.713s'), (b'x-ratelimit-reset-tokens', b'5.73s'), (b'x-request-id', b'req_41cc4b178c8a186f447718195e67f06a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1646115a867291-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:05:49.361 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:05:49.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:05:49.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:05:49.361 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:05:49.361 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:05:49.362 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:05:49.363 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:05:49.363 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:05:49.365 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:05:51.769 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:05:51.769 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:05:51.769 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:05:51.770 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:05:52.920 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:05:52.920 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:05:52.921 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:05:52.995 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:05:52.997 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:05:52.998 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:05:53.049 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:05:53.555 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.56 seconds
2024-10-12 05:05:53.576 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}, {'role': 'assistant', 'content': 'Sure! Would you like to add any customizations to your burger?'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, a regular burger it is. Would you like to add anything else to your order?'}, {'role': 'user', 'content': 'Nope.'}], 'model': 'gpt-4o'}}
2024-10-12 05:05:53.577 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:05:53.578 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:05:53.578 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:05:53.578 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:05:53.578 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:05:53.625 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:05:54 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'91'), (b'x-ratelimit-remaining-tokens', b'8929'), (b'x-ratelimit-reset-requests', b'12h58m23.817s'), (b'x-ratelimit-reset-tokens', b'6.42s'), (b'x-request-id', b'req_705c4f9a0b48f6aa5339bf6696711720'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1646304cfe7291-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:05:53.625 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:05:53.625 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:05:53.626 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:05:53.626 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:05:53.626 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:05:53.626 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:05:53.626 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:05:53.627 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:05:53.627 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:05:53.627 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:06:13.628 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}, {'role': 'assistant', 'content': 'Sure! Would you like to add any customizations to your burger?'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, a regular burger it is. Would you like to add anything else to your order?'}, {'role': 'user', 'content': 'Nope.'}], 'model': 'gpt-4o'}}
2024-10-12 05:06:13.630 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:06:13.631 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:06:13.631 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:06:13.660 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B49E410>
2024-10-12 05:06:13.660 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:06:13.675 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B49E3E0>
2024-10-12 05:06:13.676 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:06:13.676 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:06:13.676 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:06:13.676 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:06:13.676 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:06:15.339 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:06:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1604'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'90'), (b'x-ratelimit-remaining-tokens', b'9021'), (b'x-ratelimit-reset-requests', b'13h5m15.675s'), (b'x-ratelimit-reset-tokens', b'5.874s'), (b'x-request-id', b'req_3a7045e6dc19750117da814e02d23e31'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1646adebddc346-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:06:15.340 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:06:15.341 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:06:15.341 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:06:15.341 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:06:15.342 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:06:15.342 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:06:15.345 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:06:15.345 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:06:15.347 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:06:40.149 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:06:40.149 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:06:40.149 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:06:40.150 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:06:41.299 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:06:41.299 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:06:41.300 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:06:41.371 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:06:41.373 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:06:41.390 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:06:41.429 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:06:41.970 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.60 seconds
2024-10-12 05:06:42.000 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}, {'role': 'assistant', 'content': 'Sure! Would you like to add any customizations to your burger?'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, a regular burger it is. Would you like to add anything else to your order?'}, {'role': 'user', 'content': 'Nope.'}, {'role': 'assistant', 'content': 'Got it! Here\'s your order:\n\n```json\n{\n    "ORDER": {\n        "Burger": {}\n    },\n    "output": "DONE"\n}\n```\n\nThank you for your order! If you need anything else, feel free to ask.'}, {'role': 'user', 'content': 'Thank you.'}], 'model': 'gpt-4o'}}
2024-10-12 05:06:42.006 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:06:42.007 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:06:42.007 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:06:42.047 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4B49F6A0>
2024-10-12 05:06:42.047 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:06:42.060 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4C4C36A0>
2024-10-12 05:06:42.061 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:06:42.061 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:06:42.061 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:06:42.062 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:06:42.062 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:06:42.598 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:06:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'90'), (b'x-ratelimit-remaining-tokens', b'8972'), (b'x-ratelimit-reset-requests', b'13h11m59.283s'), (b'x-ratelimit-reset-tokens', b'6.168s'), (b'x-request-id', b'req_550eec156c186cc1ab0480ca154bc8cc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16475f58725e6a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:06:42.599 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:06:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:06:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:06:42.600 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:06:42.600 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:06:42.600 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:06:42.601 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:06:42.601 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:06:42.603 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:07:09.529 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:07:09.529 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:07:09.529 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:07:09.530 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:07:10.679 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:07:10.679 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:07:10.680 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:07:10.683 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:07:10.686 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:07:10.704 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:07:10.739 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:07:11.244 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.56 seconds
2024-10-12 05:07:11.268 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What would you like to order today from our menu?'}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Sure! Can you please let me know what you'd like to order? We have burgers, sandwiches, salads, and more."}, {'role': 'user', 'content': 'Can I get a burger?'}, {'role': 'assistant', 'content': 'Sure! Would you like to add any customizations to your burger?'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, a regular burger it is. Would you like to add anything else to your order?'}, {'role': 'user', 'content': 'Nope.'}, {'role': 'assistant', 'content': 'Got it! Here\'s your order:\n\n```json\n{\n    "ORDER": {\n        "Burger": {}\n    },\n    "output": "DONE"\n}\n```\n\nThank you for your order! If you need anything else, feel free to ask.'}, {'role': 'user', 'content': 'Thank you.'}, {'role': 'assistant', 'content': "You're welcome! Have a great day!"}, {'role': 'user', 'content': 'Thanks.'}], 'model': 'gpt-4o'}}
2024-10-12 05:07:11.269 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:07:11.269 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:07:11.270 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:07:11.292 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4C4B4EB0>
2024-10-12 05:07:11.292 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BF3602C6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:07:11.322 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF4C4B4E80>
2024-10-12 05:07:11.322 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:07:11.322 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:07:11.323 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:07:11.323 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:07:11.323 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:07:12.096 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:07:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'718'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'89'), (b'x-ratelimit-remaining-tokens', b'8960'), (b'x-ratelimit-reset-requests', b'13h18m42.026s'), (b'x-ratelimit-reset-tokens', b'6.24s'), (b'x-request-id', b'req_7c8b234b50fe513a7dfba1a9f61903bc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1648163d627ce4-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:07:12.096 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:07:12.096 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:07:12.096 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:07:12.096 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:07:12.096 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:07:12.096 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:07:12.098 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:07:12.098 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:07:12.099 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:07:59.382 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:07:59.389 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:07:59.397 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:07:59.397 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:07:59.627 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:07:59.630 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:07:59.632 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:07:59.633 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:07:59.634 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:07:59.636 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:07:59.636 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:07:59.637 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:07:59.908 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:07:59.911 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:07:59.911 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:08:04.839 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:08:04.839 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:08:04.840 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:08:04.840 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:08:05.354 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:08:06.574 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:08:06.574 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:08:06.575 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:08:06.575 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:08:07.723 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:08:07.724 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:08:07.725 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:08:07.729 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:08:07.731 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:08:07.747 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:08:07.783 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:08:09.054 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.32 seconds
2024-10-12 05:08:09.063 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 05:08:09.078 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:08:09.119 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FE69C60>
2024-10-12 05:08:09.119 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:08:09.131 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FE69C30>
2024-10-12 05:08:09.131 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:08:09.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:08:09.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:08:09.132 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:08:09.132 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:08:10.144 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:08:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'961'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'88'), (b'x-ratelimit-remaining-tokens', b'9114'), (b'x-ratelimit-reset-requests', b'13h24m56.219s'), (b'x-ratelimit-reset-tokens', b'5.316s'), (b'x-request-id', b'req_bda057e1e3831affa761e05a4ca46ea9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1EScfuTW89NK4HCxOza3knQXi78wW5F0ziz64mYz3jc-1728727691-1.0.1.1-zn4bs5.FTjEL1fQjhh50phjEo1DmS6LhBQU19SoR9LTIhPzulV_NfSBDX_hHiTVYKGlFwu9UF3Ae8le3E2xWSQ; path=/; expires=Sat, 12-Oct-24 10:38:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DXwFz7kklAsCrtgp2IQgxAxQEkpjiB0kh_GvQKn2hIU-1728727691166-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d16497f8f01c3ee-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:08:10.145 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:08:10.146 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:08:10.147 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:08:10.147 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:08:10.147 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:08:10.147 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:08:10.151 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:08:10.151 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:08:10.154 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:08:14.053 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:08:14.053 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:08:14.054 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:08:14.054 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:08:16.614 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:08:16.614 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:08:16.615 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:08:16.621 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:08:16.624 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:08:16.638 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:08:16.683 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:08:17.262 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 05:08:17.274 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}], 'model': 'gpt-4o'}}
2024-10-12 05:08:17.276 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:08:17.276 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:08:17.276 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:08:17.302 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FEC5D50>
2024-10-12 05:08:17.302 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:08:17.313 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FEC5D20>
2024-10-12 05:08:17.313 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:08:17.314 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:08:17.314 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:08:17.314 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:08:17.314 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:08:18.271 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:08:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'902'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'87'), (b'x-ratelimit-remaining-tokens', b'9077'), (b'x-ratelimit-reset-requests', b'13h32m0.034s'), (b'x-ratelimit-reset-tokens', b'5.538s'), (b'x-request-id', b'req_25f0884633a190b129609803c4ecd36f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1649b2afbd8c6b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:08:18.272 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:08:18.272 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:08:18.273 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:08:18.273 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:08:18.273 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:08:18.273 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:08:18.275 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:08:18.275 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:08:18.277 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:08:20.653 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:08:20.654 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:08:20.654 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:08:20.654 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:08:22.894 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:08:22.894 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:08:22.895 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:08:22.923 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:08:22.926 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:08:22.929 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:08:22.953 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:08:23.587 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 05:08:23.601 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to add anything else to your order?'}, {'role': 'user', 'content': "Yeah, maybe it's better good too."}], 'model': 'gpt-4o'}}
2024-10-12 05:08:23.602 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:08:23.603 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:08:23.603 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:08:23.617 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FECE320>
2024-10-12 05:08:23.617 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:08:23.629 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FEC6110>
2024-10-12 05:08:23.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:08:23.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:08:23.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:08:23.630 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:08:23.630 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:08:24.610 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:08:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'931'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'86'), (b'x-ratelimit-remaining-tokens', b'9051'), (b'x-ratelimit-reset-requests', b'13h39m5.716s'), (b'x-ratelimit-reset-tokens', b'5.694s'), (b'x-request-id', b'req_de09bfa1ffe81cb6731a485f1bad0482'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1649da2a7641f5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:08:24.611 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:08:24.611 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:08:24.612 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:08:24.612 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:08:24.612 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:08:24.612 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:08:24.614 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:08:24.614 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:08:24.617 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:08:29.614 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:08:29.614 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:08:29.614 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:08:29.615 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:08:31.853 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:08:31.853 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:08:31.854 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:08:31.880 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:08:31.883 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:08:31.884 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:08:31.912 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:08:32.545 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 05:08:32.563 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to add anything else to your order?'}, {'role': 'user', 'content': "Yeah, maybe it's better good too."}, {'role': 'assistant', 'content': 'Sure thing! Just to confirm, you have ordered fries so far. Would you like to add anything else to your order or any specific modifications?'}, {'role': 'user', 'content': 'Yes, I would like to have a burger.'}], 'model': 'gpt-4o'}}
2024-10-12 05:08:32.565 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:08:32.566 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:08:32.566 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:08:32.584 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FECEDA0>
2024-10-12 05:08:32.585 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:08:32.597 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FED7FA0>
2024-10-12 05:08:32.597 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:08:32.598 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:08:32.598 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:08:32.598 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:08:32.598 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:08:34.094 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:08:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1427'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'85'), (b'x-ratelimit-remaining-tokens', b'9005'), (b'x-ratelimit-reset-requests', b'13h46m8.739s'), (b'x-ratelimit-reset-tokens', b'5.97s'), (b'x-request-id', b'req_ea6fb9c115d3436a0efbbc7250e1c361'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164a122bc4440d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:08:34.095 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:08:34.095 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:08:34.096 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:08:34.096 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:08:34.096 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:08:34.096 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:08:34.099 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:08:34.099 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:08:34.102 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:08:43.623 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:08:43.623 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:08:43.623 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:08:43.624 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:08:47.532 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:08:47.533 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:08:47.533 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:08:47.623 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:08:47.625 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:08:47.645 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:08:47.653 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:08:48.284 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 05:08:48.311 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to add anything else to your order?'}, {'role': 'user', 'content': "Yeah, maybe it's better good too."}, {'role': 'assistant', 'content': 'Sure thing! Just to confirm, you have ordered fries so far. Would you like to add anything else to your order or any specific modifications?'}, {'role': 'user', 'content': 'Yes, I would like to have a burger.'}, {'role': 'assistant', 'content': 'Perfect! Here\'s what you have so far in your order:\n\n{\n    "ORDER": {\n        "Fries": {},\n        "Burger": {}\n    },\n    "output": "Would you like any modifications to your burger or fries, or is there anything else you\'d like to add?"\n}'}, {'role': 'user', 'content': "Um, I'll get some extra cheese on my burger."}], 'model': 'gpt-4o'}}
2024-10-12 05:08:48.313 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:08:48.313 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:08:48.313 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:08:48.330 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FECEB90>
2024-10-12 05:08:48.330 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:08:48.367 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FED7C40>
2024-10-12 05:08:48.367 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:08:48.367 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:08:48.367 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:08:48.368 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:08:48.368 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:08:48.409 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:08:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'84'), (b'x-ratelimit-remaining-tokens', b'8932'), (b'x-ratelimit-reset-requests', b'13h53m4.977s'), (b'x-ratelimit-reset-tokens', b'6.408s'), (b'x-request-id', b'req_916910d97be88eedb385dd13b0fc7540'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164a74bd9141bb-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:08:48.409 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:08:48.410 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:08:48.410 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:08:48.410 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:08:48.410 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:08:48.410 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:08:48.410 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:08:48.411 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:08:48.411 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:08:48.411 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:09:08.411 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to add anything else to your order?'}, {'role': 'user', 'content': "Yeah, maybe it's better good too."}, {'role': 'assistant', 'content': 'Sure thing! Just to confirm, you have ordered fries so far. Would you like to add anything else to your order or any specific modifications?'}, {'role': 'user', 'content': 'Yes, I would like to have a burger.'}, {'role': 'assistant', 'content': 'Perfect! Here\'s what you have so far in your order:\n\n{\n    "ORDER": {\n        "Fries": {},\n        "Burger": {}\n    },\n    "output": "Would you like any modifications to your burger or fries, or is there anything else you\'d like to add?"\n}'}, {'role': 'user', 'content': "Um, I'll get some extra cheese on my burger."}], 'model': 'gpt-4o'}}
2024-10-12 05:09:08.413 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:09:08.414 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:09:08.414 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:09:08.429 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FEE2260>
2024-10-12 05:09:08.430 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:09:08.442 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029D9FEE2230>
2024-10-12 05:09:08.442 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:09:08.443 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:09:08.443 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:09:08.443 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:09:08.443 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:09:10.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:09:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1717'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'83'), (b'x-ratelimit-remaining-tokens', b'8932'), (b'x-ratelimit-reset-requests', b'13h59m56.895s'), (b'x-ratelimit-reset-tokens', b'6.408s'), (b'x-request-id', b'req_684cc38feedc5b17a954979acb482bbd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164af2399641ad-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:09:10.214 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:09:10.214 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:09:10.215 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:09:10.215 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:09:10.215 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:09:10.215 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:09:10.218 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:09:10.218 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:09:10.220 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:09:21.383 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:09:21.383 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:09:21.383 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:09:21.384 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:09:23.433 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:09:23.433 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:09:23.434 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:09:23.474 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:09:23.478 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:09:23.493 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:09:23.494 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:09:24.106 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 05:09:24.132 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! What would you like to order today? We have items like hamburgers, fries, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'I would like to get some fries.'}, {'role': 'assistant', 'content': 'Great choice! Would you like to add anything else to your order?'}, {'role': 'user', 'content': "Yeah, maybe it's better good too."}, {'role': 'assistant', 'content': 'Sure thing! Just to confirm, you have ordered fries so far. Would you like to add anything else to your order or any specific modifications?'}, {'role': 'user', 'content': 'Yes, I would like to have a burger.'}, {'role': 'assistant', 'content': 'Perfect! Here\'s what you have so far in your order:\n\n{\n    "ORDER": {\n        "Fries": {},\n        "Burger": {}\n    },\n    "output": "Would you like any modifications to your burger or fries, or is there anything else you\'d like to add?"\n}'}, {'role': 'user', 'content': "Um, I'll get some extra cheese on my burger."}, {'role': 'assistant', 'content': 'Got it! Your updated order is:\n\n{\n    "ORDER": {\n        "Fries": {},\n        "Burger": {"Cheese": "extra"}\n    },\n    "output": "Anything else, or would you like to complete your order?"\n}'}, {'role': 'user', 'content': 'Yes, my order is complete.'}], 'model': 'gpt-4o'}}
2024-10-12 05:09:24.134 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:09:24.135 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:09:24.135 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:09:24.172 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029DA0EFB4F0>
2024-10-12 05:09:24.172 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029D8AB206C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:09:24.188 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029DA0EFB4C0>
2024-10-12 05:09:24.188 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:09:24.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:09:24.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:09:24.189 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:09:24.189 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:09:25.090 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:09:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'843'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'82'), (b'x-ratelimit-remaining-tokens', b'8877'), (b'x-ratelimit-reset-requests', b'14h6m53.153s'), (b'x-ratelimit-reset-tokens', b'6.738s'), (b'x-request-id', b'req_07a62d4932993738db95ac7e074aeda0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164b54af268cb7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:09:25.091 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:09:25.091 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:09:25.091 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:09:25.092 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:09:25.092 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:09:25.092 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:09:41.733 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:09:41.733 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:09:41.734 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 05:09:58.283 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:09:58.290 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:09:58.296 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:09:58.296 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:09:58.641 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:09:58.644 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:09:58.646 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:09:58.648 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:09:58.649 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:09:58.650 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:09:58.651 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:09:58.651 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:09:58.956 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:09:58.958 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:09:58.958 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:10:03.774 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:10:03.775 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:10:03.775 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:10:03.775 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:10:04.340 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:10:05.502 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:05.502 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:05.502 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:10:05.503 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:10:06.653 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:10:06.653 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:10:06.654 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:10:06.716 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:10:06.719 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:10:06.721 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:10:06.721 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:10:08.027 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.31 seconds
2024-10-12 05:10:08.036 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 05:10:08.049 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:10:08.062 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D3610C0>
2024-10-12 05:10:08.062 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:10:08.074 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D429CF0>
2024-10-12 05:10:08.074 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:10:08.074 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:10:08.074 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:10:08.075 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:10:08.075 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:10:09.075 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:10:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'951'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'81'), (b'x-ratelimit-remaining-tokens', b'9114'), (b'x-ratelimit-reset-requests', b'14h13m21.267s'), (b'x-ratelimit-reset-tokens', b'5.316s'), (b'x-request-id', b'req_526b074bd85fc9242359a7aa94694fb8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=APhtHsvgisXqsHK2sIjwmWj_fgEGUvEf.3r6RpW88qs-1728727810-1.0.1.1-KYyp.GiD.ZMXbtf0K9noWQJqrvKe1JiRQBqgJd7WXGrMNyEllwIV0E6xzD7t70e3KyfRK.pY9X1wYHvGupfODA; path=/; expires=Sat, 12-Oct-24 10:40:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=_Pc507.EAQ3xvBuowMTtQShTtrnkijTJU4rKppSFLvs-1728727810099-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164c66ee188ce8-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:10:09.077 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:10:09.077 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:10:09.078 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:10:09.078 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:10:09.078 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:10:09.078 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:10:09.082 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:10:09.082 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:10:09.084 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:10:11.452 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:11.453 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:11.453 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:10:11.453 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:10:13.952 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:10:13.952 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:10:13.953 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:10:14.040 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:10:14.043 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:10:14.055 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:10:14.081 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:10:14.672 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 05:10:14.683 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your order today? We have a variety of items such as burgers, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'Hi, I wanted to get a cheeseburger.'}], 'model': 'gpt-4o'}}
2024-10-12 05:10:14.684 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:10:14.685 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:10:14.685 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:10:14.707 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D485E10>
2024-10-12 05:10:14.708 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:10:14.721 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D485DE0>
2024-10-12 05:10:14.721 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:10:14.722 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:10:14.722 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:10:14.722 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:10:14.723 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:10:15.609 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:10:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'830'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'80'), (b'x-ratelimit-remaining-tokens', b'9073'), (b'x-ratelimit-reset-requests', b'14h20m26.619s'), (b'x-ratelimit-reset-tokens', b'5.562s'), (b'x-request-id', b'req_c8ff159a7814cd7f5b595fdbc5ed11ab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164c907d8bc3fa-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:10:15.610 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:10:15.611 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:10:15.611 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:10:15.612 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:10:15.612 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:10:15.612 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:10:15.614 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:10:15.614 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:10:15.617 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:10:20.542 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:20.542 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:20.542 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:10:20.543 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:10:22.852 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:10:22.852 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:10:22.854 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:10:22.880 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:10:22.882 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:10:22.899 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:10:22.911 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:10:23.524 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 05:10:23.540 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your order today? We have a variety of items such as burgers, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'Hi, I wanted to get a cheeseburger.'}, {'role': 'assistant', 'content': 'Just to confirm, would you like the Bacon Cheeseburger, which comes with bacon, cheese, and lettuce? Any modifications or extras?'}, {'role': 'user', 'content': "Yes, I'll make a cheeseburger."}], 'model': 'gpt-4o'}}
2024-10-12 05:10:23.542 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:10:23.542 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:10:23.542 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:10:23.552 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D48DFC0>
2024-10-12 05:10:23.553 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:10:23.564 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D48DF60>
2024-10-12 05:10:23.565 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:10:23.565 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:10:23.565 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:10:23.565 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:10:23.565 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:10:24.135 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:10:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'79'), (b'x-ratelimit-remaining-tokens', b'9031'), (b'x-ratelimit-reset-requests', b'14h27m29.775s'), (b'x-ratelimit-reset-tokens', b'5.814s'), (b'x-request-id', b'req_dee368a36c72d5feb247e5cf8b27022c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164cc7b94e432c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:10:24.136 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:10:24.136 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:10:24.136 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:10:24.136 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:10:24.137 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:10:24.137 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:10:24.138 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:10:24.138 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:10:24.140 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:10:27.711 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:27.712 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:27.712 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:10:27.712 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:10:28.861 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:10:28.861 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:10:28.861 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:10:28.929 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:10:28.931 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:10:28.932 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:10:28.944 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:10:29.521 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.59 seconds
2024-10-12 05:10:29.541 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your order today? We have a variety of items such as burgers, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'Hi, I wanted to get a cheeseburger.'}, {'role': 'assistant', 'content': 'Just to confirm, would you like the Bacon Cheeseburger, which comes with bacon, cheese, and lettuce? Any modifications or extras?'}, {'role': 'user', 'content': "Yes, I'll make a cheeseburger."}, {'role': 'assistant', 'content': "Got it. You'll have a Bacon Cheeseburger. Would you like to add any modifications or extras to it?"}, {'role': 'user', 'content': 'No.'}], 'model': 'gpt-4o'}}
2024-10-12 05:10:29.542 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:10:29.543 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:10:29.543 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:10:29.580 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D48EC50>
2024-10-12 05:10:29.580 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:10:29.593 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D48EC20>
2024-10-12 05:10:29.593 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:10:29.593 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:10:29.593 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:10:29.594 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:10:29.594 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:10:30.283 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:10:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'641'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'78'), (b'x-ratelimit-remaining-tokens', b'9004'), (b'x-ratelimit-reset-requests', b'14h34m35.748s'), (b'x-ratelimit-reset-tokens', b'5.976s'), (b'x-request-id', b'req_390fc7cc2b97b2010ec8332bf8bb1984'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164ced697dc330-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:10:30.285 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:10:30.285 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:10:30.285 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:10:30.285 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:10:30.285 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:10:30.285 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:10:30.287 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:10:30.287 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:10:30.289 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:10:41.213 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:41.213 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:41.213 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:10:41.214 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:10:42.372 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:10:42.372 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:10:42.373 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:10:42.397 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:10:42.399 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:10:42.400 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:10:42.431 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:10:42.989 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.59 seconds
2024-10-12 05:10:43.014 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your order today? We have a variety of items such as burgers, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'Hi, I wanted to get a cheeseburger.'}, {'role': 'assistant', 'content': 'Just to confirm, would you like the Bacon Cheeseburger, which comes with bacon, cheese, and lettuce? Any modifications or extras?'}, {'role': 'user', 'content': "Yes, I'll make a cheeseburger."}, {'role': 'assistant', 'content': "Got it. You'll have a Bacon Cheeseburger. Would you like to add any modifications or extras to it?"}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, here\'s what I have for your order:\n\n{\n    "ORDER": {\n        "Bacon Cheeseburger": {}\n    },\n    "output": "Would you like anything else?"\n}'}, {'role': 'user', 'content': "That's it."}], 'model': 'gpt-4o'}}
2024-10-12 05:10:43.016 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:10:43.017 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:10:43.017 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:10:43.025 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D49D360>
2024-10-12 05:10:43.025 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:10:43.038 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D48DDB0>
2024-10-12 05:10:43.038 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:10:43.038 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:10:43.038 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:10:43.039 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:10:43.039 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:10:43.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:10:44 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'77'), (b'x-ratelimit-remaining-tokens', b'8962'), (b'x-ratelimit-reset-requests', b'14h41m34.308s'), (b'x-ratelimit-reset-tokens', b'6.228s'), (b'x-request-id', b'req_3c3a99947de4258ab21c0babbfde6f7a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164d417a1d0f3d-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:10:43.076 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:10:43.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:10:43.077 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:10:43.077 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:10:43.077 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:10:43.077 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:10:43.077 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:10:43.078 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:10:43.078 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:10:43.078 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:10:50.171 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:10:50.171 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:10:50.171 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 05:11:03.079 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with your order today? We have a variety of items such as burgers, chicken sandwiches, and more.'}, {'role': 'user', 'content': 'Hi, I wanted to get a cheeseburger.'}, {'role': 'assistant', 'content': 'Just to confirm, would you like the Bacon Cheeseburger, which comes with bacon, cheese, and lettuce? Any modifications or extras?'}, {'role': 'user', 'content': "Yes, I'll make a cheeseburger."}, {'role': 'assistant', 'content': "Got it. You'll have a Bacon Cheeseburger. Would you like to add any modifications or extras to it?"}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': 'Alright, here\'s what I have for your order:\n\n{\n    "ORDER": {\n        "Bacon Cheeseburger": {}\n    },\n    "output": "Would you like anything else?"\n}'}, {'role': 'user', 'content': "That's it."}], 'model': 'gpt-4o'}}
2024-10-12 05:11:03.081 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:11:03.081 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:11:03.082 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:11:03.090 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D49E680>
2024-10-12 05:11:03.090 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018C180CC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:11:03.101 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018C2D49E650>
2024-10-12 05:11:03.101 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:11:03.101 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:11:03.102 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:11:03.102 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:11:03.102 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:11:03.858 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:11:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'700'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'76'), (b'x-ratelimit-remaining-tokens', b'8962'), (b'x-ratelimit-reset-requests', b'14h48m26.236s'), (b'x-ratelimit-reset-tokens', b'6.228s'), (b'x-request-id', b'req_35bfd7a6941c879eb6346b4b0a07af5e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164dbedf67c461-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:11:03.859 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:11:03.859 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:11:03.859 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:11:03.860 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:11:03.860 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:11:03.860 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:11:59.861 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 05:11:59.871 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 05:11:59.877 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 05:11:59.877 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 05:12:00.087 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 05:12:00.090 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:12:00.092 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 05:12:00.094 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:12:00.095 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 05:12:00.096 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 05:12:00.098 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 05:12:00.098 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 05:12:00.361 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 05:12:00.364 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 05:12:00.364 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 05:12:05.084 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 05:12:05.085 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 05:12:05.085 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:05.085 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:05.593 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:12:11.558 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:11.558 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:11.558 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:12:11.558 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:12.708 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:12.709 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:12:12.710 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:12.750 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:12.754 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:12.755 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:12.767 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:14.073 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.32 seconds
2024-10-12 05:12:14.081 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 05:12:14.096 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:12:14.129 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90C49D50>
2024-10-12 05:12:14.129 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AB8FEAC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:12:14.141 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90C49D20>
2024-10-12 05:12:14.142 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:14.142 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:14.142 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:14.142 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:14.142 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:15.053 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:12:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'855'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'75'), (b'x-ratelimit-remaining-tokens', b'9114'), (b'x-ratelimit-reset-requests', b'14h54m27.218s'), (b'x-ratelimit-reset-tokens', b'5.316s'), (b'x-request-id', b'req_6e7d05de1e8900d20519dabf93815c84'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qFfOD.FfdvglU0wHgOpT8j0ixzQGKJDmVRVogQF7FZ8-1728727936-1.0.1.1-Nvi2alImi2oCQZoIt_6z8rMbysDpTWUa2NcVxiY7JFV2uvhmpggzKiquxV4J8aCRkddVOxwvX_qd5OCxHJVt_A; path=/; expires=Sat, 12-Oct-24 10:42:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=hDZVf1Yc3h9ngB9WfaP0c6v9nNqhjA4igdVc6fDcRDo-1728727936079-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164f7ad8dac439-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:15.054 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:12:15.054 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:15.055 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:15.055 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:15.055 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:15.056 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:12:15.059 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:15.059 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:15.062 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:12:18.078 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:18.078 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:18.078 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:12:18.078 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:19.938 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:19.938 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:12:19.940 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:20.008 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:20.011 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:20.012 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:20.067 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:20.684 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 05:12:20.694 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What can I get for you today?'}, {'role': 'user', 'content': 'Yes, I would like to get it.'}], 'model': 'gpt-4o'}}
2024-10-12 05:12:20.696 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:12:20.696 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:12:20.696 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:12:20.707 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:20.708 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:20.708 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 05:12:20.709 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90CA5F90>
2024-10-12 05:12:20.709 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AB8FEAC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:12:20.724 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90CA5F60>
2024-10-12 05:12:20.724 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:20.725 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:20.725 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:20.725 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:20.725 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:21.483 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:12:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'689'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'74'), (b'x-ratelimit-remaining-tokens', b'9096'), (b'x-ratelimit-reset-requests', b'15h1m32.618s'), (b'x-ratelimit-reset-tokens', b'5.424s'), (b'x-request-id', b'req_7f1d36610fb1e1cdfe85c120736ae801'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164fa4085e8cdd-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:21.483 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:12:21.483 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:21.484 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:21.484 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:21.484 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:21.484 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:12:21.485 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:21.485 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:22.238 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:22.238 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:12:22.239 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:22.332 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:22.335 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:22.336 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:22.367 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:22.965 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 05:12:22.992 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What can I get for you today?'}, {'role': 'user', 'content': 'Yes, I would like to get it.'}, {'role': 'assistant', 'content': "Could you please let me know which items you'd like to order from our menu?"}, {'role': 'user', 'content': "It's cheeseburger."}], 'model': 'gpt-4o'}}
2024-10-12 05:12:22.993 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:22.994 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:24.078 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:12:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1029'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'73'), (b'x-ratelimit-remaining-tokens', b'8601'), (b'x-ratelimit-reset-requests', b'15h8m42.361s'), (b'x-ratelimit-reset-tokens', b'8.393s'), (b'x-request-id', b'req_a42ebbcb91432325d3a770b5e00c3a0b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164fb238418cdd-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:24.079 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:12:24.079 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:24.079 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:24.080 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:24.080 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:24.080 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:12:24.081 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:24.081 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:24.084 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:12:27.557 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:27.558 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:27.558 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:12:27.558 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:28.708 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:28.708 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:12:28.709 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:28.725 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:28.729 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:28.730 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:28.767 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:28.836 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:28.836 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:28.837 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 05:12:29.308 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 05:12:29.344 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 05:12:29.362 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What can I get for you today?'}, {'role': 'user', 'content': 'Yes, I would like to get it.'}, {'role': 'assistant', 'content': "Could you please let me know which items you'd like to order from our menu?"}, {'role': 'user', 'content': "It's cheeseburger."}, {'role': 'assistant', 'content': "Did you mean our Bacon Cheeseburger which comes with bacon, cheese, and lettuce, or would you like a regular Burger with a cheese modification? Any specific modifications you'd like to add?"}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o'}}
2024-10-12 05:12:29.363 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:12:29.364 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:12:29.364 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:12:29.374 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90CAF430>
2024-10-12 05:12:29.375 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AB8FEAC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:12:29.387 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB90CAF460>
2024-10-12 05:12:29.388 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:29.388 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:29.388 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:29.388 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:29.388 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:29.429 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 12 Oct 2024 10:12:30 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'486'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'72'), (b'x-ratelimit-remaining-tokens', b'8723'), (b'x-ratelimit-reset-requests', b'15h15m47.948s'), (b'x-ratelimit-reset-tokens', b'7.656s'), (b'x-request-id', b'req_8cc23eda6fa91e0b6aa1ca4b2052e525'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d164fda283a17b9-EWR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:29.430 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-10-12 05:12:29.430 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:29.430 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:29.430 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:29.430 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:29.431 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests"
2024-10-12 05:12:29.431 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\openai\_base_client.py", line 967, in _request
    response.raise_for_status()
  File "C:\Python310\lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-12 05:12:29.433 - RealTimeSTT: openai._base_client - DEBUG - Retrying due to status code 429
2024-10-12 05:12:29.433 - RealTimeSTT: openai._base_client - DEBUG - 1 retry left
2024-10-12 05:12:29.433 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2024-10-12 05:12:49.434 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What can I get for you today?'}, {'role': 'user', 'content': 'Yes, I would like to get it.'}, {'role': 'assistant', 'content': "Could you please let me know which items you'd like to order from our menu?"}, {'role': 'user', 'content': "It's cheeseburger."}, {'role': 'assistant', 'content': "Did you mean our Bacon Cheeseburger which comes with bacon, cheese, and lettuce, or would you like a regular Burger with a cheese modification? Any specific modifications you'd like to add?"}, {'role': 'user', 'content': 'Yes.'}], 'model': 'gpt-4o'}}
2024-10-12 05:12:49.435 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:12:49.435 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:12:49.435 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:12:49.453 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB91D006A0>
2024-10-12 05:12:49.454 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AB8FEAC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:12:49.465 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB91D00670>
2024-10-12 05:12:49.466 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:49.467 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:50.333 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:12:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'817'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'71'), (b'x-ratelimit-remaining-tokens', b'9020'), (b'x-ratelimit-reset-requests', b'15h22m39.873s'), (b'x-ratelimit-reset-tokens', b'5.88s'), (b'x-request-id', b'req_a856b14a2f662bf43afd9f19fb1450ac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d165057ad8c7d18-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:50.334 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:12:50.335 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:50.335 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:50.335 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:50.335 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:50.335 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:12:50.337 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:50.337 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:51.037 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:51.037 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:51.039 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:51.040 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:51.043 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:51.059 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:51.107 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:51.885 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.84 seconds
2024-10-12 05:12:51.885 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:51.885 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:51.887 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:12:55.138 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 05:12:55.138 - RealTimeSTT: root - INFO - recording started
2024-10-12 05:12:55.138 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 05:12:55.139 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 05:12:56.478 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 05:12:56.478 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 05:12:56.479 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 05:12:56.579 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 05:12:56.583 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 05:12:56.590 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 05:12:56.607 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 05:12:57.161 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.58 seconds
2024-10-12 05:12:57.190 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Order Format: Once the user provides their order, extract the items and modifications into the following format:\n{\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n}\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample Interactions:\n\nScenario 1: User orders multiple items with modifications:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "Gotcha. Would like anything else?"\n    }\n\nScenario 2: Handling inappropriate language:\n    - User Input: "Uhmm fuck. Do you guys have burgers?"\n    - Assistant Response:\n    {\n        "ORDER": {},\n        "output": "Yes we do! Do you just want a regular burger then?"\n    }\n\nScenario 3: Customer confirms their order is complete:\n    - User Input: "No that\'s it."\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2},\n            "Fries": {},\n            "Chicken Biryani": {"Rice": 2, "Chicken": 2}\n        },\n        "output": "DONE"\n    }\n\nScenario 4: Polite response to aggressive user:\n    - User Input: "Yes bitch"\n    - Assistant Response:\n    {\n        "ORDER": {\n            "Burger": {"Cheese": 2}\n        },\n        "output": "All right!"\n    }\n\nAlways follow the format and tone in your responses, ensuring a structured and user-friendly interaction. Continue acting as the assistant, adhering to the guidelines provided, and extract the order details accordingly.\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': 'Hi there! What can I get for you today?'}, {'role': 'user', 'content': 'Yes, I would like to get it.'}, {'role': 'assistant', 'content': "Could you please let me know which items you'd like to order from our menu?"}, {'role': 'user', 'content': "It's cheeseburger."}, {'role': 'assistant', 'content': "Did you mean our Bacon Cheeseburger which comes with bacon, cheese, and lettuce, or would you like a regular Burger with a cheese modification? Any specific modifications you'd like to add?"}, {'role': 'user', 'content': 'Yes.'}, {'role': 'assistant', 'content': "Alright, I'll add a Bacon Cheeseburger to your order. If you need any modifications or additional items, just let me know! Would you like anything else?"}, {'role': 'user', 'content': "No, it's okay."}], 'model': 'gpt-4o'}}
2024-10-12 05:12:57.191 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 05:12:57.191 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 05:12:57.191 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 05:12:57.200 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB91D0D960>
2024-10-12 05:12:57.200 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AB8FEAC6C0> server_hostname='api.openai.com' timeout=5.0
2024-10-12 05:12:57.212 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AB91D0D930>
2024-10-12 05:12:57.212 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 05:12:57.213 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 05:12:57.213 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 05:12:57.213 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 05:12:57.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 05:12:58.287 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 10:12:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1011'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'70'), (b'x-ratelimit-remaining-tokens', b'8977'), (b'x-ratelimit-reset-requests', b'15h29m44.134s'), (b'x-ratelimit-reset-tokens', b'6.138s'), (b'x-request-id', b'req_73dd0fb921d7464d9e35b8371ef6dfa4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1650881fc97d18-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 05:12:58.287 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 05:12:58.288 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 05:12:58.288 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 05:12:58.288 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 05:12:58.288 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 05:12:58.289 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 05:12:58.292 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 05:12:58.292 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 05:12:58.294 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 05:13:08.908 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 05:13:08.908 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 05:13:08.919 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 05:13:09.567 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 05:13:09.578 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 05:13:09.651 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 08:10:29.802 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 08:10:29.812 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 08:10:29.820 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 08:10:29.820 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 08:10:30.284 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 08:10:30.290 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:10:30.307 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 08:10:30.313 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:10:30.314 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 08:10:30.319 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:10:30.319 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 08:10:30.319 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 08:10:47.991 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 08:10:47.997 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 08:10:47.997 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 08:10:48.668 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 08:10:48.669 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 08:10:48.669 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:10:48.669 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:10:49.405 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:10:49.890 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:10:49.891 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:10:49.891 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:10:49.892 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:10:56.361 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:10:56.361 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:10:56.362 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:10:56.407 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:10:56.415 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:10:56.417 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:10:56.420 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:10:57.259 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.84 seconds
2024-10-12 08:10:57.259 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:10:57.260 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:10:57.261 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:11:01.801 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:11:01.801 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:11:01.802 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:11:01.802 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:11:03.780 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:11:03.781 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:11:03.781 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:11:03.867 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:11:03.870 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:11:03.881 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:11:03.910 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:11:04.542 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 08:11:04.542 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:11:04.542 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:11:04.544 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:11:06.530 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:11:06.530 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:11:06.531 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:11:06.531 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:11:11.721 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:11:11.721 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:11:11.722 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:11:11.727 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:11:11.730 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:11:11.743 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:11:11.780 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:11:12.470 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.74 seconds
2024-10-12 08:11:12.470 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:11:12.470 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:11:12.472 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:11:13.891 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:11:13.891 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:11:13.891 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:11:13.892 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:11:18.181 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:11:18.181 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:11:18.182 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:11:18.246 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:11:18.249 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:11:18.265 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:11:18.310 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:11:18.897 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.65 seconds
2024-10-12 08:11:18.897 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:11:18.897 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:11:18.899 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:11:20.551 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:11:20.551 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:11:20.551 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:11:20.552 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:11:26.311 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:11:26.311 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:11:26.312 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:11:26.349 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:11:26.352 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:11:26.370 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:11:26.371 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:11:27.110 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.76 seconds
2024-10-12 08:11:27.111 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:11:27.111 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:11:27.112 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:11:30.124 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 08:11:30.125 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 08:11:30.135 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 08:11:30.721 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 08:11:30.722 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 08:11:30.778 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 08:36:13.601 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 08:36:13.611 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 08:36:13.616 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 08:36:13.616 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 08:36:13.752 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 08:36:13.757 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:36:13.760 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 08:36:13.765 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:36:13.765 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 08:36:13.769 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:36:13.770 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 08:36:13.770 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 08:36:14.205 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 08:36:14.207 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 08:36:14.207 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 08:36:19.261 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 08:36:19.262 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 08:36:19.262 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:36:19.262 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:36:19.882 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:36:21.561 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:36:21.561 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:36:21.561 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:36:21.562 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:36:22.710 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:36:22.710 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:36:22.711 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:36:22.758 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:36:22.764 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:36:22.769 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:36:22.774 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:36:23.471 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.71 seconds
2024-10-12 08:36:23.485 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:23.514 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:36:23.547 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E29F66E0>
2024-10-12 08:36:23.547 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:36:23.558 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E29F66B0>
2024-10-12 08:36:23.558 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:23.558 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:23.558 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:23.559 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:23.559 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:24.349 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'741'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29328'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.344s'), (b'x-request-id', b'req_c92c963cc8f270e25661552b327e3b6c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JO6KMS55GoER4bEsHHbNkJTDXybRSJ1N73NuE3eoOEg-1728740184-1.0.1.1-yi6Qz6eM1KDpirQRYgfiUNfyNKyXrEjSwe_q2aekkuIKEWmLkH4AmP_kwdk2xBJ9GrF4judAkC.NuqAZozIM_g; path=/; expires=Sat, 12-Oct-24 14:06:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yxUWj2P7aJVHGtsgwDIhgfns0Xiza7VWAn6Zf.WoYjI-1728740184492-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177a843b3243e2-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:24.350 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:24.350 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:24.350 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:24.350 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:24.350 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:24.350 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:24.358 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:24.359 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:24.359 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:24.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:24.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:24.360 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:25.442 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1025'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29314'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.37s'), (b'x-request-id', b'req_0f08c8639d0acb8a027b9c831d2fb4a4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177a893fe643e2-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:25.443 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:25.443 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:25.444 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:25.444 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:25.444 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:25.444 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:25.446 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:36:25.446 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:36:25.449 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:36:29.360 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:36:29.360 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:36:29.360 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:36:29.360 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:36:32.441 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:36:32.441 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:36:32.442 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:36:32.524 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:36:32.527 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:36:32.536 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:36:32.561 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:36:33.164 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 08:36:33.177 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."}'}, {'role': 'user', 'content': 'Yes, I would like to bury you on some price.'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:33.178 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:36:33.178 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:36:33.179 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:36:33.190 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A59090>
2024-10-12 08:36:33.190 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:36:33.234 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A59060>
2024-10-12 08:36:33.234 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:33.234 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:33.235 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:33.235 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:33.235 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:34.029 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'736'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29242'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.516s'), (b'x-request-id', b'req_6560513331783016f7fe2b374ab75ee3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177ac0a9220f5d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:34.030 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:34.030 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:34.031 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:34.031 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:34.031 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:34.031 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:34.040 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I apologize for any confusion. Let\'s focus on creating your order. Could you please let me know which menu items you would like today?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:34.041 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:34.041 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:34.042 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:34.042 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:34.042 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:34.619 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'525'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29313'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.373s'), (b'x-request-id', b'req_d2ffad5a5f928b6f48387b1121e6699a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177ac5bf450f5d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:34.619 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:34.620 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:34.620 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:34.620 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:34.620 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:34.620 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:34.622 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:36:34.622 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:36:34.624 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:36:38.390 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:36:38.390 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:36:38.390 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:36:38.391 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:36:41.840 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:36:41.840 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:36:41.841 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:36:41.856 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:36:41.858 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:36:41.869 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:36:41.910 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:36:42.550 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.69 seconds
2024-10-12 08:36:42.566 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."}'}, {'role': 'user', 'content': 'Yes, I would like to bury you on some price.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize for any confusion. Let\'s focus on creating your order. Could you please let me know which menu items you would like today?"}'}, {'role': 'user', 'content': 'I said I would like a burger and some fries.'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:42.567 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:36:42.568 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:36:42.568 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:36:42.584 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A625F0>
2024-10-12 08:36:42.584 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:36:42.598 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A625C0>
2024-10-12 08:36:42.598 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:42.599 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:43.537 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'834'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29189'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.622s'), (b'x-request-id', b'req_74c2a1d92c6d4dd8ff75f266070013cf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177afb38e580d9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:43.538 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:43.538 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:43.538 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:43.539 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:43.539 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:43.539 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:43.546 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {}, "Fries": {}}, "output": "Got it, a Burger and Fries. Would you like to add any customizations or order anything else?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:43.547 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:43.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:43.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:43.548 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:43.548 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:44.325 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'699'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29284'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.43s'), (b'x-request-id', b'req_4a80fb68a5b9cd39c3b70fbb5235a45d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177b012e6680d9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:44.326 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:44.327 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:44.327 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:44.327 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:44.328 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:44.328 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:44.330 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:36:44.330 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:36:44.333 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:36:48.760 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:36:48.760 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:36:48.760 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:36:48.761 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:36:52.151 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:36:52.151 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:36:52.152 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:36:52.214 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:36:52.217 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:36:52.237 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:36:52.279 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:36:52.881 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 08:36:52.900 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."}'}, {'role': 'user', 'content': 'Yes, I would like to bury you on some price.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize for any confusion. Let\'s focus on creating your order. Could you please let me know which menu items you would like today?"}'}, {'role': 'user', 'content': 'I said I would like a burger and some fries.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}, "Fries": {}}, "output": "Got it, a Burger and Fries. Would you like to add any customizations or order anything else?"}'}, {'role': 'user', 'content': 'Maybe extra tomatoes with the burgers.'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:52.901 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:36:52.901 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:36:52.901 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:36:52.913 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A6FDC0>
2024-10-12 08:36:52.913 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:36:52.926 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A554B0>
2024-10-12 08:36:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:52.927 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:52.927 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:52.927 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:53.766 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'785'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29141'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.718s'), (b'x-request-id', b'req_85d44b14b53ccc73c4a8abb75a47b430'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177b3bc89b43f7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:53.767 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:53.767 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:53.767 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:53.768 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:53.768 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:53.768 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:53.777 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "Sure thing! Extra tomatoes on the Burger. Is there anything else you\'d like to add or modify?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:36:53.778 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:36:53.778 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:36:53.778 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:36:53.779 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:36:53.779 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:36:54.384 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:36:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29194'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.61s'), (b'x-request-id', b'req_9ac42ecab7b93686be1ab596d793a4d0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177b411dd543f7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:36:54.385 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:36:54.385 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:36:54.385 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:36:54.385 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:36:54.386 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:36:54.386 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:36:54.387 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:36:54.388 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:36:54.390 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:36:57.459 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:36:57.459 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:36:57.459 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:36:57.460 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:36:59.320 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:36:59.321 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:36:59.322 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:36:59.387 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:36:59.389 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:36:59.409 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:36:59.439 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:37:00.048 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 08:37:00.075 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."}'}, {'role': 'user', 'content': 'Yes, I would like to bury you on some price.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize for any confusion. Let\'s focus on creating your order. Could you please let me know which menu items you would like today?"}'}, {'role': 'user', 'content': 'I said I would like a burger and some fries.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}, "Fries": {}}, "output": "Got it, a Burger and Fries. Would you like to add any customizations or order anything else?"}'}, {'role': 'user', 'content': 'Maybe extra tomatoes with the burgers.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "Sure thing! Extra tomatoes on the Burger. Is there anything else you\'d like to add or modify?"}'}, {'role': 'user', 'content': "No, that's fine with me."}], 'model': 'gpt-4o'}}
2024-10-12 08:37:00.076 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:37:00.076 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:37:00.076 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:37:00.099 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A76FB0>
2024-10-12 08:37:00.099 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:37:00.110 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A76EF0>
2024-10-12 08:37:00.110 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:37:00.111 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:37:00.111 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:37:00.111 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:37:00.111 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:37:00.945 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:37:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29094'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.812s'), (b'x-request-id', b'req_74088004e74dea4973bf3a8ff4c6fe03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177b68affd0f4f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:37:00.945 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:37:00.945 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:37:00.946 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:37:00.946 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:37:00.946 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:37:00.946 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:37:00.953 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "Great! Your order is a Burger with extra tomatoes and Fries. Thank you for your order. DONE."}'}], 'model': 'gpt-4o'}}
2024-10-12 08:37:00.953 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:37:00.954 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:37:00.954 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:37:00.954 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:37:00.954 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:37:01.851 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:37:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'829'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29137'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.725s'), (b'x-request-id', b'req_43720e47eb2af9e07b7e5bc984c204e0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177b6dec710f4f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:37:01.852 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:37:01.852 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:37:01.853 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:37:01.853 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:37:01.853 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:37:01.853 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:37:01.854 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:37:01.855 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:37:01.857 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:37:17.810 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:37:17.811 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:37:17.811 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:37:17.812 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:37:19.350 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:37:19.350 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:37:19.351 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:37:19.372 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:37:19.375 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:37:19.384 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:37:19.410 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:37:20.004 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 08:37:20.032 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hi there! Would you like to place an order? Here are the items you can choose from: Burger, Fries, Chicken Sandwich, Bacon Cheeseburger, Avocado Toast, BLT Sandwich, Caesar Salad, Egg Salad Sandwich, Veggie Burger, Spinach & Egg Wrap, Coffee, and Classic Hot Dog."}'}, {'role': 'user', 'content': 'Yes, I would like to bury you on some price.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize for any confusion. Let\'s focus on creating your order. Could you please let me know which menu items you would like today?"}'}, {'role': 'user', 'content': 'I said I would like a burger and some fries.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}, "Fries": {}}, "output": "Got it, a Burger and Fries. Would you like to add any customizations or order anything else?"}'}, {'role': 'user', 'content': 'Maybe extra tomatoes with the burgers.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "Sure thing! Extra tomatoes on the Burger. Is there anything else you\'d like to add or modify?"}'}, {'role': 'user', 'content': "No, that's fine with me."}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "Great! Your order is a Burger with extra tomatoes and Fries. Thank you for your order. DONE."}'}, {'role': 'user', 'content': 'All right, thank you.'}], 'model': 'gpt-4o'}}
2024-10-12 08:37:20.033 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:37:20.034 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:37:20.034 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:37:20.045 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A77850>
2024-10-12 08:37:20.045 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000227CD728640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:37:20.058 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000227E2A76D70>
2024-10-12 08:37:20.058 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:37:20.058 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:37:20.058 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:37:20.059 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:37:20.059 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:37:20.936 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:37:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'818'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29047'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.906s'), (b'x-request-id', b'req_d6f4de53cba0fa91b5af0cb8b94297a3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177be55d7a43bb-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:37:20.937 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:37:20.937 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:37:20.938 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:37:20.938 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:37:20.938 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:37:20.938 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:37:20.945 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {"Tomatoes": 1}, "Fries": {}}, "output": "You\'re welcome! If you have any more questions or need further assistance in the future, feel free to ask. Enjoy your meal!"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:37:20.946 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:37:20.947 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:37:20.947 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:37:20.947 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:37:20.947 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:37:21.627 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:37:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'630'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29078'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.842s'), (b'x-request-id', b'req_080ae0561a95b8fa90b5f3319aef2415'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177beaea3143bb-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:37:21.627 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:37:21.628 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:37:21.628 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:37:21.628 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:37:21.628 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:37:21.628 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:37:21.630 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:37:21.630 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:37:21.632 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:37:30.289 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 08:37:30.290 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 08:37:30.291 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 08:37:31.102 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-12 08:37:31.110 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-12 08:37:31.181 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-12 08:38:55.307 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-12 08:38:55.321 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-12 08:38:55.331 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-12 08:38:55.331 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-12 08:38:55.589 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-12 08:38:55.596 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:38:55.599 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-12 08:38:55.604 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:38:55.605 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-12 08:38:55.609 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Python310\lib\site-packages\torch\_ops.py", line 1032, in load_library
    ctypes.CDLL(path)
  File "C:\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Python310\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-12 08:38:55.610 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-12 08:38:55.610 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "C:\Python310\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-12 08:38:56.043 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-12 08:38:56.046 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-12 08:38:56.046 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-12 08:39:01.468 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-12 08:39:01.469 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-12 08:39:01.469 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:01.469 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:02.094 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:03.341 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:03.341 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:03.341 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:03.342 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:04.491 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:04.491 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:04.491 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:04.573 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:04.581 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:04.590 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:04.621 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:05.971 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.39 seconds
2024-10-12 08:39:05.986 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:06.042 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:06.085 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A467D0>
2024-10-12 08:39:06.086 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:06.103 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A467A0>
2024-10-12 08:39:06.103 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:06.103 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:06.103 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:06.104 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:06.104 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:06.711 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29328'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.344s'), (b'x-request-id', b'req_8e6de121e0da3884a73b6784bdd1d3ab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rF896NEhYEbzJ.dN.e3byUlVs7aWGYugu79bWYmrwYw-1728740346-1.0.1.1-qBGVZuHWKEY_PRPm1fVHtzrqkq1rVsnxVEY418kdVcypYXhz2L7vuUAefu1MtuVQIsJVyzuUnJtni6wg.y496w; path=/; expires=Sat, 12-Oct-24 14:09:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TMUnQLOZM6hQlpxrDYrjdFvDQNf8j506J6IPH1tZcDA-1728740346859-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177e7c2fe943b7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:06.712 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:06.718 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:06.720 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:06.721 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:06.721 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:06.721 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:06.730 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:06.731 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:06.732 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:06.732 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:06.732 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:06.732 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:07.358 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'562'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29327'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.344s'), (b'x-request-id', b'req_1b70aea646b3cb31613ea42d80c77185'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177e800bc043b7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:07.358 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:07.358 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:07.359 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:07.359 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:07.359 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:07.359 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:07.360 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:07.360 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:07.362 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:09.551 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:09.551 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:09.551 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:09.552 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:11.912 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:11.912 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:11.913 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:11.959 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:11.960 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:11.970 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:11.981 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:12.631 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 08:39:12.641 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:12.643 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:39:12.643 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:39:12.643 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:12.651 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AA90C0>
2024-10-12 08:39:12.651 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:12.666 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AA9090>
2024-10-12 08:39:12.666 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:12.667 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:12.667 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:12.667 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:12.667 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:13.495 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'774'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29296'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.408s'), (b'x-request-id', b'req_3cba4efe9de62190cae5364d3f30194a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177ea52b2a41d3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:13.495 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:13.496 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:13.496 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:13.496 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:13.497 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:13.497 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:13.503 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:13.504 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:13.505 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:13.505 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:13.505 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:13.505 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:14.342 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'755'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29349'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.3s'), (b'x-request-id', b'req_d24929af3f4e8b7c95bc52e2b5a66bba'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177eaa68cf41d3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:14.343 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:14.343 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:14.344 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:14.344 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:14.344 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:14.344 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:14.345 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:14.345 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:14.348 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:18.061 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:18.061 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:18.061 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:18.061 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:20.751 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:20.751 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:20.751 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:20.761 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:20.763 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:20.764 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:20.811 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:21.426 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 08:39:21.440 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:21.442 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:39:21.443 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:39:21.443 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:21.456 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AB2800>
2024-10-12 08:39:21.457 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:21.472 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AB27D0>
2024-10-12 08:39:21.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:21.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:21.472 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:21.473 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:21.473 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:22.214 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'682'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29242'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.516s'), (b'x-request-id', b'req_74fab58b5019e7cf70ed8de9bd0e19a9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177edc3aad1791-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:22.215 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:22.215 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:22.215 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:22.216 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:22.216 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:22.216 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:22.223 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:22.224 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:22.225 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:22.225 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:22.225 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:22.225 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:22.788 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'513'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29260'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.478s'), (b'x-request-id', b'req_4cb54f7fc51eda513cba38e116f25597'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177ee0edbe1791-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:22.788 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:22.789 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:22.789 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:22.789 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:22.789 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:22.789 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:22.790 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:22.790 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:22.792 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:27.661 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:27.661 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:27.661 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:27.662 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:29.191 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:29.191 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:29.192 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:29.247 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:29.249 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:29.250 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:29.260 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:29.887 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.64 seconds
2024-10-12 08:39:29.907 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}], 'model': 'gpt-4o'}}
2024-10-12 08:39:29.908 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:39:29.909 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:39:29.909 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:29.917 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6ABBDF0>
2024-10-12 08:39:29.917 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:29.929 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AAAF20>
2024-10-12 08:39:29.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:29.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:29.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:29.929 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:29.930 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:30.877 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'887'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29194'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.612s'), (b'x-request-id', b'req_e0eea2c0bd1606abe7d063f1c64431ce'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f110a620c76-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:30.877 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:30.878 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:30.878 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:30.878 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:30.878 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:30.878 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:30.883 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:30.884 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:30.886 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:30.886 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:30.886 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:30.886 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:31.753 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'816'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29288'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.423s'), (b'x-request-id', b'req_b1570dd6651f116827de52f89d958973'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f170f650c76-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:31.754 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:31.754 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:31.755 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:31.755 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:31.755 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:31.756 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:31.757 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:31.757 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:31.759 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:34.441 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:34.441 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:34.441 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:34.442 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:35.791 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:35.792 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:35.792 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:35.845 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:35.848 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:35.851 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:35.856 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:36.408 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.56 seconds
2024-10-12 08:39:36.436 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:36.438 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:36.438 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:36.438 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:36.438 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:36.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:37.296 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'798'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29141'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.718s'), (b'x-request-id', b'req_237d8670fde7274c20377feaf00ab883'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f39b8d40c76-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:37.297 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:37.297 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:37.298 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:37.298 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:37.298 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:37.298 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:37.304 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:37.305 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:37.306 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:37.306 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:37.306 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:37.306 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:38.395 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'1026'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29194'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.61s'), (b'x-request-id', b'req_2a098deaa49fad33ae451023e64964b7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f3f2d090c76-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:38.396 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:38.396 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:38.396 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:38.396 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:38.396 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:38.397 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:38.397 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:38.398 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:38.401 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:40.711 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:40.711 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:40.711 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:40.712 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:42.251 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:42.251 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:42.251 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:42.338 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:42.340 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:42.342 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:42.381 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:42.891 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:42.891 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:42.891 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 08:39:43.850 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-12 08:39:43.903 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.56 seconds
2024-10-12 08:39:43.934 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:43.935 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:39:43.935 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:39:43.935 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:43.947 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AC7820>
2024-10-12 08:39:43.947 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:43.961 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AC77F0>
2024-10-12 08:39:43.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:43.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:43.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:43.962 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:43.962 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:44.748 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'729'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29087'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.826s'), (b'x-request-id', b'req_b9549e2f1ad40a4a0270d92d0ea383d5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f68cef48cb9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:44.749 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:44.749 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:44.750 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:44.750 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:44.750 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:44.750 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:44.757 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:44.758 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:44.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:44.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:44.760 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:44.760 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:45.439 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'623'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29135'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.729s'), (b'x-request-id', b'req_5db052c4db08f95ee5615208dacca4c5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f6dbbdb8cb9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:45.440 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:45.440 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:45.440 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:45.440 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:45.440 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:45.441 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:45.442 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:45.442 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:46.152 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:46.152 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:46.153 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:46.154 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:46.157 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:46.157 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:46.162 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:48.368 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 2.21 seconds
2024-10-12 08:39:48.404 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:48.406 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:48.407 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:48.407 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:48.408 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:48.408 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:49.098 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'639'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29056'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.888s'), (b'x-request-id', b'req_e0b9a968849c56b49e70b6f0da5e017a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f848a208cb9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:49.099 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:49.099 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:49.100 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:49.100 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:49.100 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:49.100 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:49.107 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:49.108 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:49.108 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:49.108 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:49.109 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:49.109 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:49.836 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'658'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29057'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.885s'), (b'x-request-id', b'req_194349645229f06f8d4189bb64c5a19f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177f88ee858cb9-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:49.842 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:49.843 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:49.844 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:49.844 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:49.845 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:49.845 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:49.846 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:49.846 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:49.849 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:39:54.732 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:39:54.732 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:39:54.732 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:39:54.732 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:39:55.881 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:39:55.881 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:39:55.882 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:39:55.892 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:39:55.894 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:39:55.895 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:39:55.951 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:39:56.508 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 08:39:56.549 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:56.550 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:39:56.551 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:39:56.551 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:39:56.560 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6ACECB0>
2024-10-12 08:39:56.561 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:39:56.574 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6ACEC80>
2024-10-12 08:39:56.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:56.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:56.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:56.575 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:56.575 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:57.354 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'723'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29024'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.952s'), (b'x-request-id', b'req_de850eae5397f3ef0d280a5310244c93'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177fb79b877c7c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:57.355 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:57.355 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:57.355 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:57.355 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:57.356 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:57.356 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:57.362 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:39:57.363 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:39:57.364 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:39:57.364 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:39:57.365 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:39:57.365 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:39:58.100 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:39:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'669'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29050'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.898s'), (b'x-request-id', b'req_e7fc2ee235d05e7a3c7d4a7364c8eeb3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177fbc88a87c7c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:39:58.101 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:39:58.101 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:39:58.102 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:39:58.103 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:39:58.103 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:39:58.104 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:39:58.105 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:39:58.105 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:39:58.108 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:40:01.261 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:01.261 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:01.261 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:40:01.262 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:02.791 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:02.791 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:02.793 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:03.045 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:03.047 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:03.049 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:03.051 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:03.729 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.68 seconds
2024-10-12 08:40:03.769 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:03.771 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:40:03.771 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:40:03.771 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:40:03.793 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6ACD540>
2024-10-12 08:40:03.793 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:40:03.817 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AC6BF0>
2024-10-12 08:40:03.817 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:03.818 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:03.819 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:03.819 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:03.819 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:04.778 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'876'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28984'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.032s'), (b'x-request-id', b'req_6e6bb9249e59198ececcbb7efd598d56'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177fe4d9bb423f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:04.778 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:04.778 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:04.779 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:04.779 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:04.779 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:04.779 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:04.786 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:04.787 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:04.787 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:04.787 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:04.788 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:04.788 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:05.380 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'537'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29070'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.858s'), (b'x-request-id', b'req_beb564fbcb2125540f2bd6eab799e411'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d177feae90a423f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:05.381 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:05.381 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:05.382 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:05.382 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:05.382 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:05.382 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:05.384 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:05.384 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:40:05.386 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:40:11.560 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:11.561 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:11.561 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:40:11.561 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:12.971 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:12.971 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:12.972 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:12.989 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:12.991 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:13.003 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:13.031 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:13.649 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.66 seconds
2024-10-12 08:40:13.702 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}, {'role': 'user', 'content': "What's this going on?"}], 'model': 'gpt-4o'}}
2024-10-12 08:40:13.704 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:40:13.705 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:40:13.705 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:40:13.760 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A470A0>
2024-10-12 08:40:13.760 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:40:13.774 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A47070>
2024-10-12 08:40:13.774 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:13.774 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:13.774 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:13.774 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:13.775 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:14.617 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'768'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28945'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.11s'), (b'x-request-id', b'req_c3ff4c078c9dc2237fc2d0006c4a9312'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d17802319308cdc-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:14.618 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:14.618 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:14.619 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:14.619 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:14.619 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:14.619 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:14.626 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I\'m here to assist you with placing an order from our menu. If there\'s something specific you\'d like to order or inquire about, please let me know!"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:14.628 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:14.628 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:14.628 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:14.629 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:14.629 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:15.165 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'481'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28955'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.088s'), (b'x-request-id', b'req_21d14850eb8b7ec90f4f8ee15cee92e0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d17802868d48cdc-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:15.166 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:15.166 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:15.166 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:15.167 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:15.167 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:15.167 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:15.168 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:15.168 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:40:15.169 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:40:18.541 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:18.542 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:18.542 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:40:18.542 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:20.072 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:20.072 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:20.072 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:20.103 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:20.106 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:20.114 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:20.151 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:20.776 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.67 seconds
2024-10-12 08:40:20.823 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}, {'role': 'user', 'content': "What's this going on?"}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to assist you with placing an order from our menu. If there\'s something specific you\'d like to order or inquire about, please let me know!"}'}, {'role': 'user', 'content': 'What happened?'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:20.825 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:40:20.826 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:40:20.826 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:40:20.840 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A46C20>
2024-10-12 08:40:20.841 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:40:20.856 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6A46F20>
2024-10-12 08:40:20.856 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:20.856 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:20.856 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:20.856 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:20.857 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:21.702 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'784'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28896'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.208s'), (b'x-request-id', b'req_cf6238d011332a81ea02e20fa7ef9101'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d17804f5fda0f70-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:21.703 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:21.703 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:21.703 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:21.703 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:21.704 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:21.704 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:21.711 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I\'m here to help you with your food order. If there\'s anything specific you\'d like to know or order, please feel free to tell me."}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:21.713 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:21.713 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:21.713 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:21.713 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:21.713 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:22.249 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'477'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28925'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.148s'), (b'x-request-id', b'req_690349cb550a759a08efb5146abf558e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d178054bd090f70-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:22.250 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:22.250 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:22.251 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:22.251 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:22.251 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:22.251 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:22.252 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:22.252 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:40:22.255 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:40:25.001 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:25.001 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:25.001 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-12 08:40:25.002 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:26.792 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:26.792 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:26.793 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:26.848 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:26.850 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:26.851 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:26.860 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:28.715 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 1.86 seconds
2024-10-12 08:40:28.771 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}, {'role': 'user', 'content': "What's this going on?"}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to assist you with placing an order from our menu. If there\'s something specific you\'d like to order or inquire about, please let me know!"}'}, {'role': 'user', 'content': 'What happened?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to help you with your food order. If there\'s anything specific you\'d like to know or order, please feel free to tell me."}'}, {'role': 'user', 'content': 'Yeah.'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:28.773 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:40:28.773 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:40:28.774 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:40:28.816 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AC7250>
2024-10-12 08:40:28.816 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:40:28.830 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6ACC6A0>
2024-10-12 08:40:28.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:28.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:28.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:28.831 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:28.831 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:28.971 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:28.971 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:28.971 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 08:40:29.672 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'790'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28854'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.292s'), (b'x-request-id', b'req_20d2a44785407de01201df57cad7d36c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d178081389119db-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:29.672 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:29.673 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:29.673 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:29.673 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:29.673 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:29.673 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:29.679 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "Great! Please let me know what you\'d like to order from our menu. We have options like Burger, Fries, Chicken Sandwich, and more."}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:29.680 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:29.681 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:29.681 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:29.681 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:29.681 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:30.457 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'721'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28867'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.264s'), (b'x-request-id', b'req_c5656dedd0095f12377b526a49abc206'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1780868c5219db-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:30.458 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:30.458 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:30.458 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:30.458 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:30.458 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:30.458 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:30.459 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:30.459 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:31.211 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:31.211 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:31.212 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:31.307 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:31.310 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:31.324 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:31.341 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:31.943 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.63 seconds
2024-10-12 08:40:31.998 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}, {'role': 'user', 'content': "What's this going on?"}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to assist you with placing an order from our menu. If there\'s something specific you\'d like to order or inquire about, please let me know!"}'}, {'role': 'user', 'content': 'What happened?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to help you with your food order. If there\'s anything specific you\'d like to know or order, please feel free to tell me."}'}, {'role': 'user', 'content': 'Yeah.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Great! Please let me know what you\'d like to order from our menu. We have options like Burger, Fries, Chicken Sandwich, and more."}'}, {'role': 'user', 'content': 'Mm-hmm.'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:31.999 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:32.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:32.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:32.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:32.001 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:32.111 - RealTimeSTT: root - INFO - voice activity detected
2024-10-12 08:40:32.111 - RealTimeSTT: root - INFO - recording started
2024-10-12 08:40:32.111 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-12 08:40:32.772 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'718'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28811'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.378s'), (b'x-request-id', b'req_cfad21512ee9eced669a51b7bce6c56a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d17809508fc19db-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:32.772 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:32.772 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:32.772 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:32.772 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:32.773 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:32.773 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:32.779 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "I\'m ready to take your order whenever you are. Just let me know what you\'d like from our menu!"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:32.780 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:32.780 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:32.781 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:32.781 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:32.781 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:33.517 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'676'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28806'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.387s'), (b'x-request-id', b'req_fe06baacd5bd72bccfa71e338bacd89e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d178099ecc819db-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:33.518 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:33.518 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:33.519 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:33.520 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:33.520 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:33.520 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:33.521 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:33.521 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-12 08:40:38.706 - RealTimeSTT: root - INFO - recording stopped
2024-10-12 08:40:38.706 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-12 08:40:38.733 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-12 08:40:38.993 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-12 08:40:38.995 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-12 08:40:38.996 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-12 08:40:39.021 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-12 08:40:39.603 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.61 seconds
2024-10-12 08:40:39.669 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are a food ordering assistant, responsible for processing customer orders from natural language input and translating them into a structured JSON format. The user will provide their food order, and your task is to extract the food items and any customizations or modifications made to them.\n\nInstructions:\n1. Menu Items: You have the following menu items available for ordering:\n    - Burger: Delicious beef burger\n    - Fries: Crispy golden fries\n    - Chicken Sandwich: Grilled chicken sandwich with mayo and lettuce\n    - Bacon Cheeseburger: Beef patty with bacon, cheese, and lettuce\n    - Avocado Toast: Fresh avocado spread on toasted bread\n    - BLT Sandwich: Bacon, lettuce, and tomato sandwich\n    - Caesar Salad: Classic Caesar salad with chicken, croutons, and Caesar dressing\n    - Egg Salad Sandwich: Egg salad sandwich with mayo on toasted bread\n    - Veggie Burger: Healthy veggie patty burger with lettuce, tomato, and onion\n    - Spinach & Egg Wrap: Healthy spinach and egg wrap\n    - Coffee: Freshly brewed coffee\n    - Classic Hot Dog: Hot dog with ketchup and mustard\n\n2. Response Format: Once the user provides their order, extract the items and modifications into the following format:\n\n    "ORDER": {\n        "food_item_1": {"modification_1": value, "modification_2": value, ...},\n        "food_item_2": {}\n    },\n    "output": "Appropriate response to continue or end the conversation."\n\n    Note: - All those values should be integers if they are additions or removals.\n          - if they are specific set values, they should be a string like this -n- where n is the desired number\n\n3. Conversations and Responses:\n    - If the user hasnt ordered yet, the "ORDER" field should be empty: "ORDER": {}.\n    - The "output" should guide the user to either order more or confirm their request.\n    - When the conversation is complete, set "output": "DONE".\n\n4. Handling Edge Cases:\n    - If the user uses inappropriate language, respond politely and redirect to the menu or confirm if they want to order.\n    - For ambiguous orders or multiple customizations, clarify with the user to confirm the exact details.\n    - Always adapt your response to the tone and details provided by the user.\n\nExample interaction:\n    - User Input: "I\'d like a burger with extra cheese and a side of fries, and also a chicken biryani with 2 extra bowls rice and extra chicken. No pickles please on my burger."\n    - Assistant Response:\n        "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"\n'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Hello! What would you like to order today from our menu?"}'}, {'role': 'user', 'content': 'I would like to order a pizza today.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m sorry, but pizza is not on our menu. Would you like to order something else from our available items, such as a Burger, Chicken Sandwich, or Fries?"}'}, {'role': 'user', 'content': 'In that case, above the police.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I apologize, I didn\'t understand that. Could you please let me know if there\'s something specific from our menu that you would like to order?"}'}, {'role': 'user', 'content': "I'm a bugger."}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "It seems like there might be a misunderstanding. If you\'re looking to order a Burger or anything else from our menu, please let me know your choice and any customizations."}'}, {'role': 'user', 'content': 'A burger.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Got it! Would you like any customizations with your Burger, such as extra cheese or no pickles, or would you like to add anything else to your order?"}'}, {'role': 'user', 'content': 'Whoa, there you go.'}, {'role': 'assistant', 'content': '{"ORDER": {"Burger": {}}, "output": "Thank you! Would you like to order anything else or confirm your order?"}'}, {'role': 'user', 'content': 'Oh no.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "No worries! Would you like to start over with your order or need help with anything else?"}'}, {'role': 'user', 'content': 'No.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Alright, if you change your mind or need anything else, feel free to let me know. Have a great day!"}'}, {'role': 'user', 'content': 'Yeah, I have a great deal.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Fantastic! If you decide to order, I\'m here to help. Would you like to add something from our menu?"}'}, {'role': 'user', 'content': "What's this going on?"}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to assist you with placing an order from our menu. If there\'s something specific you\'d like to order or inquire about, please let me know!"}'}, {'role': 'user', 'content': 'What happened?'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m here to help you with your food order. If there\'s anything specific you\'d like to know or order, please feel free to tell me."}'}, {'role': 'user', 'content': 'Yeah.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "Great! Please let me know what you\'d like to order from our menu. We have options like Burger, Fries, Chicken Sandwich, and more."}'}, {'role': 'user', 'content': 'Mm-hmm.'}, {'role': 'assistant', 'content': '{"ORDER": {}, "output": "I\'m ready to take your order whenever you are. Just let me know what you\'d like from our menu!"}'}, {'role': 'user', 'content': 'Yeah.'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:39.670 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-12 08:40:39.670 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-12 08:40:39.671 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-12 08:40:39.693 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AE7400>
2024-10-12 08:40:39.693 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024091790640> server_hostname='api.openai.com' timeout=5.0
2024-10-12 08:40:39.707 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240A6AE7DF0>
2024-10-12 08:40:39.707 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:39.708 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:39.708 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:39.708 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:39.708 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:40.342 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'575'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28778'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.444s'), (b'x-request-id', b'req_568c5f18f2d3faba0de31b775ec8d810'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1780c528c042dc-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:40.342 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:40.343 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:40.343 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:40.343 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:40.343 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:40.343 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:40.351 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': ' You are a machine that takes text returns what is supposed to be the food ORDER part of the text and the reply part. Sometimes there is no ORDER part.\n                          You should parse the text and strictly return the processed text in the following format:\n                        \n                          For example, if you get the input: "ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"                          Your output should be: {"ORDER": {"Burger": {"Cheese": 2, "Pickles":"-0-"},"Fries": {},"Chicken Biryani": {"Rice": 2, "Chicken": 1}}, "output": "Gotcha. Would like anything else?"}\n\n                          if you get the input: "Would you like something else?"\n                          your output should be: {"ORDER":{}, "output": "Would you like something else?"}\n\n                          if you get the input: "````json {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"}````"\n                          your output should be: {"ORDER":{"Pizza":{}, "Pork":{"Tomato":"-7-"}}, "output":"DONE"} \n                        \n                          Now process the following user\'s input as instructed:\n                      '}, {'role': 'user', 'content': '{"ORDER": {}, "output": "Whenever you\'re ready, just let me know what you\'d like to order, and I\'ll be happy to assist!"}'}], 'model': 'gpt-4o'}}
2024-10-12 08:40:40.352 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-12 08:40:40.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-12 08:40:40.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-12 08:40:40.353 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-12 08:40:40.353 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-12 08:40:40.901 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 12 Oct 2024 13:40:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mq4m0syxneokht0updvyuird'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'28694'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'2.61s'), (b'x-request-id', b'req_67a31c0d726bfe3cf86fd1f954c5774d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d1780c93c7442dc-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-12 08:40:40.902 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-12 08:40:40.902 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-12 08:40:40.902 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-12 08:40:40.902 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-12 08:40:40.902 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-12 08:40:40.903 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-10-12 08:40:40.904 - RealTimeSTT: root - INFO - Setting listen time
2024-10-12 08:40:40.904 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-12 08:40:40.906 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-12 08:40:42.899 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-12 08:40:42.899 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-12 08:40:42.902 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-12 08:40:43.622 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
